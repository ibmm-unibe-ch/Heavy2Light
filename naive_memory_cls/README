# Naive/Memory Chain Classifier

This repository provides a transformer-based classifier for distinguishing **naive** and **memory** B-cell sequences, using **adapters** integrated into pre-trained models (e.g., RoBERTa).

---

## üß¨ Input Format

Both the training and validation scripts expect a CSV input file containing a column named `sequence_alignment_aa`, which holds the amino acid sequences of interest.

> ‚ö†Ô∏è If your column name differs, **please update it in your CSV file or modify the code accordingly**.

---

## üöÄ Quickstart

### üîç Testing the Model

To test the model on a dataset, choose the appropriate **chain type** (e.g., `heavy`, `light`) and corresponding **model checkpoint** and **tokenizer path**.

#### Example: Heavy Chain

```bash
CHAIN="heavy"
MODEL_PATH="/FULL_config_4_smaller_model_run_lr5e-5_500epochs_max_seq_length_512/checkpoint-117674391"
TOKENIZER_PATH="$MODEL_PATH"
MODE="test"

ADAPTER_NAME="${CHAIN}_to_naive_memory_cls"
MAX_LENGTH=150
BATCH_SIZE=64
EPOCHS=200
LEARNING_RATE=3e-6
WEIGHT_DECAY=0.01
DROPOUT=0.1
RUN_NAME="${CHAIN}_bs${BATCH_SIZE}_lr${LEARNING_RATE}_wd${WEIGHT_DECAY}_do${DROPOUT}"
WANDB_PROJECT="naive_memory_classifier"

ADAPTERS_DIR="../models/${RUN_NAME}/BEST_MODEL*"
TEST_CSV="unsorted_b_cells_full_paired_data_all_cols.csv"

echo "Run name: ${RUN_NAME}"

python train_naive_memory_classifier.py \
    --mode $MODE \
    --model_path $MODEL_PATH \
    --tokenizer_path $TOKENIZER_PATH \
    --adapter_name $ADAPTER_NAME \
    --checkpoint_base_dir $ADAPTERS_DIR \
    --max_length $MAX_LENGTH \
    --batch_size $BATCH_SIZE \
    --run_name $RUN_NAME \
    --wandb_project $WANDB_PROJECT \
    --adapter_path $ADAPTERS_DIR \
    --test_csv $TEST_CSV
