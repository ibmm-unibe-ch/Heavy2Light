{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a693e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba9abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_antibody_data(file_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse antibody generation data from text file and create two DataFrames:\n",
    "    1. Detailed sequences DataFrame\n",
    "    2. Summary statistics DataFrame\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the input text file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: (sequences_df, summary_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Initialize lists to store parsed data\n",
    "    sequences_data = []\n",
    "    summary_data = []\n",
    "    \n",
    "    # Split content by heavy chains\n",
    "    heavy_chain_sections = re.split(r'Heavy chain (\\d+)', content)[1:]  # Skip first empty element\n",
    "    \n",
    "    for i in range(0, len(heavy_chain_sections), 2):\n",
    "        heavy_chain_num = int(heavy_chain_sections[i])\n",
    "        section_content = heavy_chain_sections[i + 1]\n",
    "        \n",
    "        # Parse individual sequences for this heavy chain\n",
    "        sequence_blocks = re.findall(\n",
    "            r'Generated sequence (\\d+):\\s*\\n'\n",
    "            r'True Light Sequence: ([A-Z]+)\\s*\\n'\n",
    "            r'Generated Light Sequence: ([A-Z]+)\\s*\\n'\n",
    "            r'Input Heavy Sequence: ([A-Z]+)\\s*\\n'\n",
    "            r'BLOSUM Score: ([0-9.]+)\\s*\\n'\n",
    "            r'Similarity Percentage: ([0-9.]+)%\\s*\\n'\n",
    "            r'Perplexity: ([0-9.]+)',\n",
    "            section_content\n",
    "        )\n",
    "        \n",
    "        # Store sequence data\n",
    "        for seq_data in sequence_blocks:\n",
    "            sequences_data.append({\n",
    "                'heavy_chain_number': heavy_chain_num,\n",
    "                'gen_light_chain_number': int(seq_data[0]),\n",
    "                'true_light_seq': seq_data[1],\n",
    "                'gen_light_seq': seq_data[2],\n",
    "                'input_heavy_seq': seq_data[3],\n",
    "                'BLOSUM': float(seq_data[4]),\n",
    "                'similarity': float(seq_data[5]),\n",
    "                'perplexity': float(seq_data[6])\n",
    "            })\n",
    "        \n",
    "        # Parse summary data for this heavy chain\n",
    "        summary_match = re.search(\n",
    "            r'--- Summary for Heavy Chain \\d+ ---\\s*\\n'\n",
    "            r'Average BLOSUM Score for \\d+ sequences: ([0-9.]+)\\s*\\n'\n",
    "            r'Best BLOSUM Score: ([0-9.]+)\\s*\\n'\n",
    "            r'Average Similarity for \\d+ sequences: ([0-9.]+)%\\s*\\n'\n",
    "            r'Best Similarity: ([0-9.]+)%\\s*\\n'\n",
    "            r'Average Perplexity for \\d+ sequences: ([0-9.]+)\\s*\\n'\n",
    "            r'Best Perplexity: ([0-9.]+)',\n",
    "            section_content\n",
    "        )\n",
    "        \n",
    "        if summary_match:\n",
    "            summary_data.append({\n",
    "                'heavy_chain_number': heavy_chain_num,\n",
    "                'avg_blosum': float(summary_match.group(1)),\n",
    "                'best_blosum': float(summary_match.group(2)),\n",
    "                'avg_similarity': float(summary_match.group(3)),\n",
    "                'best_similarity': float(summary_match.group(4)),\n",
    "                'average_perplexity': float(summary_match.group(5)),\n",
    "                'best_perplexity': float(summary_match.group(6))\n",
    "            })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    sequences_df = pd.DataFrame(sequences_data)\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    return sequences_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbe5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(sequences_df: pd.DataFrame, summary_df: pd.DataFrame, \n",
    "                sequences_file: str = 'antibody_sequences.csv', \n",
    "                summary_file: str = 'antibody_summary.csv',\n",
    "                output_dir: str = './') -> None:\n",
    "    \"\"\"\n",
    "    Save DataFrames to CSV files\n",
    "    \n",
    "    Args:\n",
    "        sequences_df (pd.DataFrame): Detailed sequences data\n",
    "        summary_df (pd.DataFrame): Summary statistics data\n",
    "        sequences_file (str): Output filename for sequences CSV\n",
    "        summary_file (str): Output filename for summary CSV\n",
    "    \"\"\"\n",
    "    sequences_df.to_csv(output_dir + sequences_file, index=False)\n",
    "    summary_df.to_csv(output_dir + summary_file, index=False)\n",
    "    \n",
    "    print(f\"Sequences data saved to: {sequences_file}\")\n",
    "    print(f\"Summary data saved to: {summary_file}\")\n",
    "    print(f\"\\nSequences DataFrame shape: {sequences_df.shape}\")\n",
    "    print(f\"Summary DataFrame shape: {summary_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2a91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/logs/full_eval_generate_multiple_light_seqs_203267.o\"  \n",
    "    \n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_eval_generate_multiple_light_seqs_203276_10k.o\"  \n",
    "\n",
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/logs/full_eval_generate_multiple_light_seqs_203276.o\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46c0af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEQUENCES DATA PREVIEW ===\n",
      "   heavy_chain_number  gen_light_chain_number  \\\n",
      "0                   1                       1   \n",
      "1                   1                       2   \n",
      "2                   1                       3   \n",
      "3                   1                       4   \n",
      "4                   1                       5   \n",
      "\n",
      "                                      true_light_seq  \\\n",
      "0  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "1  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "2  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "3  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "4  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "\n",
      "                                       gen_light_seq  \\\n",
      "0  QSALTQPPSASGSPGQSVTISCTGTSSDIGGYNFVSWYQQHPGKAP...   \n",
      "1  SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...   \n",
      "2  DIVMTQSPDSLAVSLGERATINCKSSQSVLYSPNNKNYLGWYQQKP...   \n",
      "3  EIVLTQSPATLSLSPGERATLSCRASQSVGTYLAWYQQKPGQAPRL...   \n",
      "4  SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPVVV...   \n",
      "\n",
      "                                     input_heavy_seq  BLOSUM  similarity  \\\n",
      "0  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   218.0   46.363636   \n",
      "1  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   204.0   39.814815   \n",
      "2  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   333.0   60.176991   \n",
      "3  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   379.0   64.485981   \n",
      "4  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   202.0   41.284404   \n",
      "\n",
      "   perplexity  \n",
      "0    2.466424  \n",
      "1    2.466424  \n",
      "2    2.466424  \n",
      "3    2.466424  \n",
      "4    2.466424  \n",
      "\n",
      "Columns: ['heavy_chain_number', 'gen_light_chain_number', 'true_light_seq', 'gen_light_seq', 'input_heavy_seq', 'BLOSUM', 'similarity', 'perplexity']\n",
      "\n",
      "=== SUMMARY DATA PREVIEW ===\n",
      "   heavy_chain_number  avg_blosum  best_blosum  avg_similarity  \\\n",
      "0                   1       252.8        391.0           49.85   \n",
      "1                   2       236.4        299.0           50.22   \n",
      "2                   3       347.6        428.0           64.28   \n",
      "3                   4       216.4        281.0           45.03   \n",
      "4                   5       310.4        513.0           57.48   \n",
      "\n",
      "   best_similarity  average_perplexity  best_perplexity  \n",
      "0            65.42                2.47             2.47  \n",
      "1            58.93                2.67             2.67  \n",
      "2            76.85                3.34             3.34  \n",
      "3            50.44                2.27             2.27  \n",
      "4            88.18                2.35             2.35  \n",
      "\n",
      "Columns: ['heavy_chain_number', 'avg_blosum', 'best_blosum', 'avg_similarity', 'best_similarity', 'average_perplexity', 'best_perplexity']\n",
      "Sequences data saved to: full_eval_generate_multiple_light_seqs_203276.csv\n",
      "Summary data saved to: summary_full_eval_generate_multiple_light_seqs_203276.csv\n",
      "\n",
      "Sequences DataFrame shape: (588289, 8)\n",
      "Summary DataFrame shape: (58838, 7)\n",
      "\n",
      "=== BASIC STATISTICS ===\n",
      "Total sequences processed: 588289\n",
      "Number of heavy chains: 58838\n",
      "Average BLOSUM score across all sequences: 316.48\n",
      "Average similarity across all sequences: 60.96%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sequences_df, summary_df = parse_antibody_data(input_file)\n",
    "        \n",
    "# Display preview of the data\n",
    "print(\"=== SEQUENCES DATA PREVIEW ===\")\n",
    "print(sequences_df.head())\n",
    "print(f\"\\nColumns: {list(sequences_df.columns)}\")\n",
    "        \n",
    "print(\"\\n=== SUMMARY DATA PREVIEW ===\")\n",
    "print(summary_df.head())\n",
    "print(f\"\\nColumns: {list(summary_df.columns)}\")\n",
    "        \n",
    "# Save to CSV files\n",
    "save_to_csv(sequences_df, summary_df, sequences_file = \"full_eval_generate_multiple_light_seqs_203276.csv\", summary_file = \"summary_full_eval_generate_multiple_light_seqs_203276.csv\" ,output_dir='/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/')\n",
    "        \n",
    "# Optional: Display some basic statistics\n",
    "print(f\"\\n=== BASIC STATISTICS ===\")\n",
    "print(f\"Total sequences processed: {len(sequences_df)}\")\n",
    "print(f\"Number of heavy chains: {len(summary_df)}\")\n",
    "print(f\"Average BLOSUM score across all sequences: {sequences_df['BLOSUM'].mean():.2f}\")\n",
    "print(f\"Average similarity across all sequences: {sequences_df['similarity'].mean():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3471aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_sequences_to_csv(input_csv_path: str, \n",
    "                          matching_csv_path: str = None,\n",
    "                          non_matching_csv_path: str = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Split sequences into two CSV files based on whether predicted_gen_light_seq_label \n",
    "    and predicted_input_heavy_seq_label match or not.\n",
    "    \n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file\n",
    "        matching_csv_path (str, optional): Path for matching sequences CSV file\n",
    "        non_matching_csv_path (str, optional): Path for non-matching sequences CSV file\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (matching_df, non_matching_df) - DataFrames for matching and non-matching sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(f\"Reading data from: {input_csv_path}\")\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Original columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_columns = ['predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    # Show distribution of labels before filtering\n",
    "    print(f\"\\n=== LABEL DISTRIBUTION BEFORE SPLITTING ===\")\n",
    "    print(\"predicted_gen_light_seq_label distribution:\")\n",
    "    print(df['predicted_gen_light_seq_label'].value_counts())\n",
    "    print(\"\\npredicted_input_heavy_seq_label distribution:\")\n",
    "    print(df['predicted_input_heavy_seq_label'].value_counts())\n",
    "    \n",
    "    # Split sequences into matching and non-matching\n",
    "    matching_df = df[df['predicted_gen_light_seq_label'] == df['predicted_input_heavy_seq_label']].copy()\n",
    "    non_matching_df = df[df['predicted_gen_light_seq_label'] != df['predicted_input_heavy_seq_label']].copy()\n",
    "    \n",
    "    print(f\"\\n=== SPLITTING RESULTS ===\")\n",
    "    print(f\"Matching sequences: {len(matching_df)}\")\n",
    "    print(f\"Non-matching sequences: {len(non_matching_df)}\")\n",
    "    print(f\"Total sequences: {len(df)}\")\n",
    "    print(f\"Percentage matching: {(len(matching_df) / len(df)) * 100:.2f}%\")\n",
    "    print(f\"Percentage non-matching: {(len(non_matching_df) / len(df)) * 100:.2f}%\")\n",
    "    \n",
    "    # Set default output paths if not provided\n",
    "    if matching_csv_path is None:\n",
    "        base_name = os.path.splitext(input_csv_path)[0]\n",
    "        matching_csv_path = f\"{base_name}_matching.csv\"\n",
    "    \n",
    "    if non_matching_csv_path is None:\n",
    "        base_name = os.path.splitext(input_csv_path)[0]\n",
    "        non_matching_csv_path = f\"{base_name}_non_matching.csv\"\n",
    "    \n",
    "    # Save matching sequences to CSV\n",
    "    matching_df.to_csv(matching_csv_path, index=False)\n",
    "    print(f\"\\nMatching sequences saved to: {matching_csv_path}\")\n",
    "    \n",
    "    # Save non-matching sequences to CSV\n",
    "    non_matching_df.to_csv(non_matching_csv_path, index=False)\n",
    "    print(f\"Non-matching sequences saved to: {non_matching_csv_path}\")\n",
    "    \n",
    "    # Show distribution of matching labels\n",
    "    if len(matching_df) > 0:\n",
    "        print(f\"\\n=== MATCHING LABELS DISTRIBUTION ===\")\n",
    "        print(\"Distribution of matching labels:\")\n",
    "        print(matching_df['predicted_gen_light_seq_label'].value_counts())\n",
    "        \n",
    "        # Show some examples of the matching data\n",
    "        print(f\"\\n=== SAMPLE OF MATCHING DATA ===\")\n",
    "        print(matching_df[['heavy_chain_number', 'gen_light_chain_number', \n",
    "                          'predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']].head(5))\n",
    "    \n",
    "    # Show distribution of non-matching labels\n",
    "    if len(non_matching_df) > 0:\n",
    "        print(f\"\\n=== NON-MATCHING LABELS DISTRIBUTION ===\")\n",
    "        print(\"Light chain labels in non-matching:\")\n",
    "        print(non_matching_df['predicted_gen_light_seq_label'].value_counts())\n",
    "        print(\"\\nHeavy chain labels in non-matching:\")\n",
    "        print(non_matching_df['predicted_input_heavy_seq_label'].value_counts())\n",
    "        \n",
    "        # Show some examples of the non-matching data\n",
    "        print(f\"\\n=== SAMPLE OF NON-MATCHING DATA ===\")\n",
    "        print(non_matching_df[['heavy_chain_number', 'gen_light_chain_number', \n",
    "                              'predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']].head(5))\n",
    "    \n",
    "    return matching_df, non_matching_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0023bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions.csv\n",
      "Original dataset shape: (588289, 12)\n",
      "Original columns: ['heavy_chain_number', 'gen_light_chain_number', 'true_light_seq', 'gen_light_seq', 'input_heavy_seq', 'BLOSUM', 'similarity', 'perplexity', 'label', 'predicted_true_light_seq_label', 'predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']\n",
      "\n",
      "=== LABEL DISTRIBUTION BEFORE SPLITTING ===\n",
      "predicted_gen_light_seq_label distribution:\n",
      "predicted_gen_light_seq_label\n",
      "0    358453\n",
      "1    229836\n",
      "Name: count, dtype: int64\n",
      "\n",
      "predicted_input_heavy_seq_label distribution:\n",
      "predicted_input_heavy_seq_label\n",
      "1    449521\n",
      "0    138768\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SPLITTING RESULTS ===\n",
      "Matching sequences: 341304\n",
      "Non-matching sequences: 246985\n",
      "Total sequences: 588289\n",
      "Percentage matching: 58.02%\n",
      "Percentage non-matching: 41.98%\n",
      "\n",
      "Matching sequences saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions.csv\n",
      "Non-matching sequences saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.csv\n",
      "\n",
      "=== MATCHING LABELS DISTRIBUTION ===\n",
      "Distribution of matching labels:\n",
      "predicted_gen_light_seq_label\n",
      "1    216186\n",
      "0    125118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SAMPLE OF MATCHING DATA ===\n",
      "   heavy_chain_number  gen_light_chain_number  predicted_gen_light_seq_label  \\\n",
      "0                   1                       1                              1   \n",
      "2                   1                       3                              1   \n",
      "3                   1                       4                              1   \n",
      "6                   1                       7                              1   \n",
      "7                   1                       8                              1   \n",
      "\n",
      "   predicted_input_heavy_seq_label  \n",
      "0                                1  \n",
      "2                                1  \n",
      "3                                1  \n",
      "6                                1  \n",
      "7                                1  \n",
      "\n",
      "=== NON-MATCHING LABELS DISTRIBUTION ===\n",
      "Light chain labels in non-matching:\n",
      "predicted_gen_light_seq_label\n",
      "0    233335\n",
      "1     13650\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Heavy chain labels in non-matching:\n",
      "predicted_input_heavy_seq_label\n",
      "1    233335\n",
      "0     13650\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SAMPLE OF NON-MATCHING DATA ===\n",
      "    heavy_chain_number  gen_light_chain_number  predicted_gen_light_seq_label  \\\n",
      "1                    1                       2                              0   \n",
      "4                    1                       5                              0   \n",
      "5                    1                       6                              0   \n",
      "14                   2                       5                              0   \n",
      "22                   3                       3                              0   \n",
      "\n",
      "    predicted_input_heavy_seq_label  \n",
      "1                                 1  \n",
      "4                                 1  \n",
      "5                                 1  \n",
      "14                                1  \n",
      "22                                1  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        heavy_chain_number  gen_light_chain_number  \\\n",
       " 0                        1                       1   \n",
       " 2                        1                       3   \n",
       " 3                        1                       4   \n",
       " 6                        1                       7   \n",
       " 7                        1                       8   \n",
       " ...                    ...                     ...   \n",
       " 588277               58838                       9   \n",
       " 588278               58838                      10   \n",
       " 588282               58839                       4   \n",
       " 588284               58839                       6   \n",
       " 588286               58839                       8   \n",
       " \n",
       "                                            true_light_seq  \\\n",
       " 0       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 2       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 3       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 6       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 7       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " ...                                                   ...   \n",
       " 588277  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       " 588278  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       " 588282  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588284  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588286  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " \n",
       "                                             gen_light_seq  \\\n",
       " 0       QSALTQPPSASGSPGQSVTISCTGTSSDIGGYNFVSWYQQHPGKAP...   \n",
       " 2       DIVMTQSPDSLAVSLGERATINCKSSQSVLYSPNNKNYLGWYQQKP...   \n",
       " 3       EIVLTQSPATLSLSPGERATLSCRASQSVGTYLAWYQQKPGQAPRL...   \n",
       " 6       QSALTQPPSASGSPGQSVTISCTGTSSDVGAYNYVSWYQQHPGKAP...   \n",
       " 7       QSVLTQPPSVSAAPGQRVTISCSGTSSNIGTNFVSWYQQFPGTAPK...   \n",
       " ...                                                   ...   \n",
       " 588277  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       " 588278  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       " 588282  DIQMTQSPSSLSASVGDRVTITCRASENIYSNLAWYQQKPGKAPKL...   \n",
       " 588284  DIVMTQSPLSLPVTPGEPASISCRSSQSLVHRNGYNYLDWYLQKPG...   \n",
       " 588286  EIVLTQSPGTLSLSPGERATLSCRASQSVSSNYLAWYQQKPGQAPR...   \n",
       " \n",
       "                                           input_heavy_seq  BLOSUM  similarity  \\\n",
       " 0       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   218.0   46.363636   \n",
       " 2       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   333.0   60.176991   \n",
       " 3       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   379.0   64.485981   \n",
       " 6       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   200.0   42.857143   \n",
       " 7       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   199.0   47.321429   \n",
       " ...                                                   ...     ...         ...   \n",
       " 588277  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTIYHWVRQAPGKGLE...   557.0  100.000000   \n",
       " 588278  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTIYHWVRQAPGKGLE...   557.0  100.000000   \n",
       " 588282  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   498.0   90.654206   \n",
       " 588284  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   301.0   55.357143   \n",
       " 588286  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   370.0   64.220183   \n",
       " \n",
       "         perplexity  label  predicted_true_light_seq_label  \\\n",
       " 0         2.466424      0                               1   \n",
       " 2         2.466424      0                               1   \n",
       " 3         2.466424      0                               1   \n",
       " 6         2.466424      0                               1   \n",
       " 7         2.466424      0                               1   \n",
       " ...            ...    ...                             ...   \n",
       " 588277    1.542342      0                               1   \n",
       " 588278    1.542342      0                               1   \n",
       " 588282    2.621815      0                               1   \n",
       " 588284    2.621815      0                               1   \n",
       " 588286    2.621815      0                               1   \n",
       " \n",
       "         predicted_gen_light_seq_label  predicted_input_heavy_seq_label  \n",
       " 0                                   1                                1  \n",
       " 2                                   1                                1  \n",
       " 3                                   1                                1  \n",
       " 6                                   1                                1  \n",
       " 7                                   1                                1  \n",
       " ...                               ...                              ...  \n",
       " 588277                              1                                1  \n",
       " 588278                              1                                1  \n",
       " 588282                              1                                1  \n",
       " 588284                              1                                1  \n",
       " 588286                              1                                1  \n",
       " \n",
       " [341304 rows x 12 columns],\n",
       "         heavy_chain_number  gen_light_chain_number  \\\n",
       " 1                        1                       2   \n",
       " 4                        1                       5   \n",
       " 5                        1                       6   \n",
       " 14                       2                       5   \n",
       " 22                       3                       3   \n",
       " ...                    ...                     ...   \n",
       " 588281               58839                       3   \n",
       " 588283               58839                       5   \n",
       " 588285               58839                       7   \n",
       " 588287               58839                       9   \n",
       " 588288               58839                      10   \n",
       " \n",
       "                                            true_light_seq  \\\n",
       " 1       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 4       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 5       DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       " 14      QSALTQPASVSGSPGQSITISCSGTSDDIGDYNYVSWYQQHPGKAP...   \n",
       " 22      DIQMTQSPSSLSAFMGDRVTITCRASQSPKTYLHWYQQRPGGVPKL...   \n",
       " ...                                                   ...   \n",
       " 588281  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588283  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588285  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588287  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " 588288  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       " \n",
       "                                             gen_light_seq  \\\n",
       " 1       SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...   \n",
       " 4       SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPVVV...   \n",
       " 5       SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...   \n",
       " 14      DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...   \n",
       " 22      EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...   \n",
       " ...                                                   ...   \n",
       " 588281  DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKP...   \n",
       " 588283  QSVLTQPPSVSGAPGQRVTISCTGSSSNIGAGYDVHWYQQLPGTAP...   \n",
       " 588285  EIVLTQSPGTLSLSPGERATLSCRASQSVSSTYLAWYQQKPGQAPR...   \n",
       " 588287  DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPG...   \n",
       " 588288  DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKP...   \n",
       " \n",
       "                                           input_heavy_seq  BLOSUM  similarity  \\\n",
       " 1       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   204.0   39.814815   \n",
       " 4       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   202.0   41.284404   \n",
       " 5       QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   210.0   44.444444   \n",
       " 14      QLQLQESGPGLVKPSETLSLICSVSGGSITTSSYYWAWIRQSPGKG...   231.0   48.672566   \n",
       " 22      EVQLVESGGDLVRPGGSLRLSCAASGFPFSRAWMTWVRQAPGKGLD...   332.0   59.259259   \n",
       " ...                                                   ...     ...         ...   \n",
       " 588281  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   339.0   61.946903   \n",
       " 588283  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   228.0   52.252252   \n",
       " 588285  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   389.0   67.592593   \n",
       " 588287  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   285.0   54.954955   \n",
       " 588288  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   325.0   61.607143   \n",
       " \n",
       "         perplexity  label  predicted_true_light_seq_label  \\\n",
       " 1         2.466424      0                               1   \n",
       " 4         2.466424      0                               1   \n",
       " 5         2.466424      0                               1   \n",
       " 14        2.674142      0                               1   \n",
       " 22        3.344425      0                               1   \n",
       " ...            ...    ...                             ...   \n",
       " 588281    2.621815      0                               1   \n",
       " 588283    2.621815      0                               1   \n",
       " 588285    2.621815      0                               1   \n",
       " 588287    2.621815      0                               1   \n",
       " 588288    2.621815      0                               1   \n",
       " \n",
       "         predicted_gen_light_seq_label  predicted_input_heavy_seq_label  \n",
       " 1                                   0                                1  \n",
       " 4                                   0                                1  \n",
       " 5                                   0                                1  \n",
       " 14                                  0                                1  \n",
       " 22                                  0                                1  \n",
       " ...                               ...                              ...  \n",
       " 588281                              0                                1  \n",
       " 588283                              0                                1  \n",
       " 588285                              0                                1  \n",
       " 588287                              0                                1  \n",
       " 588288                              0                                1  \n",
       " \n",
       " [246985 rows x 12 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions.csv\"\n",
    "matching_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions.csv\"\n",
    "non_matching_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.csv\"\n",
    "\n",
    "split_sequences_to_csv(input_csv_path, \n",
    "                       matching_csv_path=matching_csv_path, \n",
    "                       non_matching_csv_path=non_matching_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_matching_labels(input_csv_path: str, output_csv_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter sequences to keep only those where predicted_gen_light_label \n",
    "    and predicted_input_heavy_label are the same.\n",
    "    \n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file\n",
    "        output_csv_path (str, optional): Path for the filtered output CSV file.\n",
    "                                       If None, defaults to adding '_filtered' to input filename.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame containing only matching label sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(f\"Reading data from: {input_csv_path}\")\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Original columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_columns = ['predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    # Show distribution of labels before filtering\n",
    "    print(f\"\\n=== LABEL DISTRIBUTION BEFORE FILTERING ===\")\n",
    "    print(\"predicted_gen_light_seq_label distribution:\")\n",
    "    print(df['predicted_gen_light_seq_label'].value_counts())\n",
    "    print(\"\\predicted_input_heavy_seq_label distribution:\")\n",
    "    print(df['predicted_input_heavy_seq_label'].value_counts())\n",
    "    \n",
    "    # Filter sequences where both predicted labels match\n",
    "    filtered_df = df[df['predicted_gen_light_seq_label'] == df['predicted_input_heavy_seq_label']].copy()\n",
    "    \n",
    "    print(f\"\\n=== FILTERING RESULTS ===\")\n",
    "    print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "    print(f\"Sequences removed: {len(df) - len(filtered_df)}\")\n",
    "    print(f\"Sequences kept: {len(filtered_df)}\")\n",
    "    print(f\"Percentage kept: {(len(filtered_df) / len(df)) * 100:.2f}%\")\n",
    "    \n",
    "    # Show distribution of matching labels\n",
    "    if len(filtered_df) > 0:\n",
    "        print(f\"\\n=== MATCHING LABELS DISTRIBUTION ===\")\n",
    "        print(\"Distribution of matching labels:\")\n",
    "        print(filtered_df['predicted_gen_light_seq_label'].value_counts())\n",
    "        \n",
    "        # Show some examples of the filtered data\n",
    "        print(f\"\\n=== SAMPLE OF FILTERED DATA ===\")\n",
    "        print(filtered_df[['heavy_chain_number', 'gen_light_chain_number', \n",
    "                          'predicted_gen_light_seq_label', 'predicted_input_heavy_seq_label']].head(10))\n",
    "    else:\n",
    "        print(\"WARNING: No sequences found with matching labels!\")\n",
    "    \n",
    "    # Save filtered data to CSV\n",
    "    if output_csv_path is None:\n",
    "        # Create default output filename\n",
    "        if input_csv_path.endswith('.csv'):\n",
    "            output_csv_path = input_csv_path.replace('.csv', '_filtered.csv')\n",
    "        else:\n",
    "            output_csv_path = input_csv_path + '_filtered.csv'\n",
    "    \n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nFiltered data saved to: {output_csv_path}\")\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81bc4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_label_mismatches(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze sequences where labels don't match to understand the differences.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Original DataFrame with all sequences\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing only mismatched sequences\n",
    "    \"\"\"\n",
    "    mismatched_df = df[df['predicted_gen_light_label'] != df['predicted_input_heavy_label']].copy()\n",
    "    \n",
    "    print(f\"\\n=== MISMATCH ANALYSIS ===\")\n",
    "    print(f\"Number of mismatched sequences: {len(mismatched_df)}\")\n",
    "    \n",
    "    if len(mismatched_df) > 0:\n",
    "        print(\"\\nMismatch patterns:\")\n",
    "        mismatch_patterns = mismatched_df.groupby(['predicted_gen_light_label', 'predicted_input_heavy_label']).size()\n",
    "        for (gen_label, heavy_label), count in mismatch_patterns.items():\n",
    "            print(f\"  Gen Light: {gen_label} vs Input Heavy: {heavy_label} -> {count} sequences\")\n",
    "        \n",
    "        print(\"\\nSample of mismatched sequences:\")\n",
    "        print(mismatched_df[['heavy_chain_number', 'gen_light_chain_number', \n",
    "                            'predicted_gen_light_label', 'predicted_input_heavy_label', \n",
    "                            'BLOSUM', 'similarity']].head())\n",
    "    \n",
    "    return mismatched_df\n",
    "\n",
    "def get_filtering_statistics(original_df: pd.DataFrame, filtered_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Generate detailed statistics about the filtering process.\n",
    "    \n",
    "    Args:\n",
    "        original_df (pd.DataFrame): Original DataFrame\n",
    "        filtered_df (pd.DataFrame): Filtered DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing filtering statistics\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'original_count': len(original_df),\n",
    "        'filtered_count': len(filtered_df),\n",
    "        'removed_count': len(original_df) - len(filtered_df),\n",
    "        'retention_rate': (len(filtered_df) / len(original_df)) * 100 if len(original_df) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Statistics by heavy chain\n",
    "    heavy_chains_original = original_df['heavy_chain_number'].unique()\n",
    "    heavy_chains_filtered = filtered_df['heavy_chain_number'].unique()\n",
    "    \n",
    "    stats['heavy_chains_original'] = len(heavy_chains_original)\n",
    "    stats['heavy_chains_retained'] = len(heavy_chains_filtered)\n",
    "    \n",
    "    # Average scores comparison\n",
    "    if len(filtered_df) > 0:\n",
    "        stats['avg_blosum_original'] = original_df['BLOSUM'].mean()\n",
    "        stats['avg_blosum_filtered'] = filtered_df['BLOSUM'].mean()\n",
    "        stats['avg_similarity_original'] = original_df['similarity'].mean()\n",
    "        stats['avg_similarity_filtered'] = filtered_df['similarity'].mean()\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f466d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_eval_generate_multiple_light_seqs_203276_10k_predictions.csv\n",
      "Original dataset shape: (107229, 11)\n",
      "Original columns: ['heavy_chain_number', 'gen_light_chain_number', 'true_light_seq', 'gen_light_seq', 'input_heavy_seq', 'BLOSUM', 'similarity', 'perplexity', 'label', 'predicted_input_heavy_label', 'predicted_gen_light_label']\n",
      "\n",
      "=== LABEL DISTRIBUTION BEFORE FILTERING ===\n",
      "predicted_gen_light_label distribution:\n",
      "predicted_gen_light_label\n",
      "0    71959\n",
      "1    35270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "predicted_input_heavy_label distribution:\n",
      "predicted_input_heavy_label\n",
      "1    84509\n",
      "0    22720\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== FILTERING RESULTS ===\n",
      "Filtered dataset shape: (53544, 11)\n",
      "Sequences removed: 53685\n",
      "Sequences kept: 53544\n",
      "Percentage kept: 49.93%\n",
      "\n",
      "=== MATCHING LABELS DISTRIBUTION ===\n",
      "Distribution of matching labels:\n",
      "predicted_gen_light_label\n",
      "1    33047\n",
      "0    20497\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SAMPLE OF FILTERED DATA ===\n",
      "    heavy_chain_number  gen_light_chain_number  predicted_gen_light_label  \\\n",
      "0                    1                       1                          1   \n",
      "2                    1                       3                          1   \n",
      "3                    1                       4                          1   \n",
      "6                    1                       7                          1   \n",
      "7                    1                       8                          1   \n",
      "8                    1                       9                          1   \n",
      "9                    1                      10                          1   \n",
      "10                   2                       1                          1   \n",
      "11                   2                       2                          1   \n",
      "12                   2                       3                          1   \n",
      "\n",
      "    predicted_input_heavy_label  \n",
      "0                             1  \n",
      "2                             1  \n",
      "3                             1  \n",
      "6                             1  \n",
      "7                             1  \n",
      "8                             1  \n",
      "9                             1  \n",
      "10                            1  \n",
      "11                            1  \n",
      "12                            1  \n",
      "\n",
      "Filtered data saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_full_eval_generate_multiple_light_seqs_203276_10k_predictions.csv\n",
      "\n",
      "=== MISMATCH ANALYSIS ===\n",
      "Number of mismatched sequences: 53685\n",
      "\n",
      "Mismatch patterns:\n",
      "  Gen Light: 0 vs Input Heavy: 1 -> 51462 sequences\n",
      "  Gen Light: 1 vs Input Heavy: 0 -> 2223 sequences\n",
      "\n",
      "Sample of mismatched sequences:\n",
      "    heavy_chain_number  gen_light_chain_number  predicted_gen_light_label  \\\n",
      "1                    1                       2                          0   \n",
      "4                    1                       5                          0   \n",
      "5                    1                       6                          0   \n",
      "14                   2                       5                          0   \n",
      "22                   3                       3                          0   \n",
      "\n",
      "    predicted_input_heavy_label  BLOSUM  similarity  \n",
      "1                             1   204.0   39.814815  \n",
      "4                             1   202.0   41.284404  \n",
      "5                             1   210.0   44.444444  \n",
      "14                            1   231.0   48.672566  \n",
      "22                            1   332.0   59.259259  \n",
      "\n",
      "=== DETAILED STATISTICS ===\n",
      "Original sequences: 107229\n",
      "Filtered sequences: 53544\n",
      "Removed sequences: 53685\n",
      "Retention rate: 49.93%\n",
      "Heavy chains in original: 10723\n",
      "Heavy chains retained: 9612\n",
      "\n",
      "Average BLOSUM score (original): 312.48\n",
      "Average BLOSUM score (filtered): 311.78\n",
      "Average similarity (original): 60.03%\n",
      "Average similarity (filtered): 60.07%\n"
     ]
    }
   ],
   "source": [
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_eval_generate_multiple_light_seqs_203267_predictions.csv\"  \n",
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_eval_generate_multiple_light_seqs_203276_10k_predictions.csv\"  \n",
    "\n",
    "output_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_full_eval_generate_multiple_light_seqs_203276_10k_predictions.csv\"  \n",
    "\n",
    "# Filter the data\n",
    "filtered_df = filter_matching_labels(input_file, output_file)\n",
    "        \n",
    "# Read original data for comparison\n",
    "original_df = pd.read_csv(input_file)\n",
    "        \n",
    "# Analyze mismatches\n",
    "mismatched_df = analyze_label_mismatches(original_df)\n",
    "        \n",
    "# Get detailed statistics\n",
    "stats = get_filtering_statistics(original_df, filtered_df)\n",
    "        \n",
    "print(f\"\\n=== DETAILED STATISTICS ===\")\n",
    "print(f\"Original sequences: {stats['original_count']}\")\n",
    "print(f\"Filtered sequences: {stats['filtered_count']}\")\n",
    "print(f\"Removed sequences: {stats['removed_count']}\")\n",
    "print(f\"Retention rate: {stats['retention_rate']:.2f}%\")\n",
    "print(f\"Heavy chains in original: {stats['heavy_chains_original']}\")\n",
    "print(f\"Heavy chains retained: {stats['heavy_chains_retained']}\")\n",
    "        \n",
    "if 'avg_blosum_original' in stats:\n",
    "    print(f\"\\nAverage BLOSUM score (original): {stats['avg_blosum_original']:.2f}\")\n",
    "    print(f\"Average BLOSUM score (filtered): {stats['avg_blosum_filtered']:.2f}\")\n",
    "    print(f\"Average similarity (original): {stats['avg_similarity_original']:.2f}%\")\n",
    "    print(f\"Average similarity (filtered): {stats['avg_similarity_filtered']:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7bbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def csv_to_fasta(csv_file_path: str, output_fasta_path: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Convert CSV antibody data to FASTA format.\n",
    "    \n",
    "    For each heavy chain:\n",
    "    1. Heavy chain sequence\n",
    "    2. True light chain sequence  \n",
    "    3. All generated light chain sequences\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the input CSV file\n",
    "        output_fasta_path (str, optional): Path for output FASTA file.\n",
    "                                         If None, uses input filename with .fasta extension\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(f\"Reading data from: {csv_file_path}\")\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_columns = ['heavy_chain_number', 'gen_light_chain_number', \n",
    "                       'true_light_seq', 'gen_light_seq', 'input_heavy_seq']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    # Group data by heavy chain\n",
    "    heavy_chain_data = defaultdict(lambda: {\n",
    "        'input_heavy_seq': '',\n",
    "        'true_light_seq': '',\n",
    "        'generated_sequences': []\n",
    "    })\n",
    "    \n",
    "    # Process each row\n",
    "    for _, row in df.iterrows():\n",
    "        heavy_chain_num = row['heavy_chain_number']\n",
    "        \n",
    "        # Store heavy chain and true light sequences (they should be the same for all rows of same heavy chain)\n",
    "        heavy_chain_data[heavy_chain_num]['input_heavy_seq'] = row['input_heavy_seq']\n",
    "        heavy_chain_data[heavy_chain_num]['true_light_seq'] = row['true_light_seq']\n",
    "        \n",
    "        # Add generated sequence with its number\n",
    "        heavy_chain_data[heavy_chain_num]['generated_sequences'].append({\n",
    "            'gen_number': row['gen_light_chain_number'],\n",
    "            'sequence': row['gen_light_seq']\n",
    "        })\n",
    "    \n",
    "    # Sort generated sequences by generation number for each heavy chain\n",
    "    for heavy_chain_num in heavy_chain_data:\n",
    "        heavy_chain_data[heavy_chain_num]['generated_sequences'].sort(\n",
    "            key=lambda x: x['gen_number']\n",
    "        )\n",
    "    \n",
    "    # Generate output filename if not provided\n",
    "    if output_fasta_path is None:\n",
    "        if csv_file_path.endswith('.csv'):\n",
    "            output_fasta_path = csv_file_path.replace('.csv', '.fasta')\n",
    "        else:\n",
    "            output_fasta_path = csv_file_path + '.fasta'\n",
    "    \n",
    "    # Write FASTA file\n",
    "    print(f\"Writing FASTA file to: {output_fasta_path}\")\n",
    "    \n",
    "    with open(output_fasta_path, 'w') as fasta_file:\n",
    "        # Process heavy chains in sorted order\n",
    "        for heavy_chain_num in sorted(heavy_chain_data.keys()):\n",
    "            data = heavy_chain_data[heavy_chain_num]\n",
    "            \n",
    "            # Write heavy chain sequence\n",
    "            fasta_file.write(f\">heavy_chain_{heavy_chain_num}\\n\")\n",
    "            fasta_file.write(f\"{data['input_heavy_seq']}\\n\")\n",
    "            \n",
    "            # Write true light chain sequence\n",
    "            fasta_file.write(f\">true_light_chain_heavy_chain_{heavy_chain_num}\\n\")\n",
    "            fasta_file.write(f\"{data['true_light_seq']}\\n\")\n",
    "            \n",
    "            # Write all generated light chain sequences\n",
    "            for gen_data in data['generated_sequences']:\n",
    "                fasta_file.write(f\">gen_light_{gen_data['gen_number']}_heavy_chain_{heavy_chain_num}\\n\")\n",
    "                fasta_file.write(f\"{gen_data['sequence']}\\n\")\n",
    "    \n",
    "    # Print summary\n",
    "    total_sequences = 0\n",
    "    heavy_chains_processed = len(heavy_chain_data)\n",
    "    \n",
    "    for heavy_chain_num, data in heavy_chain_data.items():\n",
    "        gen_count = len(data['generated_sequences'])\n",
    "        total_sequences += 2 + gen_count  # heavy + true light + generated sequences\n",
    "        print(f\"Heavy chain {heavy_chain_num}: 1 heavy + 1 true light + {gen_count} generated = {2 + gen_count} sequences\")\n",
    "    \n",
    "    print(f\"\\n=== FASTA GENERATION SUMMARY ===\")\n",
    "    print(f\"Heavy chains processed: {heavy_chains_processed}\")\n",
    "    print(f\"Total sequences written: {total_sequences}\")\n",
    "    print(f\"FASTA file saved to: {output_fasta_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1456f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_fasta_output(fasta_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Validate the generated FASTA file by reading and analyzing it.\n",
    "    \n",
    "    Args:\n",
    "        fasta_file_path (str): Path to the FASTA file to validate\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== VALIDATING FASTA FILE ===\")\n",
    "    \n",
    "    sequence_counts = defaultdict(int)\n",
    "    heavy_chains_found = set()\n",
    "    \n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        current_header = None\n",
    "        sequence_count = 0\n",
    "        \n",
    "        for line in fasta_file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                current_header = line[1:]  # Remove '>'\n",
    "                sequence_count += 1\n",
    "                \n",
    "                # Parse header to categorize\n",
    "                if current_header.startswith('heavy_chain_'):\n",
    "                    sequence_counts['heavy_chains'] += 1\n",
    "                    heavy_chain_num = current_header.split('_')[-1]\n",
    "                    heavy_chains_found.add(int(heavy_chain_num))\n",
    "                elif current_header.startswith('true_light_chain_'):\n",
    "                    sequence_counts['true_light_chains'] += 1\n",
    "                elif current_header.startswith('gen_light_'):\n",
    "                    sequence_counts['generated_light_chains'] += 1\n",
    "    \n",
    "    print(f\"Total sequences in FASTA: {sequence_count}\")\n",
    "    print(f\"Heavy chains: {sequence_counts['heavy_chains']}\")\n",
    "    print(f\"True light chains: {sequence_counts['true_light_chains']}\")\n",
    "    print(f\"Generated light chains: {sequence_counts['generated_light_chains']}\")\n",
    "    print(f\"Heavy chain numbers found: {sorted(heavy_chains_found)}\")\n",
    "    \n",
    "    # Check consistency\n",
    "    if sequence_counts['heavy_chains'] == sequence_counts['true_light_chains']:\n",
    "        print(\"✓ Each heavy chain has a corresponding true light chain\")\n",
    "    else:\n",
    "        print(\"✗ Mismatch between heavy chains and true light chains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2475441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_fasta_with_metadata(csv_file_path: str, output_fasta_path: str = None, \n",
    "                              include_scores: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Create FASTA file with optional metadata in headers.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the input CSV file\n",
    "        output_fasta_path (str, optional): Path for output FASTA file\n",
    "        include_scores (bool): Whether to include BLOSUM and similarity scores in headers\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Group data by heavy chain\n",
    "    heavy_chain_data = defaultdict(lambda: {\n",
    "        'input_heavy_seq': '',\n",
    "        'true_light_seq': '',\n",
    "        'generated_sequences': []\n",
    "    })\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        heavy_chain_num = row['heavy_chain_number']\n",
    "        \n",
    "        heavy_chain_data[heavy_chain_num]['input_heavy_seq'] = row['input_heavy_seq']\n",
    "        heavy_chain_data[heavy_chain_num]['true_light_seq'] = row['true_light_seq']\n",
    "        \n",
    "        # Include metadata if requested\n",
    "        gen_info = {\n",
    "            'gen_number': row['gen_light_chain_number'],\n",
    "            'sequence': row['gen_light_seq']\n",
    "        }\n",
    "        \n",
    "        if include_scores and 'BLOSUM' in df.columns and 'similarity' in df.columns:\n",
    "            gen_info['blosum'] = row['BLOSUM']\n",
    "            gen_info['similarity'] = row['similarity']\n",
    "        \n",
    "        heavy_chain_data[heavy_chain_num]['generated_sequences'].append(gen_info)\n",
    "    \n",
    "    # Sort generated sequences\n",
    "    for heavy_chain_num in heavy_chain_data:\n",
    "        heavy_chain_data[heavy_chain_num]['generated_sequences'].sort(\n",
    "            key=lambda x: x['gen_number']\n",
    "        )\n",
    "    \n",
    "    # Generate output filename\n",
    "    if output_fasta_path is None:\n",
    "        suffix = '_with_scores.fasta' if include_scores else '.fasta'\n",
    "        if csv_file_path.endswith('.csv'):\n",
    "            output_fasta_path = csv_file_path.replace('.csv', suffix)\n",
    "        else:\n",
    "            output_fasta_path = csv_file_path + suffix\n",
    "    \n",
    "    # Write FASTA file\n",
    "    with open(output_fasta_path, 'w') as fasta_file:\n",
    "        for heavy_chain_num in sorted(heavy_chain_data.keys()):\n",
    "            data = heavy_chain_data[heavy_chain_num]\n",
    "            \n",
    "            # Heavy chain\n",
    "            fasta_file.write(f\">heavy_chain_{heavy_chain_num}\\n\")\n",
    "            fasta_file.write(f\"{data['input_heavy_seq']}\\n\")\n",
    "            \n",
    "            # True light chain\n",
    "            fasta_file.write(f\">true_light_chain_heavy_chain_{heavy_chain_num}\\n\")\n",
    "            fasta_file.write(f\"{data['true_light_seq']}\\n\")\n",
    "            \n",
    "            # Generated sequences\n",
    "            for gen_data in data['generated_sequences']:\n",
    "                if include_scores and 'blosum' in gen_data:\n",
    "                    header = f\">gen_light_{gen_data['gen_number']}_heavy_chain_{heavy_chain_num}_BLOSUM_{gen_data['blosum']}_similarity_{gen_data['similarity']:.2f}\"\n",
    "                else:\n",
    "                    header = f\">gen_light_{gen_data['gen_number']}_heavy_chain_{heavy_chain_num}\"\n",
    "                \n",
    "                fasta_file.write(f\"{header}\\n\")\n",
    "                fasta_file.write(f\"{gen_data['sequence']}\\n\")\n",
    "    \n",
    "    print(f\"FASTA file with {'metadata' if include_scores else 'standard format'} saved to: {output_fasta_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5aa23bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file with standard format saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.fasta\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.csv\"  \n",
    "  \n",
    "output_path =  \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs\"\n",
    "\n",
    "# Optional: Generate FASTA with scores in headers\n",
    "create_fasta_with_metadata(input_file, include_scores=False, \n",
    "                            output_fasta_path=f\"{output_path}/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e61793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file with standard format saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_full_eval_generate_multiple_light_seqs_203276_10k_predictions.fasta\n"
     ]
    }
   ],
   "source": [
    " # Input CSV file path \n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267.csv\"\n",
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_full_eval_generate_multiple_light_seqs_203276_10k_predictions.csv\"  \n",
    "  \n",
    "output_path =  \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy\"\n",
    "\n",
    "# Optional: Generate FASTA with scores in headers\n",
    "create_fasta_with_metadata(input_file, include_scores=False, \n",
    "                            output_fasta_path=f\"{output_path}/matching_prediction_full_eval_generate_multiple_light_seqs_203276_10k_predictions.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daff0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c88a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_record(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse a single JSON record and extract all required fields.\n",
    "    \n",
    "    Args:\n",
    "        data (Dict[str, Any]): Single JSON record\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Parsed record with extracted fields\n",
    "    \"\"\"\n",
    "    \n",
    "    record = {}\n",
    "    \n",
    "    # Basic fields\n",
    "    record['sequence_id'] = data.get('Sequence ID', '')\n",
    "    record['raw_sequence'] = data.get('Raw Sequence', '')\n",
    "    record['sequence_length'] = data.get('Sequence Length', 0)\n",
    "    record['domain_classification'] = data.get('Domain Classification', '')\n",
    "    record['nt_trimmed'] = data.get('NT-Trimmed', '')\n",
    "    \n",
    "    # Extract first hit information\n",
    "    hits = data.get('Hits', [])\n",
    "    if hits and len(hits) > 0:\n",
    "        first_hit = hits[0]\n",
    "        record['first_hit_gene'] = first_hit.get('gene', '')\n",
    "        record['first_hit_bit_score'] = first_hit.get('bit_score', 0.0)\n",
    "        record['first_hit_e_value'] = first_hit.get('e_value', 0.0)\n",
    "        \n",
    "        # Extract gene name (before the first space or \"unnamed\")\n",
    "        gene_full = first_hit.get('gene', '')\n",
    "        gene_name = extract_gene_name(gene_full)\n",
    "        record['gene_name'] = gene_name\n",
    "        \n",
    "        # Extract light locus\n",
    "        record['light_locus'] = extract_light_locus(gene_name)\n",
    "    else:\n",
    "        record['first_hit_gene'] = ''\n",
    "        record['first_hit_bit_score'] = 0.0\n",
    "        record['first_hit_e_value'] = 0.0\n",
    "        record['gene_name'] = ''\n",
    "        record['light_locus'] = ''\n",
    "    \n",
    "    # Extract region sequences\n",
    "    regions = ['FR1', 'CDR1', 'FR2', 'CDR2', 'FR3', 'CDR3']\n",
    "    \n",
    "    for region in regions:\n",
    "        region_data = data.get(region, {})\n",
    "        if isinstance(region_data, dict):\n",
    "            # Extract AA sequence\n",
    "            aa_seq = region_data.get('AA', '')\n",
    "            record[f'{region}_sequence'] = aa_seq\n",
    "            \n",
    "            # Extract additional region information\n",
    "            record[f'{region}_length'] = region_data.get('length', 0.0)\n",
    "            record[f'{region}_percent_identity'] = region_data.get('percent identity', 0.0)\n",
    "            record[f'{region}_matches'] = region_data.get('matches', 0.0)\n",
    "            record[f'{region}_mismatches'] = region_data.get('mismatches', 0.0)\n",
    "            record[f'{region}_gaps'] = region_data.get('gaps', 0.0)\n",
    "        else:\n",
    "            # Handle case where region data might be missing or malformed\n",
    "            record[f'{region}_sequence'] = ''\n",
    "            record[f'{region}_length'] = 0.0\n",
    "            record[f'{region}_percent_identity'] = 0.0\n",
    "            record[f'{region}_matches'] = 0.0\n",
    "            record[f'{region}_mismatches'] = 0.0\n",
    "            record[f'{region}_gaps'] = 0.0\n",
    "    \n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1080b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_antibody_json_to_csv(json_file_path: str, output_csv_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse JSON file with antibody analysis data and convert to CSV format.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the input JSON file\n",
    "        output_csv_path (str, optional): Path for output CSV file.\n",
    "                                       If None, uses input filename with .csv extension\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Parsed data as DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Reading JSON data from: {json_file_path}\")\n",
    "    \n",
    "    # Read JSON file line by line (each line is a separate JSON object)\n",
    "    parsed_data = []\n",
    "    \n",
    "    with open(json_file_path, 'r') as file:\n",
    "        for line_num, line in enumerate(file, 1):\n",
    "            line = line.strip()\n",
    "            if not line:  # Skip empty lines\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Parse JSON object from line\n",
    "                data = json.loads(line)\n",
    "                parsed_record = parse_single_record(data)\n",
    "                parsed_data.append(parsed_record)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Could not parse line {line_num}: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing line {line_num}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Successfully parsed {len(parsed_data)} records\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    # Generate output filename if not provided\n",
    "    if output_csv_path is None:\n",
    "        if json_file_path.endswith('.json'):\n",
    "            output_csv_path = json_file_path.replace('.json', '.csv')\n",
    "        else:\n",
    "            output_csv_path = json_file_path + '.csv'\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"CSV file saved to: {output_csv_path}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n=== PARSING SUMMARY ===\")\n",
    "    print(f\"Total records processed: {len(df)}\")\n",
    "    print(f\"Columns created: {len(df.columns)}\")\n",
    "    print(f\"Column names: {list(df.columns)}\")\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        print(f\"\\n=== SAMPLE DATA ===\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Show locus distribution\n",
    "        if 'light_locus' in df.columns:\n",
    "            print(f\"\\n=== LIGHT LOCUS DISTRIBUTION ===\")\n",
    "            print(df['light_locus'].value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5400d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gene_name(gene_full: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract gene name from full gene description.\n",
    "    \n",
    "    Examples:\n",
    "    \"IGLV1-51*01 unnamed protein product\" -> \"IGLV1-51*01\"\n",
    "    \"IGKV3-20*01 immunoglobulin kappa\" -> \"IGKV3-20*01\"\n",
    "    \n",
    "    Args:\n",
    "        gene_full (str): Full gene description\n",
    "        \n",
    "    Returns:\n",
    "        str: Extracted gene name\n",
    "    \"\"\"\n",
    "    if not gene_full:\n",
    "        return ''\n",
    "    \n",
    "    # Split by space and take the first part (before \"unnamed\" or other descriptors)\n",
    "    parts = gene_full.split()\n",
    "    if parts:\n",
    "        return parts[0]\n",
    "    return gene_full\n",
    "\n",
    "def extract_light_locus(gene_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract light chain locus from gene name.\n",
    "    \n",
    "    Args:\n",
    "        gene_name (str): Gene name (e.g., \"IGLV1-51*01\")\n",
    "        \n",
    "    Returns:\n",
    "        str: Light locus (\"IGL\", \"IGK\", or \"\")\n",
    "    \"\"\"\n",
    "    if not gene_name:\n",
    "        return ''\n",
    "    \n",
    "    # Check for common light chain patterns\n",
    "    if gene_name.startswith('IGL'):\n",
    "        return 'IGL'\n",
    "    elif gene_name.startswith('IGK'):\n",
    "        return 'IGK'\n",
    "    elif gene_name.startswith('IGKV'):\n",
    "        return 'IGK'\n",
    "    elif gene_name.startswith('IGLV'):\n",
    "        return 'IGL'\n",
    "    \n",
    "    return ''\n",
    "\n",
    "def analyze_parsed_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Analyze the parsed data and provide detailed statistics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Parsed antibody data\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== DETAILED ANALYSIS ===\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Total sequences: {len(df)}\")\n",
    "    print(f\"Unique sequence IDs: {df['sequence_id'].nunique()}\")\n",
    "    \n",
    "    # Sequence length statistics\n",
    "    if 'sequence_length' in df.columns:\n",
    "        print(f\"Average sequence length: {df['sequence_length'].mean():.1f}\")\n",
    "        print(f\"Min sequence length: {df['sequence_length'].min()}\")\n",
    "        print(f\"Max sequence length: {df['sequence_length'].max()}\")\n",
    "    \n",
    "    # Light locus distribution\n",
    "    if 'light_locus' in df.columns:\n",
    "        print(f\"\\nLight locus distribution:\")\n",
    "        locus_counts = df['light_locus'].value_counts()\n",
    "        for locus, count in locus_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"  {locus}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Gene name patterns\n",
    "    if 'gene_name' in df.columns:\n",
    "        print(f\"\\nTop 10 most common genes:\")\n",
    "        top_genes = df['gene_name'].value_counts().head(10)\n",
    "        for gene, count in top_genes.items():\n",
    "            print(f\"  {gene}: {count}\")\n",
    "    \n",
    "    # Region sequence lengths\n",
    "    regions = ['FR1', 'CDR1', 'FR2', 'CDR2', 'FR3', 'CDR3']\n",
    "    print(f\"\\nAverage region lengths:\")\n",
    "    for region in regions:\n",
    "        length_col = f'{region}_length'\n",
    "        if length_col in df.columns:\n",
    "            avg_length = df[length_col].mean()\n",
    "            print(f\"  {region}: {avg_length:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b7cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simplified_csv(df: pd.DataFrame, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a simplified CSV with only the most important columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Full parsed data\n",
    "        output_path (str): Output path for simplified CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select key columns\n",
    "    key_columns = [\n",
    "        'sequence_id', 'raw_sequence', 'gene_name', 'light_locus',\n",
    "        'FR1_sequence', 'CDR1_sequence', 'FR2_sequence', \n",
    "        'CDR2_sequence', 'FR3_sequence', 'CDR3_sequence',\n",
    "        'nt_trimmed'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only existing columns\n",
    "    available_columns = [col for col in key_columns if col in df.columns]\n",
    "    simplified_df = df[available_columns].copy()\n",
    "    \n",
    "    # Save simplified version\n",
    "    simplified_df.to_csv(output_path, index=False)\n",
    "    print(f\"Simplified CSV saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41eac7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading JSON data from: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.json\n",
      "Successfully parsed 339147 records\n",
      "CSV file saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\n",
      "\n",
      "=== PARSING SUMMARY ===\n",
      "Total records processed: 339147\n",
      "Columns created: 46\n",
      "Column names: ['sequence_id', 'raw_sequence', 'sequence_length', 'domain_classification', 'nt_trimmed', 'first_hit_gene', 'first_hit_bit_score', 'first_hit_e_value', 'gene_name', 'light_locus', 'FR1_sequence', 'FR1_length', 'FR1_percent_identity', 'FR1_matches', 'FR1_mismatches', 'FR1_gaps', 'CDR1_sequence', 'CDR1_length', 'CDR1_percent_identity', 'CDR1_matches', 'CDR1_mismatches', 'CDR1_gaps', 'FR2_sequence', 'FR2_length', 'FR2_percent_identity', 'FR2_matches', 'FR2_mismatches', 'FR2_gaps', 'CDR2_sequence', 'CDR2_length', 'CDR2_percent_identity', 'CDR2_matches', 'CDR2_mismatches', 'CDR2_gaps', 'FR3_sequence', 'FR3_length', 'FR3_percent_identity', 'FR3_matches', 'FR3_mismatches', 'FR3_gaps', 'CDR3_sequence', 'CDR3_length', 'CDR3_percent_identity', 'CDR3_matches', 'CDR3_mismatches', 'CDR3_gaps']\n",
      "\n",
      "=== SAMPLE DATA ===\n",
      "                    sequence_id  \\\n",
      "0   gen_light_4_heavy_chain_203   \n",
      "1   gen_light_6_heavy_chain_203   \n",
      "2   gen_light_8_heavy_chain_203   \n",
      "3  gen_light_10_heavy_chain_203   \n",
      "4               heavy_chain_204   \n",
      "\n",
      "                                        raw_sequence  sequence_length  \\\n",
      "0  DIQMTQSPSSLSASVGDRVTITCRASQGINNYLAWYQQKPGKAPKS...              107   \n",
      "1  DIQMTQSPSSLSASVGDRVTITCRASQSISNYLNWYQQKAGKAPKL...              108   \n",
      "2  DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPNL...              107   \n",
      "3  DIQLTQSPSFLSASVGDRVTITCRASQGITSYLAWYQQKPGKAPKL...              107   \n",
      "4  QVQLVESGGGVVQPGRSLRLFCAASGFSFSSYAMYWVRQAPGKGLE...              125   \n",
      "\n",
      "  domain_classification                                         nt_trimmed  \\\n",
      "0                  imgt  DIQMTQSPSSLSASVGDRVTITCRASQGINNYLAWYQQKPGKAPKS...   \n",
      "1                  imgt  DIQMTQSPSSLSASVGDRVTITCRASQSISNYLNWYQQKAGKAPKL...   \n",
      "2                  imgt  DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPNL...   \n",
      "3                  imgt  DIQLTQSPSFLSASVGDRVTITCRASQGITSYLAWYQQKPGKAPKL...   \n",
      "4                  imgt  QVQLVESGGGVVQPGRSLRLFCAASGFSFSSYAMYWVRQAPGKGLE...   \n",
      "\n",
      "                        first_hit_gene  first_hit_bit_score  \\\n",
      "0  IGKV1-16*02 unnamed protein product                189.0   \n",
      "1  IGKV1-39*01 unnamed protein product                187.0   \n",
      "2   IGKV1-5*03 unnamed protein product                186.0   \n",
      "3   IGKV1-9*01 unnamed protein product                188.0   \n",
      "4  IGHV3-30*15 unnamed protein product                181.0   \n",
      "\n",
      "   first_hit_e_value    gene_name light_locus  ... FR3_percent_identity  \\\n",
      "0       2.000000e-66  IGKV1-16*02         IGK  ...                100.0   \n",
      "1       7.000000e-66  IGKV1-39*01         IGK  ...                100.0   \n",
      "2       1.000000e-65   IGKV1-5*03         IGK  ...                 91.7   \n",
      "3       4.000000e-66   IGKV1-9*01         IGK  ...                100.0   \n",
      "4       3.000000e-63  IGHV3-30*15              ...                 89.5   \n",
      "\n",
      "   FR3_matches  FR3_mismatches  FR3_gaps  CDR3_sequence  CDR3_length  \\\n",
      "0         36.0             0.0       0.0                         7.0   \n",
      "1         36.0             0.0       0.0                         7.0   \n",
      "2         33.0             3.0       0.0                         7.0   \n",
      "3         36.0             0.0       0.0                         7.0   \n",
      "4         34.0             4.0       0.0                         1.0   \n",
      "\n",
      "  CDR3_percent_identity  CDR3_matches  CDR3_mismatches  CDR3_gaps  \n",
      "0                  85.7           6.0              1.0        0.0  \n",
      "1                 100.0           7.0              0.0        0.0  \n",
      "2                  85.7           6.0              1.0        0.0  \n",
      "3                  71.4           5.0              2.0        0.0  \n",
      "4                 100.0           1.0              0.0        0.0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "\n",
      "=== LIGHT LOCUS DISTRIBUTION ===\n",
      "light_locus\n",
      "IGK    194801\n",
      "IGL     98263\n",
      "        46083\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DETAILED ANALYSIS ===\n",
      "Total sequences: 339147\n",
      "Unique sequence IDs: 339147\n",
      "Average sequence length: 111.4\n",
      "Min sequence length: 70\n",
      "Max sequence length: 214\n",
      "\n",
      "Light locus distribution:\n",
      "  IGK: 194801 (57.4%)\n",
      "  IGL: 98263 (29.0%)\n",
      "  : 46083 (13.6%)\n",
      "\n",
      "Top 10 most common genes:\n",
      "  IGKV3-20*01: 38546\n",
      "  IGKV1-27*01: 25600\n",
      "  IGKV1-39*01: 22600\n",
      "  IGKV3-15*01: 19061\n",
      "  IGKV2-28*01: 16495\n",
      "  IGKV3-11*01: 13580\n",
      "  IGKV1-5*03: 12466\n",
      "  IGLV2-14*03: 10735\n",
      "  IGLV1-40*01: 9408\n",
      "  IGLV2-8*01: 7595\n",
      "\n",
      "Average region lengths:\n",
      "  FR1: 25.4\n",
      "  CDR1: 8.0\n",
      "  FR2: 17.0\n",
      "  CDR2: 3.7\n",
      "  FR3: 36.3\n",
      "  CDR3: 6.6\n"
     ]
    }
   ],
   "source": [
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267.json\"  \n",
    "\n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions.json\"\n",
    "#output_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\"    \n",
    "\n",
    "\n",
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions.json\"\n",
    "output_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\"    \n",
    "\n",
    "    \n",
    "# Parse JSON to CSV\n",
    "df = parse_antibody_json_to_csv(input_file, \n",
    "                                 output_csv_path=output_csv_path)\n",
    "        \n",
    "# Analyze the parsed data\n",
    "analyze_parsed_data(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f24b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_heavy_chain_number(sequence_id: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract heavy chain number from sequence ID.\n",
    "    \n",
    "    Examples:\n",
    "    \"heavy_chain_32\" -> 32\n",
    "    \"true_light_chain_heavy_chain_32\" -> 32  \n",
    "    \"gen_light_3_heavy_chain_32\" -> 32\n",
    "    \n",
    "    Args:\n",
    "        sequence_id (str): Sequence identifier\n",
    "        \n",
    "    Returns:\n",
    "        int: Heavy chain number, or -1 if not found\n",
    "    \"\"\"\n",
    "    # Look for pattern \"heavy_chain_X\" at the end\n",
    "    match = re.search(r'heavy_chain_(\\d+)$', sequence_id)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    # Look for pattern \"heavy_chain_X\" anywhere\n",
    "    match = re.search(r'heavy_chain_(\\d+)', sequence_id)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return -1\n",
    "\n",
    "def extract_sequence_type_and_number(sequence_id: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract sequence type and generation number from sequence ID.\n",
    "    \n",
    "    Args:\n",
    "        sequence_id (str): Sequence identifier\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (sequence_type, generation_number)\n",
    "               sequence_type: 'heavy', 'true_light', 'gen_light'\n",
    "               generation_number: int for generated sequences, None for others\n",
    "    \"\"\"\n",
    "    if sequence_id.startswith('heavy_chain_'):\n",
    "        return ('heavy', None)\n",
    "    elif sequence_id.startswith('true_light_chain_'):\n",
    "        return ('true_light', None)\n",
    "    elif sequence_id.startswith('gen_light_'):\n",
    "        # Extract generation number\n",
    "        match = re.search(r'gen_light_(\\d+)_', sequence_id)\n",
    "        if match:\n",
    "            return ('gen_light', int(match.group(1)))\n",
    "        else:\n",
    "            return ('gen_light', None)\n",
    "    \n",
    "    return ('unknown', None)\n",
    "\n",
    "def reformat_csv_by_heavy_chain(input_csv_path: str, output_csv_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reformat CSV to group all sequences belonging to the same heavy chain on one row.\n",
    "    \n",
    "    Args:\n",
    "        input_csv_path (str): Path to input CSV file\n",
    "        output_csv_path (str, optional): Path for output CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Reformatted DataFrame with grouped sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Reading data from: {input_csv_path}\")\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Original columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Group sequences by heavy chain number\n",
    "    heavy_chain_groups = defaultdict(lambda: {\n",
    "        'heavy': None,\n",
    "        'true_light': None,\n",
    "        'generated': {}\n",
    "    })\n",
    "    \n",
    "    # Process each row and group by heavy chain\n",
    "    for idx, row in df.iterrows():\n",
    "        sequence_id = row['sequence_id']\n",
    "        heavy_chain_num = extract_heavy_chain_number(sequence_id)\n",
    "        seq_type, gen_num = extract_sequence_type_and_number(sequence_id)\n",
    "        \n",
    "        if heavy_chain_num == -1:\n",
    "            print(f\"Warning: Could not extract heavy chain number from: {sequence_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Store the row data based on sequence type\n",
    "        if seq_type == 'heavy':\n",
    "            heavy_chain_groups[heavy_chain_num]['heavy'] = row\n",
    "        elif seq_type == 'true_light':\n",
    "            heavy_chain_groups[heavy_chain_num]['true_light'] = row\n",
    "        elif seq_type == 'gen_light':\n",
    "            heavy_chain_groups[heavy_chain_num]['generated'][gen_num] = row\n",
    "    \n",
    "    print(f\"Found {len(heavy_chain_groups)} heavy chain groups\")\n",
    "    \n",
    "    # Create reformatted data\n",
    "    reformatted_data = []\n",
    "    \n",
    "    for heavy_chain_num in sorted(heavy_chain_groups.keys()):\n",
    "        group_data = heavy_chain_groups[heavy_chain_num]\n",
    "        \n",
    "        # Start with overall_id\n",
    "        row_data = {'overall_id': heavy_chain_num}\n",
    "        \n",
    "        # Add heavy chain data\n",
    "        if group_data['heavy'] is not None:\n",
    "            heavy_row = group_data['heavy']\n",
    "            for col in heavy_row.index:\n",
    "                if col != 'sequence_id':  # Skip sequence_id to avoid confusion\n",
    "                    row_data[f'heavy_{col}'] = heavy_row[col]\n",
    "        \n",
    "        # Add true light chain data\n",
    "        if group_data['true_light'] is not None:\n",
    "            true_light_row = group_data['true_light']\n",
    "            for col in true_light_row.index:\n",
    "                if col != 'sequence_id':\n",
    "                    row_data[f'true_light_{col}'] = true_light_row[col]\n",
    "        \n",
    "        # Add generated light chain data\n",
    "        generated_sequences = group_data['generated']\n",
    "        max_gen_sequences = len(generated_sequences)\n",
    "        \n",
    "        # Sort generated sequences by generation number\n",
    "        sorted_gen_nums = sorted(generated_sequences.keys())\n",
    "        \n",
    "        for i, gen_num in enumerate(sorted_gen_nums, 1):\n",
    "            gen_row = generated_sequences[gen_num]\n",
    "            for col in gen_row.index:\n",
    "                if col != 'sequence_id':\n",
    "                    row_data[f'gen_light_{i}_{col}'] = gen_row[col]\n",
    "            # Also store the original generation number\n",
    "            row_data[f'gen_light_{i}_original_number'] = gen_num\n",
    "        \n",
    "        # Add count information\n",
    "        row_data['num_generated_sequences'] = len(generated_sequences)\n",
    "        \n",
    "        reformatted_data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    reformatted_df = pd.DataFrame(reformatted_data)\n",
    "    \n",
    "    # Generate output filename if not provided\n",
    "    if output_csv_path is None:\n",
    "        if input_csv_path.endswith('.csv'):\n",
    "            output_csv_path = input_csv_path.replace('.csv', '_reformatted.csv')\n",
    "        else:\n",
    "            output_csv_path = input_csv_path + '_reformatted.csv'\n",
    "    \n",
    "    # Save reformatted data\n",
    "    reformatted_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\n=== REFORMATTING SUMMARY ===\")\n",
    "    print(f\"Heavy chain groups processed: {len(heavy_chain_groups)}\")\n",
    "    print(f\"Reformatted dataset shape: {reformatted_df.shape}\")\n",
    "    print(f\"Output saved to: {output_csv_path}\")\n",
    "    \n",
    "    # Show sample of reformatted data\n",
    "    print(f\"\\n=== SAMPLE OF REFORMATTED DATA ===\")\n",
    "    print(\"Column names:\")\n",
    "    for i, col in enumerate(reformatted_df.columns):\n",
    "        print(f\"  {i+1}. {col}\")\n",
    "    \n",
    "    if len(reformatted_df) > 0:\n",
    "        print(f\"\\nFirst few rows (showing key columns):\")\n",
    "        key_cols = ['overall_id', 'num_generated_sequences']\n",
    "        # Add some sequence columns if they exist\n",
    "        for col in reformatted_df.columns:\n",
    "            if 'raw_sequence' in col:\n",
    "                key_cols.append(col)\n",
    "        \n",
    "        available_key_cols = [col for col in key_cols if col in reformatted_df.columns]\n",
    "        print(reformatted_df[available_key_cols].head())\n",
    "    \n",
    "    return reformatted_df\n",
    "\n",
    "def analyze_reformatted_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Analyze the reformatted data and provide statistics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Reformatted DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== DETAILED ANALYSIS ===\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total heavy chain groups: {len(df)}\")\n",
    "    \n",
    "    # Analyze number of generated sequences per heavy chain\n",
    "    if 'num_generated_sequences' in df.columns:\n",
    "        gen_seq_stats = df['num_generated_sequences'].describe()\n",
    "        print(f\"\\nGenerated sequences per heavy chain:\")\n",
    "        print(f\"  Average: {gen_seq_stats['mean']:.1f}\")\n",
    "        print(f\"  Min: {int(gen_seq_stats['min'])}\")\n",
    "        print(f\"  Max: {int(gen_seq_stats['max'])}\")\n",
    "        print(f\"  Distribution:\")\n",
    "        \n",
    "        gen_counts = df['num_generated_sequences'].value_counts().sort_index()\n",
    "        for count, freq in gen_counts.items():\n",
    "            percentage = (freq / len(df)) * 100\n",
    "            print(f\"    {int(count)} generated sequences: {freq} heavy chains ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Check for missing data\n",
    "    missing_heavy = df[[col for col in df.columns if col.startswith('heavy_')]].isnull().all(axis=1).sum()\n",
    "    missing_true_light = df[[col for col in df.columns if col.startswith('true_light_')]].isnull().all(axis=1).sum()\n",
    "    \n",
    "    print(f\"\\nMissing data:\")\n",
    "    print(f\"  Heavy chains without heavy sequence data: {missing_heavy}\")\n",
    "    print(f\"  Heavy chains without true light sequence data: {missing_true_light}\")\n",
    "\n",
    "def create_sequence_only_format(df: pd.DataFrame, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a simplified version with only sequence data (no analysis results).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Reformatted DataFrame\n",
    "        output_path (str): Output path for sequence-only CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only sequence-related columns\n",
    "    sequence_columns = ['overall_id', 'num_generated_sequences']\n",
    "    \n",
    "    # Add sequence columns\n",
    "    for col in df.columns:\n",
    "        if any(seq_col in col for seq_col in ['raw_sequence', 'gene_name', 'light_locus']):\n",
    "            sequence_columns.append(col)\n",
    "        elif any(region in col for region in ['FR1_sequence', 'CDR1_sequence', 'FR2_sequence', \n",
    "                                             'CDR2_sequence', 'FR3_sequence', 'CDR3_sequence']):\n",
    "            sequence_columns.append(col)\n",
    "    \n",
    "    # Filter to only existing columns\n",
    "    available_columns = [col for col in sequence_columns if col in df.columns]\n",
    "    sequence_df = df[available_columns].copy()\n",
    "    \n",
    "    # Save sequence-only version\n",
    "    sequence_df.to_csv(output_path, index=False)\n",
    "    print(f\"Sequence-only CSV saved to: {output_path}\")\n",
    "\n",
    "def validate_reformatted_data(original_df: pd.DataFrame, reformatted_df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Validate that the reformatting preserved all data correctly.\n",
    "    \n",
    "    Args:\n",
    "        original_df (pd.DataFrame): Original DataFrame\n",
    "        reformatted_df (pd.DataFrame): Reformatted DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== VALIDATION ===\")\n",
    "    \n",
    "    # Count total sequences in original data\n",
    "    original_heavy_chains = set()\n",
    "    for _, row in original_df.iterrows():\n",
    "        heavy_chain_num = extract_heavy_chain_number(row['sequence_id'])\n",
    "        if heavy_chain_num != -1:\n",
    "            original_heavy_chains.add(heavy_chain_num)\n",
    "    \n",
    "    print(f\"Heavy chains in original data: {len(original_heavy_chains)}\")\n",
    "    print(f\"Heavy chains in reformatted data: {len(reformatted_df)}\")\n",
    "    \n",
    "    if len(original_heavy_chains) == len(reformatted_df):\n",
    "        print(\"✓ All heavy chains preserved\")\n",
    "    else:\n",
    "        print(\"✗ Some heavy chains may be missing\")\n",
    "        missing = original_heavy_chains - set(reformatted_df['overall_id'])\n",
    "        if missing:\n",
    "            print(f\"  Missing heavy chains: {sorted(missing)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56133be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\n",
      "Original dataset shape: (339147, 46)\n",
      "Original columns: ['sequence_id', 'raw_sequence', 'sequence_length', 'domain_classification', 'nt_trimmed', 'first_hit_gene', 'first_hit_bit_score', 'first_hit_e_value', 'gene_name', 'light_locus', 'FR1_sequence', 'FR1_length', 'FR1_percent_identity', 'FR1_matches', 'FR1_mismatches', 'FR1_gaps', 'CDR1_sequence', 'CDR1_length', 'CDR1_percent_identity', 'CDR1_matches', 'CDR1_mismatches', 'CDR1_gaps', 'FR2_sequence', 'FR2_length', 'FR2_percent_identity', 'FR2_matches', 'FR2_mismatches', 'FR2_gaps', 'CDR2_sequence', 'CDR2_length', 'CDR2_percent_identity', 'CDR2_matches', 'CDR2_mismatches', 'CDR2_gaps', 'FR3_sequence', 'FR3_length', 'FR3_percent_identity', 'FR3_matches', 'FR3_mismatches', 'FR3_gaps', 'CDR3_sequence', 'CDR3_length', 'CDR3_percent_identity', 'CDR3_matches', 'CDR3_mismatches', 'CDR3_gaps']\n",
      "Found 46081 heavy chain groups\n",
      "\n",
      "=== REFORMATTING SUMMARY ===\n",
      "Heavy chain groups processed: 46081\n",
      "Reformatted dataset shape: (46081, 552)\n",
      "Output saved to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv\n",
      "\n",
      "=== SAMPLE OF REFORMATTED DATA ===\n",
      "Column names:\n",
      "  1. overall_id\n",
      "  2. heavy_raw_sequence\n",
      "  3. heavy_sequence_length\n",
      "  4. heavy_domain_classification\n",
      "  5. heavy_nt_trimmed\n",
      "  6. heavy_first_hit_gene\n",
      "  7. heavy_first_hit_bit_score\n",
      "  8. heavy_first_hit_e_value\n",
      "  9. heavy_gene_name\n",
      "  10. heavy_light_locus\n",
      "  11. heavy_FR1_sequence\n",
      "  12. heavy_FR1_length\n",
      "  13. heavy_FR1_percent_identity\n",
      "  14. heavy_FR1_matches\n",
      "  15. heavy_FR1_mismatches\n",
      "  16. heavy_FR1_gaps\n",
      "  17. heavy_CDR1_sequence\n",
      "  18. heavy_CDR1_length\n",
      "  19. heavy_CDR1_percent_identity\n",
      "  20. heavy_CDR1_matches\n",
      "  21. heavy_CDR1_mismatches\n",
      "  22. heavy_CDR1_gaps\n",
      "  23. heavy_FR2_sequence\n",
      "  24. heavy_FR2_length\n",
      "  25. heavy_FR2_percent_identity\n",
      "  26. heavy_FR2_matches\n",
      "  27. heavy_FR2_mismatches\n",
      "  28. heavy_FR2_gaps\n",
      "  29. heavy_CDR2_sequence\n",
      "  30. heavy_CDR2_length\n",
      "  31. heavy_CDR2_percent_identity\n",
      "  32. heavy_CDR2_matches\n",
      "  33. heavy_CDR2_mismatches\n",
      "  34. heavy_CDR2_gaps\n",
      "  35. heavy_FR3_sequence\n",
      "  36. heavy_FR3_length\n",
      "  37. heavy_FR3_percent_identity\n",
      "  38. heavy_FR3_matches\n",
      "  39. heavy_FR3_mismatches\n",
      "  40. heavy_FR3_gaps\n",
      "  41. heavy_CDR3_sequence\n",
      "  42. heavy_CDR3_length\n",
      "  43. heavy_CDR3_percent_identity\n",
      "  44. heavy_CDR3_matches\n",
      "  45. heavy_CDR3_mismatches\n",
      "  46. heavy_CDR3_gaps\n",
      "  47. true_light_raw_sequence\n",
      "  48. true_light_sequence_length\n",
      "  49. true_light_domain_classification\n",
      "  50. true_light_nt_trimmed\n",
      "  51. true_light_first_hit_gene\n",
      "  52. true_light_first_hit_bit_score\n",
      "  53. true_light_first_hit_e_value\n",
      "  54. true_light_gene_name\n",
      "  55. true_light_light_locus\n",
      "  56. true_light_FR1_sequence\n",
      "  57. true_light_FR1_length\n",
      "  58. true_light_FR1_percent_identity\n",
      "  59. true_light_FR1_matches\n",
      "  60. true_light_FR1_mismatches\n",
      "  61. true_light_FR1_gaps\n",
      "  62. true_light_CDR1_sequence\n",
      "  63. true_light_CDR1_length\n",
      "  64. true_light_CDR1_percent_identity\n",
      "  65. true_light_CDR1_matches\n",
      "  66. true_light_CDR1_mismatches\n",
      "  67. true_light_CDR1_gaps\n",
      "  68. true_light_FR2_sequence\n",
      "  69. true_light_FR2_length\n",
      "  70. true_light_FR2_percent_identity\n",
      "  71. true_light_FR2_matches\n",
      "  72. true_light_FR2_mismatches\n",
      "  73. true_light_FR2_gaps\n",
      "  74. true_light_CDR2_sequence\n",
      "  75. true_light_CDR2_length\n",
      "  76. true_light_CDR2_percent_identity\n",
      "  77. true_light_CDR2_matches\n",
      "  78. true_light_CDR2_mismatches\n",
      "  79. true_light_CDR2_gaps\n",
      "  80. true_light_FR3_sequence\n",
      "  81. true_light_FR3_length\n",
      "  82. true_light_FR3_percent_identity\n",
      "  83. true_light_FR3_matches\n",
      "  84. true_light_FR3_mismatches\n",
      "  85. true_light_FR3_gaps\n",
      "  86. true_light_CDR3_sequence\n",
      "  87. true_light_CDR3_length\n",
      "  88. true_light_CDR3_percent_identity\n",
      "  89. true_light_CDR3_matches\n",
      "  90. true_light_CDR3_mismatches\n",
      "  91. true_light_CDR3_gaps\n",
      "  92. gen_light_1_raw_sequence\n",
      "  93. gen_light_1_sequence_length\n",
      "  94. gen_light_1_domain_classification\n",
      "  95. gen_light_1_nt_trimmed\n",
      "  96. gen_light_1_first_hit_gene\n",
      "  97. gen_light_1_first_hit_bit_score\n",
      "  98. gen_light_1_first_hit_e_value\n",
      "  99. gen_light_1_gene_name\n",
      "  100. gen_light_1_light_locus\n",
      "  101. gen_light_1_FR1_sequence\n",
      "  102. gen_light_1_FR1_length\n",
      "  103. gen_light_1_FR1_percent_identity\n",
      "  104. gen_light_1_FR1_matches\n",
      "  105. gen_light_1_FR1_mismatches\n",
      "  106. gen_light_1_FR1_gaps\n",
      "  107. gen_light_1_CDR1_sequence\n",
      "  108. gen_light_1_CDR1_length\n",
      "  109. gen_light_1_CDR1_percent_identity\n",
      "  110. gen_light_1_CDR1_matches\n",
      "  111. gen_light_1_CDR1_mismatches\n",
      "  112. gen_light_1_CDR1_gaps\n",
      "  113. gen_light_1_FR2_sequence\n",
      "  114. gen_light_1_FR2_length\n",
      "  115. gen_light_1_FR2_percent_identity\n",
      "  116. gen_light_1_FR2_matches\n",
      "  117. gen_light_1_FR2_mismatches\n",
      "  118. gen_light_1_FR2_gaps\n",
      "  119. gen_light_1_CDR2_sequence\n",
      "  120. gen_light_1_CDR2_length\n",
      "  121. gen_light_1_CDR2_percent_identity\n",
      "  122. gen_light_1_CDR2_matches\n",
      "  123. gen_light_1_CDR2_mismatches\n",
      "  124. gen_light_1_CDR2_gaps\n",
      "  125. gen_light_1_FR3_sequence\n",
      "  126. gen_light_1_FR3_length\n",
      "  127. gen_light_1_FR3_percent_identity\n",
      "  128. gen_light_1_FR3_matches\n",
      "  129. gen_light_1_FR3_mismatches\n",
      "  130. gen_light_1_FR3_gaps\n",
      "  131. gen_light_1_CDR3_sequence\n",
      "  132. gen_light_1_CDR3_length\n",
      "  133. gen_light_1_CDR3_percent_identity\n",
      "  134. gen_light_1_CDR3_matches\n",
      "  135. gen_light_1_CDR3_mismatches\n",
      "  136. gen_light_1_CDR3_gaps\n",
      "  137. gen_light_1_original_number\n",
      "  138. gen_light_2_raw_sequence\n",
      "  139. gen_light_2_sequence_length\n",
      "  140. gen_light_2_domain_classification\n",
      "  141. gen_light_2_nt_trimmed\n",
      "  142. gen_light_2_first_hit_gene\n",
      "  143. gen_light_2_first_hit_bit_score\n",
      "  144. gen_light_2_first_hit_e_value\n",
      "  145. gen_light_2_gene_name\n",
      "  146. gen_light_2_light_locus\n",
      "  147. gen_light_2_FR1_sequence\n",
      "  148. gen_light_2_FR1_length\n",
      "  149. gen_light_2_FR1_percent_identity\n",
      "  150. gen_light_2_FR1_matches\n",
      "  151. gen_light_2_FR1_mismatches\n",
      "  152. gen_light_2_FR1_gaps\n",
      "  153. gen_light_2_CDR1_sequence\n",
      "  154. gen_light_2_CDR1_length\n",
      "  155. gen_light_2_CDR1_percent_identity\n",
      "  156. gen_light_2_CDR1_matches\n",
      "  157. gen_light_2_CDR1_mismatches\n",
      "  158. gen_light_2_CDR1_gaps\n",
      "  159. gen_light_2_FR2_sequence\n",
      "  160. gen_light_2_FR2_length\n",
      "  161. gen_light_2_FR2_percent_identity\n",
      "  162. gen_light_2_FR2_matches\n",
      "  163. gen_light_2_FR2_mismatches\n",
      "  164. gen_light_2_FR2_gaps\n",
      "  165. gen_light_2_CDR2_sequence\n",
      "  166. gen_light_2_CDR2_length\n",
      "  167. gen_light_2_CDR2_percent_identity\n",
      "  168. gen_light_2_CDR2_matches\n",
      "  169. gen_light_2_CDR2_mismatches\n",
      "  170. gen_light_2_CDR2_gaps\n",
      "  171. gen_light_2_FR3_sequence\n",
      "  172. gen_light_2_FR3_length\n",
      "  173. gen_light_2_FR3_percent_identity\n",
      "  174. gen_light_2_FR3_matches\n",
      "  175. gen_light_2_FR3_mismatches\n",
      "  176. gen_light_2_FR3_gaps\n",
      "  177. gen_light_2_CDR3_sequence\n",
      "  178. gen_light_2_CDR3_length\n",
      "  179. gen_light_2_CDR3_percent_identity\n",
      "  180. gen_light_2_CDR3_matches\n",
      "  181. gen_light_2_CDR3_mismatches\n",
      "  182. gen_light_2_CDR3_gaps\n",
      "  183. gen_light_2_original_number\n",
      "  184. gen_light_3_raw_sequence\n",
      "  185. gen_light_3_sequence_length\n",
      "  186. gen_light_3_domain_classification\n",
      "  187. gen_light_3_nt_trimmed\n",
      "  188. gen_light_3_first_hit_gene\n",
      "  189. gen_light_3_first_hit_bit_score\n",
      "  190. gen_light_3_first_hit_e_value\n",
      "  191. gen_light_3_gene_name\n",
      "  192. gen_light_3_light_locus\n",
      "  193. gen_light_3_FR1_sequence\n",
      "  194. gen_light_3_FR1_length\n",
      "  195. gen_light_3_FR1_percent_identity\n",
      "  196. gen_light_3_FR1_matches\n",
      "  197. gen_light_3_FR1_mismatches\n",
      "  198. gen_light_3_FR1_gaps\n",
      "  199. gen_light_3_CDR1_sequence\n",
      "  200. gen_light_3_CDR1_length\n",
      "  201. gen_light_3_CDR1_percent_identity\n",
      "  202. gen_light_3_CDR1_matches\n",
      "  203. gen_light_3_CDR1_mismatches\n",
      "  204. gen_light_3_CDR1_gaps\n",
      "  205. gen_light_3_FR2_sequence\n",
      "  206. gen_light_3_FR2_length\n",
      "  207. gen_light_3_FR2_percent_identity\n",
      "  208. gen_light_3_FR2_matches\n",
      "  209. gen_light_3_FR2_mismatches\n",
      "  210. gen_light_3_FR2_gaps\n",
      "  211. gen_light_3_CDR2_sequence\n",
      "  212. gen_light_3_CDR2_length\n",
      "  213. gen_light_3_CDR2_percent_identity\n",
      "  214. gen_light_3_CDR2_matches\n",
      "  215. gen_light_3_CDR2_mismatches\n",
      "  216. gen_light_3_CDR2_gaps\n",
      "  217. gen_light_3_FR3_sequence\n",
      "  218. gen_light_3_FR3_length\n",
      "  219. gen_light_3_FR3_percent_identity\n",
      "  220. gen_light_3_FR3_matches\n",
      "  221. gen_light_3_FR3_mismatches\n",
      "  222. gen_light_3_FR3_gaps\n",
      "  223. gen_light_3_CDR3_sequence\n",
      "  224. gen_light_3_CDR3_length\n",
      "  225. gen_light_3_CDR3_percent_identity\n",
      "  226. gen_light_3_CDR3_matches\n",
      "  227. gen_light_3_CDR3_mismatches\n",
      "  228. gen_light_3_CDR3_gaps\n",
      "  229. gen_light_3_original_number\n",
      "  230. num_generated_sequences\n",
      "  231. gen_light_4_raw_sequence\n",
      "  232. gen_light_4_sequence_length\n",
      "  233. gen_light_4_domain_classification\n",
      "  234. gen_light_4_nt_trimmed\n",
      "  235. gen_light_4_first_hit_gene\n",
      "  236. gen_light_4_first_hit_bit_score\n",
      "  237. gen_light_4_first_hit_e_value\n",
      "  238. gen_light_4_gene_name\n",
      "  239. gen_light_4_light_locus\n",
      "  240. gen_light_4_FR1_sequence\n",
      "  241. gen_light_4_FR1_length\n",
      "  242. gen_light_4_FR1_percent_identity\n",
      "  243. gen_light_4_FR1_matches\n",
      "  244. gen_light_4_FR1_mismatches\n",
      "  245. gen_light_4_FR1_gaps\n",
      "  246. gen_light_4_CDR1_sequence\n",
      "  247. gen_light_4_CDR1_length\n",
      "  248. gen_light_4_CDR1_percent_identity\n",
      "  249. gen_light_4_CDR1_matches\n",
      "  250. gen_light_4_CDR1_mismatches\n",
      "  251. gen_light_4_CDR1_gaps\n",
      "  252. gen_light_4_FR2_sequence\n",
      "  253. gen_light_4_FR2_length\n",
      "  254. gen_light_4_FR2_percent_identity\n",
      "  255. gen_light_4_FR2_matches\n",
      "  256. gen_light_4_FR2_mismatches\n",
      "  257. gen_light_4_FR2_gaps\n",
      "  258. gen_light_4_CDR2_sequence\n",
      "  259. gen_light_4_CDR2_length\n",
      "  260. gen_light_4_CDR2_percent_identity\n",
      "  261. gen_light_4_CDR2_matches\n",
      "  262. gen_light_4_CDR2_mismatches\n",
      "  263. gen_light_4_CDR2_gaps\n",
      "  264. gen_light_4_FR3_sequence\n",
      "  265. gen_light_4_FR3_length\n",
      "  266. gen_light_4_FR3_percent_identity\n",
      "  267. gen_light_4_FR3_matches\n",
      "  268. gen_light_4_FR3_mismatches\n",
      "  269. gen_light_4_FR3_gaps\n",
      "  270. gen_light_4_CDR3_sequence\n",
      "  271. gen_light_4_CDR3_length\n",
      "  272. gen_light_4_CDR3_percent_identity\n",
      "  273. gen_light_4_CDR3_matches\n",
      "  274. gen_light_4_CDR3_mismatches\n",
      "  275. gen_light_4_CDR3_gaps\n",
      "  276. gen_light_4_original_number\n",
      "  277. gen_light_5_raw_sequence\n",
      "  278. gen_light_5_sequence_length\n",
      "  279. gen_light_5_domain_classification\n",
      "  280. gen_light_5_nt_trimmed\n",
      "  281. gen_light_5_first_hit_gene\n",
      "  282. gen_light_5_first_hit_bit_score\n",
      "  283. gen_light_5_first_hit_e_value\n",
      "  284. gen_light_5_gene_name\n",
      "  285. gen_light_5_light_locus\n",
      "  286. gen_light_5_FR1_sequence\n",
      "  287. gen_light_5_FR1_length\n",
      "  288. gen_light_5_FR1_percent_identity\n",
      "  289. gen_light_5_FR1_matches\n",
      "  290. gen_light_5_FR1_mismatches\n",
      "  291. gen_light_5_FR1_gaps\n",
      "  292. gen_light_5_CDR1_sequence\n",
      "  293. gen_light_5_CDR1_length\n",
      "  294. gen_light_5_CDR1_percent_identity\n",
      "  295. gen_light_5_CDR1_matches\n",
      "  296. gen_light_5_CDR1_mismatches\n",
      "  297. gen_light_5_CDR1_gaps\n",
      "  298. gen_light_5_FR2_sequence\n",
      "  299. gen_light_5_FR2_length\n",
      "  300. gen_light_5_FR2_percent_identity\n",
      "  301. gen_light_5_FR2_matches\n",
      "  302. gen_light_5_FR2_mismatches\n",
      "  303. gen_light_5_FR2_gaps\n",
      "  304. gen_light_5_CDR2_sequence\n",
      "  305. gen_light_5_CDR2_length\n",
      "  306. gen_light_5_CDR2_percent_identity\n",
      "  307. gen_light_5_CDR2_matches\n",
      "  308. gen_light_5_CDR2_mismatches\n",
      "  309. gen_light_5_CDR2_gaps\n",
      "  310. gen_light_5_FR3_sequence\n",
      "  311. gen_light_5_FR3_length\n",
      "  312. gen_light_5_FR3_percent_identity\n",
      "  313. gen_light_5_FR3_matches\n",
      "  314. gen_light_5_FR3_mismatches\n",
      "  315. gen_light_5_FR3_gaps\n",
      "  316. gen_light_5_CDR3_sequence\n",
      "  317. gen_light_5_CDR3_length\n",
      "  318. gen_light_5_CDR3_percent_identity\n",
      "  319. gen_light_5_CDR3_matches\n",
      "  320. gen_light_5_CDR3_mismatches\n",
      "  321. gen_light_5_CDR3_gaps\n",
      "  322. gen_light_5_original_number\n",
      "  323. gen_light_6_raw_sequence\n",
      "  324. gen_light_6_sequence_length\n",
      "  325. gen_light_6_domain_classification\n",
      "  326. gen_light_6_nt_trimmed\n",
      "  327. gen_light_6_first_hit_gene\n",
      "  328. gen_light_6_first_hit_bit_score\n",
      "  329. gen_light_6_first_hit_e_value\n",
      "  330. gen_light_6_gene_name\n",
      "  331. gen_light_6_light_locus\n",
      "  332. gen_light_6_FR1_sequence\n",
      "  333. gen_light_6_FR1_length\n",
      "  334. gen_light_6_FR1_percent_identity\n",
      "  335. gen_light_6_FR1_matches\n",
      "  336. gen_light_6_FR1_mismatches\n",
      "  337. gen_light_6_FR1_gaps\n",
      "  338. gen_light_6_CDR1_sequence\n",
      "  339. gen_light_6_CDR1_length\n",
      "  340. gen_light_6_CDR1_percent_identity\n",
      "  341. gen_light_6_CDR1_matches\n",
      "  342. gen_light_6_CDR1_mismatches\n",
      "  343. gen_light_6_CDR1_gaps\n",
      "  344. gen_light_6_FR2_sequence\n",
      "  345. gen_light_6_FR2_length\n",
      "  346. gen_light_6_FR2_percent_identity\n",
      "  347. gen_light_6_FR2_matches\n",
      "  348. gen_light_6_FR2_mismatches\n",
      "  349. gen_light_6_FR2_gaps\n",
      "  350. gen_light_6_CDR2_sequence\n",
      "  351. gen_light_6_CDR2_length\n",
      "  352. gen_light_6_CDR2_percent_identity\n",
      "  353. gen_light_6_CDR2_matches\n",
      "  354. gen_light_6_CDR2_mismatches\n",
      "  355. gen_light_6_CDR2_gaps\n",
      "  356. gen_light_6_FR3_sequence\n",
      "  357. gen_light_6_FR3_length\n",
      "  358. gen_light_6_FR3_percent_identity\n",
      "  359. gen_light_6_FR3_matches\n",
      "  360. gen_light_6_FR3_mismatches\n",
      "  361. gen_light_6_FR3_gaps\n",
      "  362. gen_light_6_CDR3_sequence\n",
      "  363. gen_light_6_CDR3_length\n",
      "  364. gen_light_6_CDR3_percent_identity\n",
      "  365. gen_light_6_CDR3_matches\n",
      "  366. gen_light_6_CDR3_mismatches\n",
      "  367. gen_light_6_CDR3_gaps\n",
      "  368. gen_light_6_original_number\n",
      "  369. gen_light_7_raw_sequence\n",
      "  370. gen_light_7_sequence_length\n",
      "  371. gen_light_7_domain_classification\n",
      "  372. gen_light_7_nt_trimmed\n",
      "  373. gen_light_7_first_hit_gene\n",
      "  374. gen_light_7_first_hit_bit_score\n",
      "  375. gen_light_7_first_hit_e_value\n",
      "  376. gen_light_7_gene_name\n",
      "  377. gen_light_7_light_locus\n",
      "  378. gen_light_7_FR1_sequence\n",
      "  379. gen_light_7_FR1_length\n",
      "  380. gen_light_7_FR1_percent_identity\n",
      "  381. gen_light_7_FR1_matches\n",
      "  382. gen_light_7_FR1_mismatches\n",
      "  383. gen_light_7_FR1_gaps\n",
      "  384. gen_light_7_CDR1_sequence\n",
      "  385. gen_light_7_CDR1_length\n",
      "  386. gen_light_7_CDR1_percent_identity\n",
      "  387. gen_light_7_CDR1_matches\n",
      "  388. gen_light_7_CDR1_mismatches\n",
      "  389. gen_light_7_CDR1_gaps\n",
      "  390. gen_light_7_FR2_sequence\n",
      "  391. gen_light_7_FR2_length\n",
      "  392. gen_light_7_FR2_percent_identity\n",
      "  393. gen_light_7_FR2_matches\n",
      "  394. gen_light_7_FR2_mismatches\n",
      "  395. gen_light_7_FR2_gaps\n",
      "  396. gen_light_7_CDR2_sequence\n",
      "  397. gen_light_7_CDR2_length\n",
      "  398. gen_light_7_CDR2_percent_identity\n",
      "  399. gen_light_7_CDR2_matches\n",
      "  400. gen_light_7_CDR2_mismatches\n",
      "  401. gen_light_7_CDR2_gaps\n",
      "  402. gen_light_7_FR3_sequence\n",
      "  403. gen_light_7_FR3_length\n",
      "  404. gen_light_7_FR3_percent_identity\n",
      "  405. gen_light_7_FR3_matches\n",
      "  406. gen_light_7_FR3_mismatches\n",
      "  407. gen_light_7_FR3_gaps\n",
      "  408. gen_light_7_CDR3_sequence\n",
      "  409. gen_light_7_CDR3_length\n",
      "  410. gen_light_7_CDR3_percent_identity\n",
      "  411. gen_light_7_CDR3_matches\n",
      "  412. gen_light_7_CDR3_mismatches\n",
      "  413. gen_light_7_CDR3_gaps\n",
      "  414. gen_light_7_original_number\n",
      "  415. gen_light_8_raw_sequence\n",
      "  416. gen_light_8_sequence_length\n",
      "  417. gen_light_8_domain_classification\n",
      "  418. gen_light_8_nt_trimmed\n",
      "  419. gen_light_8_first_hit_gene\n",
      "  420. gen_light_8_first_hit_bit_score\n",
      "  421. gen_light_8_first_hit_e_value\n",
      "  422. gen_light_8_gene_name\n",
      "  423. gen_light_8_light_locus\n",
      "  424. gen_light_8_FR1_sequence\n",
      "  425. gen_light_8_FR1_length\n",
      "  426. gen_light_8_FR1_percent_identity\n",
      "  427. gen_light_8_FR1_matches\n",
      "  428. gen_light_8_FR1_mismatches\n",
      "  429. gen_light_8_FR1_gaps\n",
      "  430. gen_light_8_CDR1_sequence\n",
      "  431. gen_light_8_CDR1_length\n",
      "  432. gen_light_8_CDR1_percent_identity\n",
      "  433. gen_light_8_CDR1_matches\n",
      "  434. gen_light_8_CDR1_mismatches\n",
      "  435. gen_light_8_CDR1_gaps\n",
      "  436. gen_light_8_FR2_sequence\n",
      "  437. gen_light_8_FR2_length\n",
      "  438. gen_light_8_FR2_percent_identity\n",
      "  439. gen_light_8_FR2_matches\n",
      "  440. gen_light_8_FR2_mismatches\n",
      "  441. gen_light_8_FR2_gaps\n",
      "  442. gen_light_8_CDR2_sequence\n",
      "  443. gen_light_8_CDR2_length\n",
      "  444. gen_light_8_CDR2_percent_identity\n",
      "  445. gen_light_8_CDR2_matches\n",
      "  446. gen_light_8_CDR2_mismatches\n",
      "  447. gen_light_8_CDR2_gaps\n",
      "  448. gen_light_8_FR3_sequence\n",
      "  449. gen_light_8_FR3_length\n",
      "  450. gen_light_8_FR3_percent_identity\n",
      "  451. gen_light_8_FR3_matches\n",
      "  452. gen_light_8_FR3_mismatches\n",
      "  453. gen_light_8_FR3_gaps\n",
      "  454. gen_light_8_CDR3_sequence\n",
      "  455. gen_light_8_CDR3_length\n",
      "  456. gen_light_8_CDR3_percent_identity\n",
      "  457. gen_light_8_CDR3_matches\n",
      "  458. gen_light_8_CDR3_mismatches\n",
      "  459. gen_light_8_CDR3_gaps\n",
      "  460. gen_light_8_original_number\n",
      "  461. gen_light_9_raw_sequence\n",
      "  462. gen_light_9_sequence_length\n",
      "  463. gen_light_9_domain_classification\n",
      "  464. gen_light_9_nt_trimmed\n",
      "  465. gen_light_9_first_hit_gene\n",
      "  466. gen_light_9_first_hit_bit_score\n",
      "  467. gen_light_9_first_hit_e_value\n",
      "  468. gen_light_9_gene_name\n",
      "  469. gen_light_9_light_locus\n",
      "  470. gen_light_9_FR1_sequence\n",
      "  471. gen_light_9_FR1_length\n",
      "  472. gen_light_9_FR1_percent_identity\n",
      "  473. gen_light_9_FR1_matches\n",
      "  474. gen_light_9_FR1_mismatches\n",
      "  475. gen_light_9_FR1_gaps\n",
      "  476. gen_light_9_CDR1_sequence\n",
      "  477. gen_light_9_CDR1_length\n",
      "  478. gen_light_9_CDR1_percent_identity\n",
      "  479. gen_light_9_CDR1_matches\n",
      "  480. gen_light_9_CDR1_mismatches\n",
      "  481. gen_light_9_CDR1_gaps\n",
      "  482. gen_light_9_FR2_sequence\n",
      "  483. gen_light_9_FR2_length\n",
      "  484. gen_light_9_FR2_percent_identity\n",
      "  485. gen_light_9_FR2_matches\n",
      "  486. gen_light_9_FR2_mismatches\n",
      "  487. gen_light_9_FR2_gaps\n",
      "  488. gen_light_9_CDR2_sequence\n",
      "  489. gen_light_9_CDR2_length\n",
      "  490. gen_light_9_CDR2_percent_identity\n",
      "  491. gen_light_9_CDR2_matches\n",
      "  492. gen_light_9_CDR2_mismatches\n",
      "  493. gen_light_9_CDR2_gaps\n",
      "  494. gen_light_9_FR3_sequence\n",
      "  495. gen_light_9_FR3_length\n",
      "  496. gen_light_9_FR3_percent_identity\n",
      "  497. gen_light_9_FR3_matches\n",
      "  498. gen_light_9_FR3_mismatches\n",
      "  499. gen_light_9_FR3_gaps\n",
      "  500. gen_light_9_CDR3_sequence\n",
      "  501. gen_light_9_CDR3_length\n",
      "  502. gen_light_9_CDR3_percent_identity\n",
      "  503. gen_light_9_CDR3_matches\n",
      "  504. gen_light_9_CDR3_mismatches\n",
      "  505. gen_light_9_CDR3_gaps\n",
      "  506. gen_light_9_original_number\n",
      "  507. gen_light_10_raw_sequence\n",
      "  508. gen_light_10_sequence_length\n",
      "  509. gen_light_10_domain_classification\n",
      "  510. gen_light_10_nt_trimmed\n",
      "  511. gen_light_10_first_hit_gene\n",
      "  512. gen_light_10_first_hit_bit_score\n",
      "  513. gen_light_10_first_hit_e_value\n",
      "  514. gen_light_10_gene_name\n",
      "  515. gen_light_10_light_locus\n",
      "  516. gen_light_10_FR1_sequence\n",
      "  517. gen_light_10_FR1_length\n",
      "  518. gen_light_10_FR1_percent_identity\n",
      "  519. gen_light_10_FR1_matches\n",
      "  520. gen_light_10_FR1_mismatches\n",
      "  521. gen_light_10_FR1_gaps\n",
      "  522. gen_light_10_CDR1_sequence\n",
      "  523. gen_light_10_CDR1_length\n",
      "  524. gen_light_10_CDR1_percent_identity\n",
      "  525. gen_light_10_CDR1_matches\n",
      "  526. gen_light_10_CDR1_mismatches\n",
      "  527. gen_light_10_CDR1_gaps\n",
      "  528. gen_light_10_FR2_sequence\n",
      "  529. gen_light_10_FR2_length\n",
      "  530. gen_light_10_FR2_percent_identity\n",
      "  531. gen_light_10_FR2_matches\n",
      "  532. gen_light_10_FR2_mismatches\n",
      "  533. gen_light_10_FR2_gaps\n",
      "  534. gen_light_10_CDR2_sequence\n",
      "  535. gen_light_10_CDR2_length\n",
      "  536. gen_light_10_CDR2_percent_identity\n",
      "  537. gen_light_10_CDR2_matches\n",
      "  538. gen_light_10_CDR2_mismatches\n",
      "  539. gen_light_10_CDR2_gaps\n",
      "  540. gen_light_10_FR3_sequence\n",
      "  541. gen_light_10_FR3_length\n",
      "  542. gen_light_10_FR3_percent_identity\n",
      "  543. gen_light_10_FR3_matches\n",
      "  544. gen_light_10_FR3_mismatches\n",
      "  545. gen_light_10_FR3_gaps\n",
      "  546. gen_light_10_CDR3_sequence\n",
      "  547. gen_light_10_CDR3_length\n",
      "  548. gen_light_10_CDR3_percent_identity\n",
      "  549. gen_light_10_CDR3_matches\n",
      "  550. gen_light_10_CDR3_mismatches\n",
      "  551. gen_light_10_CDR3_gaps\n",
      "  552. gen_light_10_original_number\n",
      "\n",
      "First few rows (showing key columns):\n",
      "   overall_id  num_generated_sequences  \\\n",
      "0           1                        3   \n",
      "1           2                        1   \n",
      "2           3                        3   \n",
      "3           4                        6   \n",
      "4           5                        7   \n",
      "\n",
      "                                  heavy_raw_sequence  \\\n",
      "0  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   \n",
      "1  QLQLQESGPGLVKPSETLSLICSVSGGSITTSSYYWAWIRQSPGKG...   \n",
      "2  EVQLVESGGDLVRPGGSLRLSCAASGFPFSRAWMTWVRQAPGKGLD...   \n",
      "3  EVQLLESGGGLVQPGGSLRLSCAASGFNFANYDMSWVRQAPGKGLE...   \n",
      "4  QVQLQESGPGLVKPSGTLSLTCVVSGGSISTNNWWSWVRQPPGKGL...   \n",
      "\n",
      "                             true_light_raw_sequence  \\\n",
      "0  DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
      "1  QSALTQPASVSGSPGQSITISCSGTSDDIGDYNYVSWYQQHPGKAP...   \n",
      "2  DIQMTQSPSSLSAFMGDRVTITCRASQSPKTYLHWYQQRPGGVPKL...   \n",
      "3  QTVVTQEPSFSVSPGGTVTLTCGLSSGSVSTKYYPSWYQQTPGQAP...   \n",
      "4  EIVLTQSPGTLSLSPGERATLSCRASQSISNTYLAWYRQKPGQAPR...   \n",
      "\n",
      "                            gen_light_1_raw_sequence  \\\n",
      "0  SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...   \n",
      "1  DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...   \n",
      "2  EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...   \n",
      "3  DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKF...   \n",
      "4  EIVLTQSPGTLSLSPGERATLSCRASQSVSSRYLAWYQQKPGQAPR...   \n",
      "\n",
      "                            gen_light_2_raw_sequence  \\\n",
      "0  SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPVVV...   \n",
      "1                                                NaN   \n",
      "2  DIQMTQSPSSLSASVGDRVTITCRASQGISNYLAWFQQKPGKAPKS...   \n",
      "3  DIVMTQSPDSLAVSLGERATINCKSSQNLLYNSNNKNYLAWYQQKP...   \n",
      "4  SYVLTQPPSVSVAPGQTARITCGGNNIGSKSVHWYQQKPGQAPVLV...   \n",
      "\n",
      "                            gen_light_3_raw_sequence  \\\n",
      "0  SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...   \n",
      "1                                                NaN   \n",
      "2  DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPG...   \n",
      "3  DIQMTQSPSSLSASVGDRVTITCRASQGISSWLAWYQQKPEKAPKS...   \n",
      "4  QSVLTQPPSASGTPGQRVTISCSGSSSNIGSNSVYWYQQLPGTAPK...   \n",
      "\n",
      "                            gen_light_4_raw_sequence  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  DIQMTQSPSSLSASVGDRVTITCRASQGISSWLAWYQQKPEKAPKS...   \n",
      "4  QSALTQPASVSGSPGQSITISCTGTSSDVGAYNHVSWYQQHPGKAP...   \n",
      "\n",
      "                            gen_light_5_raw_sequence  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKP...   \n",
      "4  DIVMTQSPLSLPVTPGEPASISCRSSQSLLHSNGYNYLDWYLQKPG...   \n",
      "\n",
      "                            gen_light_6_raw_sequence  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKL...   \n",
      "4  QSVLTQPPSVSGAPGQRVTISCTGSSSNIGANYDVHWYQHLPGAAP...   \n",
      "\n",
      "                            gen_light_7_raw_sequence gen_light_8_raw_sequence  \\\n",
      "0                                                NaN                      NaN   \n",
      "1                                                NaN                      NaN   \n",
      "2                                                NaN                      NaN   \n",
      "3                                                NaN                      NaN   \n",
      "4  QSALTQPPSASGSPGQSVTISCTGTSSDVGGYNYVSWYQQHPGKAP...                      NaN   \n",
      "\n",
      "  gen_light_9_raw_sequence gen_light_10_raw_sequence  \n",
      "0                      NaN                       NaN  \n",
      "1                      NaN                       NaN  \n",
      "2                      NaN                       NaN  \n",
      "3                      NaN                       NaN  \n",
      "4                      NaN                       NaN  \n",
      "\n",
      "=== DETAILED ANALYSIS ===\n",
      "Total heavy chain groups: 46081\n",
      "\n",
      "Generated sequences per heavy chain:\n",
      "  Average: 5.4\n",
      "  Min: 1\n",
      "  Max: 10\n",
      "  Distribution:\n",
      "    1 generated sequences: 7451 heavy chains (16.2%)\n",
      "    2 generated sequences: 5146 heavy chains (11.2%)\n",
      "    3 generated sequences: 3771 heavy chains (8.2%)\n",
      "    4 generated sequences: 3387 heavy chains (7.4%)\n",
      "    5 generated sequences: 3454 heavy chains (7.5%)\n",
      "    6 generated sequences: 3600 heavy chains (7.8%)\n",
      "    7 generated sequences: 4195 heavy chains (9.1%)\n",
      "    8 generated sequences: 4649 heavy chains (10.1%)\n",
      "    9 generated sequences: 5326 heavy chains (11.6%)\n",
      "    10 generated sequences: 5102 heavy chains (11.1%)\n",
      "\n",
      "Missing data:\n",
      "  Heavy chains without heavy sequence data: 0\n",
      "  Heavy chains without true light sequence data: 0\n",
      "\n",
      "=== VALIDATION ===\n",
      "Heavy chains in original data: 46081\n",
      "Heavy chains in reformatted data: 46081\n",
      "✓ All heavy chains preserved\n"
     ]
    }
   ],
   "source": [
    "# Input CSV file path - update this to your actual file path\n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267_parsed.csv\" \n",
    "#input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\" \n",
    "\n",
    "input_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\" \n",
    "\n",
    "output_csv_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv\"  \n",
    "\n",
    "# Read original data for validation\n",
    "original_df = pd.read_csv(input_file)\n",
    "        \n",
    "# Reformat the CSV\n",
    "reformatted_df = reformat_csv_by_heavy_chain(input_file, output_csv_path=None)\n",
    "        \n",
    "# Analyze reformatted data\n",
    "analyze_reformatted_data(reformatted_df)\n",
    "        \n",
    "# Validate the reformatting\n",
    "validate_reformatted_data(original_df, reformatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bbb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_extract(input_csv: str, output_csv: str = None):\n",
    "    \"\"\"\n",
    "    Quick extraction function.\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Input CSV file path\n",
    "        output_csv (str, optional): Output CSV file path\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    columns_to_keep = [\n",
    "        'overall_id',\n",
    "        'heavy_raw_sequence', \n",
    "        'true_light_raw_sequence',\n",
    "        'true_light_first_hit_gene',\n",
    "        'true_light_gene_name',\n",
    "        'true_light_light_locus',\n",
    "        'gen_light_1_raw_sequence',\n",
    "        'gen_light_1_nt_trimmed',\n",
    "        'gen_light_1_first_hit_gene',\n",
    "        'gen_light_1_light_locus',\n",
    "        'similarity',\n",
    "        'predicted_input_heavy_label',\n",
    "        'predicted_gen_light_label',\n",
    "    ]\n",
    "    \n",
    "    existing_columns = [col for col in columns_to_keep if col in df.columns]\n",
    "    filtered_df = df[existing_columns]\n",
    "    \n",
    "    if output_csv is None:\n",
    "        output_csv = input_csv.replace('.csv', '_simple.csv')\n",
    "    \n",
    "    filtered_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved {len(filtered_df)} rows with {len(existing_columns)} columns to: {output_csv}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45311482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1023631/639183065.py:9: DtypeWarning: Columns (414,416,417,418,421,422,423,429,435,441,447,460,462,463,464,467,468,469,475,481,487,493,506,508,509,510,513,514,515,521,527,533,539) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 46081 rows with 10 columns to: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_id</th>\n",
       "      <th>heavy_raw_sequence</th>\n",
       "      <th>true_light_raw_sequence</th>\n",
       "      <th>true_light_first_hit_gene</th>\n",
       "      <th>true_light_gene_name</th>\n",
       "      <th>true_light_light_locus</th>\n",
       "      <th>gen_light_1_raw_sequence</th>\n",
       "      <th>gen_light_1_nt_trimmed</th>\n",
       "      <th>gen_light_1_first_hit_gene</th>\n",
       "      <th>gen_light_1_light_locus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...</td>\n",
       "      <td>IGKV1-5*03 unnamed protein product</td>\n",
       "      <td>IGKV1-5*03</td>\n",
       "      <td>IGK</td>\n",
       "      <td>SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...</td>\n",
       "      <td>SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...</td>\n",
       "      <td>IGLV3-19*01 unnamed protein product</td>\n",
       "      <td>IGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QLQLQESGPGLVKPSETLSLICSVSGGSITTSSYYWAWIRQSPGKG...</td>\n",
       "      <td>QSALTQPASVSGSPGQSITISCSGTSDDIGDYNYVSWYQQHPGKAP...</td>\n",
       "      <td>IGLV2-14*03 unnamed protein product</td>\n",
       "      <td>IGLV2-14*03</td>\n",
       "      <td>IGL</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...</td>\n",
       "      <td>IGKV3-20*01 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>EVQLVESGGDLVRPGGSLRLSCAASGFPFSRAWMTWVRQAPGKGLD...</td>\n",
       "      <td>DIQMTQSPSSLSAFMGDRVTITCRASQSPKTYLHWYQQRPGGVPKL...</td>\n",
       "      <td>IGKV1-39*01 unnamed protein product</td>\n",
       "      <td>IGKV1-39*01</td>\n",
       "      <td>IGK</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...</td>\n",
       "      <td>IGKV3-20*01 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>EVQLLESGGGLVQPGGSLRLSCAASGFNFANYDMSWVRQAPGKGLE...</td>\n",
       "      <td>QTVVTQEPSFSVSPGGTVTLTCGLSSGSVSTKYYPSWYQQTPGQAP...</td>\n",
       "      <td>IGLV8-61*01 unnamed protein product</td>\n",
       "      <td>IGLV8-61*01</td>\n",
       "      <td>IGL</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKF...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKF...</td>\n",
       "      <td>IGKV1-5*03 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>QVQLQESGPGLVKPSGTLSLTCVVSGGSISTNNWWSWVRQPPGKGL...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSISNTYLAWYRQKPGQAPR...</td>\n",
       "      <td>IGKV3-20*01 unnamed protein product</td>\n",
       "      <td>IGKV3-20*01</td>\n",
       "      <td>IGK</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSRYLAWYQQKPGQAPR...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSRYLAWYQQKPGQAPR...</td>\n",
       "      <td>IGKV3-20*01 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46076</th>\n",
       "      <td>58832</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFDVYGISWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCQASQSINNWLAWYQQKPGKAPKL...</td>\n",
       "      <td>IGKV1-5*03 unnamed protein product</td>\n",
       "      <td>IGKV1-5*03</td>\n",
       "      <td>IGK</td>\n",
       "      <td>SYVLTQPPSVSVAPGQTARITCGGNNIGSKSVHWYQQKPGQAPVLV...</td>\n",
       "      <td>SYVLTQPPSVSVAPGQTARITCGGNNIGSKSVHWYQQKPGQAPVLV...</td>\n",
       "      <td>IGLV3-21*02 unnamed protein product</td>\n",
       "      <td>IGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46077</th>\n",
       "      <td>58834</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFIFSSFGMHWVRKAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCKSSLSLLNSGNQKNYLTWYQEKP...</td>\n",
       "      <td>IGKV1-39*01 unnamed protein product</td>\n",
       "      <td>IGKV1-39*01</td>\n",
       "      <td>IGK</td>\n",
       "      <td>DIVMTQTPLSLPVTPGEPASISCRSSQSLLDSDDGNTYLDWYLQKP...</td>\n",
       "      <td>DIVMTQTPLSLPVTPGEPASISCRSSQSLLDSDDGNTYLDWYLQKP...</td>\n",
       "      <td>IGKV2-28*01 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46078</th>\n",
       "      <td>58835</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSDNDFSWVRQAPGQGLE...</td>\n",
       "      <td>QSALTQPRSVSGSPGQSVTISCTGTSSDVGGYNYVSWYQQHPGKAP...</td>\n",
       "      <td>IGLV2-11*01 unnamed protein product</td>\n",
       "      <td>IGLV2-11*01</td>\n",
       "      <td>IGL</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>IGKV1-5*03 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46079</th>\n",
       "      <td>58837</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFSTYYMSWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGISNILAWYQQKPGKAPKL...</td>\n",
       "      <td>IGKV1-NL1*01 unnamed protein product</td>\n",
       "      <td>IGKV1-NL1*01</td>\n",
       "      <td>IGK</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...</td>\n",
       "      <td>IGLV3-10*01 unnamed protein product</td>\n",
       "      <td>IGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46080</th>\n",
       "      <td>58839</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...</td>\n",
       "      <td>AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...</td>\n",
       "      <td>IGKV1-NL1*01 unnamed protein product</td>\n",
       "      <td>IGKV1-NL1*01</td>\n",
       "      <td>IGK</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSRSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSRSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>IGKV1-27*01 unnamed protein product</td>\n",
       "      <td>IGK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46081 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall_id                                 heavy_raw_sequence  \\\n",
       "0               1  QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKG...   \n",
       "1               2  QLQLQESGPGLVKPSETLSLICSVSGGSITTSSYYWAWIRQSPGKG...   \n",
       "2               3  EVQLVESGGDLVRPGGSLRLSCAASGFPFSRAWMTWVRQAPGKGLD...   \n",
       "3               4  EVQLLESGGGLVQPGGSLRLSCAASGFNFANYDMSWVRQAPGKGLE...   \n",
       "4               5  QVQLQESGPGLVKPSGTLSLTCVVSGGSISTNNWWSWVRQPPGKGL...   \n",
       "...           ...                                                ...   \n",
       "46076       58832  QVQLVQSGAEVKKPGASVKVSCKASGYTFDVYGISWVRQAPGQGLE...   \n",
       "46077       58834  EVQLVESGGGLVQPGGSLRLSCAASGFIFSSFGMHWVRKAPGKGLE...   \n",
       "46078       58835  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSDNDFSWVRQAPGQGLE...   \n",
       "46079       58837  EVQLVESGGGLVQPGGSLRLSCAASGFTFSTYYMSWVRQAPGKGLE...   \n",
       "46080       58839  QVQLVQSGAEVKKPGSSVKVSCKASGYVFSTSWMNWVRQAPGQGLE...   \n",
       "\n",
       "                                 true_light_raw_sequence  \\\n",
       "0      DIQMTQSPSTLSASVGDRVTITCRASHSINTWLAWYQQKPGKAPKL...   \n",
       "1      QSALTQPASVSGSPGQSITISCSGTSDDIGDYNYVSWYQQHPGKAP...   \n",
       "2      DIQMTQSPSSLSAFMGDRVTITCRASQSPKTYLHWYQQRPGGVPKL...   \n",
       "3      QTVVTQEPSFSVSPGGTVTLTCGLSSGSVSTKYYPSWYQQTPGQAP...   \n",
       "4      EIVLTQSPGTLSLSPGERATLSCRASQSISNTYLAWYRQKPGQAPR...   \n",
       "...                                                  ...   \n",
       "46076  DIQMTQSPSTLSASVGDRVTITCQASQSINNWLAWYQQKPGKAPKL...   \n",
       "46077  DIQMTQSPSSLSASVGDRVTITCKSSLSLLNSGNQKNYLTWYQEKP...   \n",
       "46078  QSALTQPRSVSGSPGQSVTISCTGTSSDVGGYNYVSWYQQHPGKAP...   \n",
       "46079  DIQMTQSPSSLSASVGDRVTITCRASQGISNILAWYQQKPGKAPKL...   \n",
       "46080  AIQLTQSPSSLSASVGDRVTITCRVSENIYSHLAWYQQKPGKAPKL...   \n",
       "\n",
       "                  true_light_first_hit_gene true_light_gene_name  \\\n",
       "0        IGKV1-5*03 unnamed protein product           IGKV1-5*03   \n",
       "1       IGLV2-14*03 unnamed protein product          IGLV2-14*03   \n",
       "2       IGKV1-39*01 unnamed protein product          IGKV1-39*01   \n",
       "3       IGLV8-61*01 unnamed protein product          IGLV8-61*01   \n",
       "4       IGKV3-20*01 unnamed protein product          IGKV3-20*01   \n",
       "...                                     ...                  ...   \n",
       "46076    IGKV1-5*03 unnamed protein product           IGKV1-5*03   \n",
       "46077   IGKV1-39*01 unnamed protein product          IGKV1-39*01   \n",
       "46078   IGLV2-11*01 unnamed protein product          IGLV2-11*01   \n",
       "46079  IGKV1-NL1*01 unnamed protein product         IGKV1-NL1*01   \n",
       "46080  IGKV1-NL1*01 unnamed protein product         IGKV1-NL1*01   \n",
       "\n",
       "      true_light_light_locus  \\\n",
       "0                        IGK   \n",
       "1                        IGL   \n",
       "2                        IGK   \n",
       "3                        IGL   \n",
       "4                        IGK   \n",
       "...                      ...   \n",
       "46076                    IGK   \n",
       "46077                    IGK   \n",
       "46078                    IGL   \n",
       "46079                    IGK   \n",
       "46080                    IGK   \n",
       "\n",
       "                                gen_light_1_raw_sequence  \\\n",
       "0      SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...   \n",
       "1      DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...   \n",
       "2      EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...   \n",
       "3      DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKF...   \n",
       "4      EIVLTQSPGTLSLSPGERATLSCRASQSVSSRYLAWYQQKPGQAPR...   \n",
       "...                                                  ...   \n",
       "46076  SYVLTQPPSVSVAPGQTARITCGGNNIGSKSVHWYQQKPGQAPVLV...   \n",
       "46077  DIVMTQTPLSLPVTPGEPASISCRSSQSLLDSDDGNTYLDWYLQKP...   \n",
       "46078  DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKL...   \n",
       "46079  SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...   \n",
       "46080  DIVMTQSPDSLAVSLGERATINCKSSRSLLYSSNNKNYLAWYQQKP...   \n",
       "\n",
       "                                  gen_light_1_nt_trimmed  \\\n",
       "0      SSELTQDPAVSVALGQTVRITCQGDSLRSYYASWYQQKPGQAPLLV...   \n",
       "1      DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSDNKNYLGWYQQKP...   \n",
       "2      EIVLTQSPGTLSLSPGERATLSCRASQSVSRSYFAWYQQKPGQAPR...   \n",
       "3      DIQMTQSPSTLSASVGDRVTITCRASQSISNWLAWYQQKPGKAPKF...   \n",
       "4      EIVLTQSPGTLSLSPGERATLSCRASQSVSSRYLAWYQQKPGQAPR...   \n",
       "...                                                  ...   \n",
       "46076  SYVLTQPPSVSVAPGQTARITCGGNNIGSKSVHWYQQKPGQAPVLV...   \n",
       "46077  DIVMTQTPLSLPVTPGEPASISCRSSQSLLDSDDGNTYLDWYLQKP...   \n",
       "46078  DIQMTQSPSTLSASVGDRVTITCRASQSISSWLAWYQQKPGKAPKL...   \n",
       "46079  SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWYQQKSGQAPVLV...   \n",
       "46080  DIVMTQSPDSLAVSLGERATINCKSSRSLLYSSNNKNYLAWYQQKP...   \n",
       "\n",
       "                gen_light_1_first_hit_gene gen_light_1_light_locus  \n",
       "0      IGLV3-19*01 unnamed protein product                     IGL  \n",
       "1      IGKV3-20*01 unnamed protein product                     IGK  \n",
       "2      IGKV3-20*01 unnamed protein product                     IGK  \n",
       "3       IGKV1-5*03 unnamed protein product                     IGK  \n",
       "4      IGKV3-20*01 unnamed protein product                     IGK  \n",
       "...                                    ...                     ...  \n",
       "46076  IGLV3-21*02 unnamed protein product                     IGL  \n",
       "46077  IGKV2-28*01 unnamed protein product                     IGK  \n",
       "46078   IGKV1-5*03 unnamed protein product                     IGK  \n",
       "46079  IGLV3-10*01 unnamed protein product                     IGL  \n",
       "46080  IGKV1-27*01 unnamed protein product                     IGK  \n",
       "\n",
       "[46081 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#quick_extract(input_csv=\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267_parsed_reformatted.csv\",  output_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267_parsed_reformatted_rel_cols.csv\")\n",
    "\n",
    "#quick_extract(input_csv=\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv\",  output_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols.csv\")\n",
    "\n",
    "quick_extract(input_csv=\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv\",  output_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fd97fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/matching_prediction_summary_full_eval_generate_multiple_light_seqs_203267_parsed_reformatted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbe9d777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['overall_id', 'heavy_raw_sequence', 'heavy_sequence_length',\n",
      "       'heavy_domain_classification', 'heavy_nt_trimmed',\n",
      "       'heavy_first_hit_gene', 'heavy_first_hit_bit_score',\n",
      "       'heavy_first_hit_e_value', 'heavy_gene_name', 'heavy_light_locus',\n",
      "       ...\n",
      "       'gen_light_10_FR3_matches', 'gen_light_10_FR3_mismatches',\n",
      "       'gen_light_10_FR3_gaps', 'gen_light_10_CDR3_sequence',\n",
      "       'gen_light_10_CDR3_length', 'gen_light_10_CDR3_percent_identity',\n",
      "       'gen_light_10_CDR3_matches', 'gen_light_10_CDR3_mismatches',\n",
      "       'gen_light_10_CDR3_gaps', 'gen_light_10_original_number'],\n",
      "      dtype='object', length=552)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    DIQLTQSPSFLSASVGDRVTITCRASQGISNFLAWYQQKPGKAPEL...\n",
       "1    DIVMTQSPDSLAVSLGERATINCKSSQSLFHSSNNKNYLAWYQQKP...\n",
       "Name: gen_light_1_nt_trimmed, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 2 rows the column gen_light_1_nt_trimmed\n",
    "print(df.columns)\n",
    "df['gen_light_1_nt_trimmed'].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280eee2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adap_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
