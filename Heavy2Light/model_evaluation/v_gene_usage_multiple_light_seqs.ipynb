{
 "cells": [
  {
   "cell_type": "code",
   "id": "2e513882",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b32af206",
   "metadata": {},
   "source": [
    "\n",
    "def simplify_gene_name(gene_name):\n",
    "    \"\"\"Remove allele designation (part after *) from gene name\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    return str(gene_name).split('*')[0]\n",
    "\n",
    "def extract_gene_family(gene_name):\n",
    "    \"\"\"Extract gene family (e.g., IGHV3 from IGHV3-23*01)\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    simplified = str(gene_name).split('*')[0]\n",
    "    # Extract family part (everything before the dash)\n",
    "    if '-' in simplified:\n",
    "        return simplified.split('-')[0]\n",
    "    return simplified\n",
    "\n",
    "def analyze_vgene_distribution(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of V genes and loci between heavy chains and generated light sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check if true light V gene column exists\n",
    "    true_light_vgene_col = None\n",
    "    possible_true_light_cols = ['true_light_gene_name', 'true_light_v_gene', 'light_gene_name', 'true_light_v_gene_name']\n",
    "    \n",
    "    for col in possible_true_light_cols:\n",
    "        if col in df.columns:\n",
    "            true_light_vgene_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"True light V gene column: {true_light_vgene_col if true_light_vgene_col else 'NOT FOUND'}\")\n",
    "    \n",
    "    # Get all relevant columns\n",
    "    light_gene_cols = [col for col in df.columns if col.startswith('gen_light_') and col.endswith('_gene_name')]\n",
    "    light_locus_cols = [col for col in df.columns if col.startswith('gen_light_') and col.endswith('_light_locus')]\n",
    "    \n",
    "    print(f\"Generated light gene columns found: {len(light_gene_cols)}\")\n",
    "    print(f\"Generated light locus columns found: {len(light_locus_cols)}\")\n",
    "    \n",
    "    # ============================\n",
    "    # V GENE ANALYSIS - GENERATED\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"GENERATED V GENE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Collect all heavy-light V gene pairs (full names)\n",
    "    heavy_light_pairs_full = []\n",
    "    vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        heavy_gene = row['heavy_gene_name']\n",
    "        if pd.isna(heavy_gene):\n",
    "            continue\n",
    "            \n",
    "        for col in light_gene_cols:\n",
    "            light_gene = row[col]\n",
    "            if not pd.isna(light_gene):\n",
    "                heavy_light_pairs_full.append((heavy_gene, light_gene))\n",
    "                vgene_dist_full[heavy_gene][light_gene] += 1\n",
    "    \n",
    "    print(f\"Total heavy-light V gene pairs (full): {len(heavy_light_pairs_full)}\")\n",
    "    \n",
    "    # Create simplified pairs\n",
    "    heavy_light_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                               for pair in heavy_light_pairs_full]\n",
    "    vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for heavy_gene, light_gene in heavy_light_pairs_simple:\n",
    "        if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "            vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "    \n",
    "    # Create family pairs\n",
    "    heavy_light_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                               for pair in heavy_light_pairs_full]\n",
    "    vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for heavy_family, light_family in heavy_light_pairs_family:\n",
    "        if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "            vgene_dist_family[heavy_family][light_family] += 1\n",
    "    \n",
    "    # Count frequencies\n",
    "    heavy_counts_full = Counter([pair[0] for pair in heavy_light_pairs_full])\n",
    "    light_counts_full = Counter([pair[1] for pair in heavy_light_pairs_full])\n",
    "    heavy_counts_simple = Counter([pair[0] for pair in heavy_light_pairs_simple if not pd.isna(pair[0])])\n",
    "    light_counts_simple = Counter([pair[1] for pair in heavy_light_pairs_simple if not pd.isna(pair[1])])\n",
    "    heavy_counts_family = Counter([pair[0] for pair in heavy_light_pairs_family if not pd.isna(pair[0])])\n",
    "    light_counts_family = Counter([pair[1] for pair in heavy_light_pairs_family if not pd.isna(pair[1])])\n",
    "    \n",
    "    print(f\"Generated - Full Names: {len(heavy_counts_full)} heavy, {len(light_counts_full)} light\")\n",
    "    print(f\"Generated - Simplified: {len(heavy_counts_simple)} heavy, {len(light_counts_simple)} light\")\n",
    "    print(f\"Generated - Families: {len(heavy_counts_family)} heavy, {len(light_counts_family)} light\")\n",
    "    \n",
    "    # ============================\n",
    "    # V GENE ANALYSIS - TRUE\n",
    "    # ============================\n",
    "    \n",
    "    # Initialize true data variables\n",
    "    true_vgene_dist_full = None\n",
    "    true_vgene_dist_simple = None\n",
    "    true_vgene_dist_family = None\n",
    "    true_heavy_counts_full = Counter()\n",
    "    true_light_counts_full = Counter()\n",
    "    true_heavy_counts_simple = Counter()\n",
    "    true_light_counts_simple = Counter()\n",
    "    true_heavy_counts_family = Counter()\n",
    "    true_light_counts_family = Counter()\n",
    "    \n",
    "    if true_light_vgene_col:\n",
    "        print(\"\\nTRUE V GENE ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Collect all heavy-true light V gene pairs\n",
    "        heavy_true_pairs_full = []\n",
    "        true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            heavy_gene = row['heavy_gene_name']\n",
    "            true_light_gene = row[true_light_vgene_col]\n",
    "            if pd.isna(heavy_gene) or pd.isna(true_light_gene):\n",
    "                continue\n",
    "            \n",
    "            heavy_true_pairs_full.append((heavy_gene, true_light_gene))\n",
    "            true_vgene_dist_full[heavy_gene][true_light_gene] += 1\n",
    "        \n",
    "        print(f\"Total heavy-true light V gene pairs: {len(heavy_true_pairs_full)}\")\n",
    "        \n",
    "        # Create simplified and family versions for true data\n",
    "        heavy_true_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                                  for pair in heavy_true_pairs_full]\n",
    "        heavy_true_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                                  for pair in heavy_true_pairs_full]\n",
    "        \n",
    "        true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "        true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for heavy_gene, light_gene in heavy_true_pairs_simple:\n",
    "            if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                true_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "        \n",
    "        for heavy_family, light_family in heavy_true_pairs_family:\n",
    "            if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                true_vgene_dist_family[heavy_family][light_family] += 1\n",
    "        \n",
    "        # Count frequencies for true data\n",
    "        true_heavy_counts_full = Counter([pair[0] for pair in heavy_true_pairs_full])\n",
    "        true_light_counts_full = Counter([pair[1] for pair in heavy_true_pairs_full])\n",
    "        true_heavy_counts_simple = Counter([pair[0] for pair in heavy_true_pairs_simple if not pd.isna(pair[0])])\n",
    "        true_light_counts_simple = Counter([pair[1] for pair in heavy_true_pairs_simple if not pd.isna(pair[1])])\n",
    "        true_heavy_counts_family = Counter([pair[0] for pair in heavy_true_pairs_family if not pd.isna(pair[0])])\n",
    "        true_light_counts_family = Counter([pair[1] for pair in heavy_true_pairs_family if not pd.isna(pair[1])])\n",
    "        \n",
    "        print(f\"True - Full Names: {len(true_heavy_counts_full)} heavy, {len(true_light_counts_full)} light\")\n",
    "        print(f\"True - Simplified: {len(true_heavy_counts_simple)} heavy, {len(true_light_counts_simple)} light\")\n",
    "        print(f\"True - Families: {len(true_heavy_counts_family)} heavy, {len(true_light_counts_family)} light\")\n",
    "    \n",
    "    # ============================\n",
    "    # LOCUS ANALYSIS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"LOCUS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Analyze true vs generated loci\n",
    "    true_gen_locus_pairs = []\n",
    "    locus_dist = defaultdict(lambda: defaultdict(int))\n",
    "    locus_accuracy = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        true_locus = row['true_light_light_locus']\n",
    "        if pd.isna(true_locus):\n",
    "            continue\n",
    "            \n",
    "        for col in light_locus_cols:\n",
    "            gen_locus = row[col]\n",
    "            if not pd.isna(gen_locus):\n",
    "                true_gen_locus_pairs.append((true_locus, gen_locus))\n",
    "                locus_dist[true_locus][gen_locus] += 1\n",
    "                locus_accuracy[true_locus]['total'] += 1\n",
    "                if gen_locus == true_locus:\n",
    "                    locus_accuracy[true_locus]['correct'] += 1\n",
    "    \n",
    "    print(f\"Total true-generated locus pairs: {len(true_gen_locus_pairs)}\")\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    total_generated = sum([stats['total'] for stats in locus_accuracy.values()])\n",
    "    total_correct = sum([stats['correct'] for stats in locus_accuracy.values()])\n",
    "    overall_accuracy = (total_correct / total_generated * 100) if total_generated > 0 else 0\n",
    "    \n",
    "    print(f\"Overall locus accuracy: {overall_accuracy:.1f}% ({total_correct}/{total_generated})\")\n",
    "    \n",
    "    # ============================\n",
    "    # COVERAGE ANALYSIS\n",
    "    # ============================\n",
    "    \n",
    "    def analyze_coverage(heavy_counts, light_counts, vgene_dist, level_name):\n",
    "        total_heavy_genes = len(heavy_counts)\n",
    "        total_light_genes = len(light_counts)\n",
    "        \n",
    "        # Count total associations\n",
    "        total_associations = sum(sum(light_dist.values()) for light_dist in vgene_dist.values())\n",
    "        \n",
    "        # Get top 5 genes\n",
    "        top_5_heavy = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "        top_5_light = [gene for gene, _ in light_counts.most_common(5)]\n",
    "        \n",
    "        # Calculate coverage of top 5 associations\n",
    "        top_5_associations = 0\n",
    "        for heavy in top_5_heavy:\n",
    "            for light in top_5_light:\n",
    "                top_5_associations += vgene_dist[heavy][light]\n",
    "        \n",
    "        coverage_pct = (top_5_associations / total_associations * 100) if total_associations > 0 else 0\n",
    "        \n",
    "        print(f\"{level_name}: {total_heavy_genes}x{total_light_genes} genes, 5x5 covers {coverage_pct:.1f}%\")\n",
    "        \n",
    "        return total_heavy_genes, total_light_genes, coverage_pct\n",
    "    \n",
    "    print(\"\\nCoverage Analysis:\")\n",
    "    full_coverage = analyze_coverage(heavy_counts_full, light_counts_full, vgene_dist_full, \"Full Names\")\n",
    "    simple_coverage = analyze_coverage(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \"Simplified\")\n",
    "    family_coverage = analyze_coverage(heavy_counts_family, light_counts_family, vgene_dist_family, \"Families\")\n",
    "    \n",
    "    # ============================\n",
    "    # HEATMAPS\n",
    "    # ============================\n",
    "    \n",
    "    def create_complete_contingency(heavy_counts, light_counts, vgene_dist):\n",
    "        all_heavy = list(heavy_counts.keys())\n",
    "        all_light = list(light_counts.keys())\n",
    "        \n",
    "        contingency = np.zeros((len(all_heavy), len(all_light)))\n",
    "        \n",
    "        for i, heavy_gene in enumerate(all_heavy):\n",
    "            for j, light_gene in enumerate(all_light):\n",
    "                contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        return contingency, all_heavy, all_light\n",
    "    \n",
    "    def create_heatmap(heavy_counts, light_counts, vgene_dist, title, cmap='YlOrRd', complete=False):\n",
    "        if complete:\n",
    "            contingency, heavy_genes, light_genes = create_complete_contingency(heavy_counts, light_counts, vgene_dist)\n",
    "        else:\n",
    "            heavy_genes = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "            light_genes = [gene for gene, _ in light_counts.most_common(5)]\n",
    "            \n",
    "            if len(heavy_genes) < 2 or len(light_genes) < 2:\n",
    "                print(f\"Insufficient data for {title}\")\n",
    "                return\n",
    "            \n",
    "            contingency = np.zeros((len(heavy_genes), len(light_genes)))\n",
    "            for i, heavy_gene in enumerate(heavy_genes):\n",
    "                for j, light_gene in enumerate(light_genes):\n",
    "                    contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        # Dynamic figure sizing\n",
    "        fig_width = max(8, len(light_genes) * 0.6)\n",
    "        fig_height = max(6, len(heavy_genes) * 0.5)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(fig_width, fig_height))\n",
    "        \n",
    "        im = ax.imshow(contingency, cmap=cmap, aspect='auto')\n",
    "        ax.set_xticks(range(len(light_genes)))\n",
    "        ax.set_yticks(range(len(heavy_genes)))\n",
    "        ax.set_xticklabels(light_genes, rotation=45, ha='right', fontsize=8)\n",
    "        ax.set_yticklabels(heavy_genes, fontsize=16)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Light V Genes')\n",
    "        ax.set_ylabel('Heavy V Genes')\n",
    "        \n",
    "        # Add annotations for smaller heatmaps\n",
    "        if len(heavy_genes) <= 15 and len(light_genes) <= 15:\n",
    "            for i in range(len(heavy_genes)):\n",
    "                for j in range(len(light_genes)):\n",
    "                    text_color = 'white' if contingency[i, j] > np.max(contingency) * 0.5 else 'black'\n",
    "                    ax.text(j, i, int(contingency[i, j]), ha='center', va='center', \n",
    "                           fontsize=14, color=text_color)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return contingency\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"CREATING HEATMAPS...\")\n",
    "    \n",
    "    # GENERATED V GENE HEATMAPS\n",
    "    print(\"\\n--- GENERATED V GENE ASSOCIATION HEATMAPS ---\")\n",
    "    \n",
    "    # 5x5 heatmaps\n",
    "    create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                  \"Generated V Gene Associations (Full Names - Top 5x5)\")\n",
    "    \n",
    "    create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                  \"Generated V Gene Associations (Simplified - Top 5x5)\")\n",
    "    \n",
    "    create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                  \"Generated V Gene Associations (Families - Top 5x5)\")\n",
    "    \n",
    "    # Complete heatmaps when feasible\n",
    "    print(\"\\n--- COMPLETE GENERATED V GENE HEATMAPS ---\")\n",
    "    \n",
    "    if family_coverage[0] <= 15 and family_coverage[1] <= 15:\n",
    "        create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                      f\"Complete Generated Gene Family Associations ({family_coverage[0]}x{family_coverage[1]})\", \n",
    "                      complete=True)\n",
    "    \n",
    "    if simple_coverage[0] <= 20 and simple_coverage[1] <= 20:\n",
    "        create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                      f\"Complete Generated Simplified Associations ({simple_coverage[0]}x{simple_coverage[1]})\", \n",
    "                      complete=True)\n",
    "    \n",
    "    if full_coverage[0] <= 25 and full_coverage[1] <= 25:\n",
    "        create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                      f\"Complete Generated Full Name Associations ({full_coverage[0]}x{full_coverage[1]})\", \n",
    "                      complete=True)\n",
    "    \n",
    "    # TRUE V GENE HEATMAPS (if available)\n",
    "    if true_light_vgene_col and true_vgene_dist_full:\n",
    "        print(\"\\n--- TRUE V GENE ASSOCIATION HEATMAPS ---\")\n",
    "        \n",
    "        # Calculate true coverage\n",
    "        true_full_coverage = analyze_coverage(true_heavy_counts_full, true_light_counts_full, true_vgene_dist_full, \"True Full\")\n",
    "        true_simple_coverage = analyze_coverage(true_heavy_counts_simple, true_light_counts_simple, true_vgene_dist_simple, \"True Simplified\")\n",
    "        true_family_coverage = analyze_coverage(true_heavy_counts_family, true_light_counts_family, true_vgene_dist_family, \"True Families\")\n",
    "        \n",
    "        # 5x5 true heatmaps\n",
    "        create_heatmap(true_heavy_counts_full, true_light_counts_full, true_vgene_dist_full, \n",
    "                      \"TRUE V Gene Associations (Full Names - Top 5x5)\", cmap='Reds')\n",
    "        \n",
    "        create_heatmap(true_heavy_counts_simple, true_light_counts_simple, true_vgene_dist_simple, \n",
    "                      \"TRUE V Gene Associations (Simplified - Top 5x5)\", cmap='Reds')\n",
    "        \n",
    "        create_heatmap(true_heavy_counts_family, true_light_counts_family, true_vgene_dist_family, \n",
    "                      \"TRUE V Gene Associations (Families - Top 5x5)\", cmap='Reds')\n",
    "        \n",
    "        # Complete true heatmaps when feasible\n",
    "        print(\"\\n--- COMPLETE TRUE V GENE HEATMAPS ---\")\n",
    "        \n",
    "        if true_family_coverage[0] <= 15 and true_family_coverage[1] <= 15:\n",
    "            create_heatmap(true_heavy_counts_family, true_light_counts_family, true_vgene_dist_family, \n",
    "                          f\"Complete TRUE Gene Family Associations ({true_family_coverage[0]}x{true_family_coverage[1]})\", \n",
    "                          cmap='Reds', complete=True)\n",
    "        \n",
    "        if true_simple_coverage[0] <= 20 and true_simple_coverage[1] <= 20:\n",
    "            create_heatmap(true_heavy_counts_simple, true_light_counts_simple, true_vgene_dist_simple, \n",
    "                          f\"Complete TRUE Simplified Associations ({true_simple_coverage[0]}x{true_simple_coverage[1]})\", \n",
    "                          cmap='Reds', complete=True)\n",
    "        \n",
    "        if true_full_coverage[0] <= 25 and true_full_coverage[1] <= 25:\n",
    "            create_heatmap(true_heavy_counts_full, true_light_counts_full, true_vgene_dist_full, \n",
    "                          f\"Complete TRUE Full Name Associations ({true_full_coverage[0]}x{true_full_coverage[1]})\", \n",
    "                          cmap='Reds', complete=True)\n",
    "    \n",
    "    # LOCUS HEATMAP\n",
    "    print(\"\\n--- LOCUS ASSOCIATION HEATMAP ---\")\n",
    "    \n",
    "    true_locus_counts = Counter([pair[0] for pair in true_gen_locus_pairs])\n",
    "    gen_locus_counts = Counter([pair[1] for pair in true_gen_locus_pairs])\n",
    "    \n",
    "    unique_true_loci = list(true_locus_counts.keys())\n",
    "    unique_gen_loci = list(gen_locus_counts.keys())\n",
    "    \n",
    "    if len(unique_true_loci) >= 2 and len(unique_gen_loci) >= 2:\n",
    "        locus_contingency = np.zeros((len(unique_true_loci), len(unique_gen_loci)))\n",
    "        \n",
    "        for i, true_locus in enumerate(unique_true_loci):\n",
    "            for j, gen_locus in enumerate(unique_gen_loci):\n",
    "                locus_contingency[i, j] = locus_dist[true_locus][gen_locus]\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        im = ax.imshow(locus_contingency, cmap='Blues', aspect='auto')\n",
    "        ax.set_xticks(range(len(unique_gen_loci)))\n",
    "        ax.set_yticks(range(len(unique_true_loci)))\n",
    "        ax.set_xticklabels(unique_gen_loci, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(unique_true_loci)\n",
    "        ax.set_title('Locus Association Heatmap (True vs Generated)')\n",
    "        ax.set_xlabel('Generated Light Chain Loci')\n",
    "        ax.set_ylabel('True Light Chain Loci')\n",
    "        \n",
    "        # Add annotations\n",
    "        for i in range(len(unique_true_loci)):\n",
    "            for j in range(len(unique_gen_loci)):\n",
    "                text_color = 'white' if locus_contingency[i, j] > np.max(locus_contingency) * 0.5 else 'black'\n",
    "                ax.text(j, i, int(locus_contingency[i, j]), ha='center', va='center', color=text_color)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # ============================\n",
    "    # RETURN RESULTS\n",
    "    # ============================\n",
    "    \n",
    "    return {\n",
    "        'heavy_counts_full': heavy_counts_full,\n",
    "        'light_counts_full': light_counts_full,\n",
    "        'heavy_counts_simple': heavy_counts_simple,\n",
    "        'light_counts_simple': light_counts_simple,\n",
    "        'heavy_counts_family': heavy_counts_family,\n",
    "        'light_counts_family': light_counts_family,\n",
    "        'true_heavy_counts_full': true_heavy_counts_full,\n",
    "        'true_light_counts_full': true_light_counts_full,\n",
    "        'true_heavy_counts_simple': true_heavy_counts_simple,\n",
    "        'true_light_counts_simple': true_light_counts_simple,\n",
    "        'true_heavy_counts_family': true_heavy_counts_family,\n",
    "        'true_light_counts_family': true_light_counts_family,\n",
    "        'vgene_dist_full': dict(vgene_dist_full),\n",
    "        'vgene_dist_simple': dict(vgene_dist_simple),\n",
    "        'vgene_dist_family': dict(vgene_dist_family),\n",
    "        'true_vgene_dist_full': dict(true_vgene_dist_full) if true_vgene_dist_full else None,\n",
    "        'true_vgene_dist_simple': dict(true_vgene_dist_simple) if true_vgene_dist_simple else None,\n",
    "        'true_vgene_dist_family': dict(true_vgene_dist_family) if true_vgene_dist_family else None,\n",
    "        'locus_dist': dict(locus_dist),\n",
    "        'locus_accuracy': dict(locus_accuracy),\n",
    "        'overall_locus_accuracy': overall_accuracy,\n",
    "        'coverage_analysis': {\n",
    "            'generated': {\n",
    "                'full': full_coverage,\n",
    "                'simple': simple_coverage,\n",
    "                'family': family_coverage\n",
    "            },\n",
    "            'true': {\n",
    "                'full': true_full_coverage if true_light_vgene_col else None,\n",
    "                'simple': true_simple_coverage if true_light_vgene_col else None,\n",
    "                'family': true_family_coverage if true_light_vgene_col else None\n",
    "            } if true_light_vgene_col else None\n",
    "        },\n",
    "        'true_light_vgene_col': true_light_vgene_col\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0aac4024",
   "metadata": {},
   "source": [
    "#csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv'\n",
    "\n",
    "csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv'\n",
    "\n",
    "try:\n",
    "    results = analyze_vgene_distribution(csv_file)\n",
    "    print(\"\\nAnalysis completed successfully!\")\n",
    "    print(\"\\nReturned results contain:\")\n",
    "    print(\"- vgene_diversity: DataFrame with diversity statistics\")\n",
    "    print(\"- heavy_vgene_counts: Counter of heavy V gene frequencies\")\n",
    "    print(\"- light_vgene_counts: Counter of light V gene frequencies\")\n",
    "    print(\"- heavy_locus_counts: Counter of heavy locus frequencies\")\n",
    "    print(\"- light_locus_counts: Counter of light locus frequencies\")\n",
    "    print(\"- vgene_chi2: Chi-square test results for V gene associations\")\n",
    "    print(\"- locus_chi2: Chi-square test results for locus associations\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the file '{csv_file}'\")\n",
    "    print(\"Please make sure the file path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6aefae7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/pairing_result_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols.csv')\n",
    "df2 = pd.read_csv('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv')\n",
    "\n",
    "\n",
    "# Check if all merge columns exist in both DataFrames\n",
    "merge_cols = ['overall_id', 'heavy_raw_sequence','true_light_raw_sequence', \n",
    "              'true_light_first_hit_gene', 'true_light_gene_name', 'true_light_light_locus',\n",
    "              'gen_light_1_raw_sequence', 'gen_light_1_nt_trimmed']\n",
    "\n",
    "print(\"Columns in df1:\", df1.columns.tolist())\n",
    "print(\"Columns in df2:\", df2.columns.tolist())\n",
    "\n",
    "# Check for missing columns\n",
    "missing_df1 = [col for col in merge_cols if col not in df1.columns]\n",
    "missing_df2 = [col for col in merge_cols if col not in df2.columns]\n",
    "\n",
    "if missing_df1:\n",
    "    print(f\"Missing columns in df1: {missing_df1}\")\n",
    "if missing_df2:\n",
    "    print(f\"Missing columns in df2: {missing_df2}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types comparison:\")\n",
    "for col in merge_cols:\n",
    "    if col in df1.columns and col in df2.columns:\n",
    "        print(f\"{col}: df1={df1[col].dtype}, df2={df2[col].dtype}\")\n",
    "\n",
    "# Perform merge\n",
    "merged = df1.merge(df2, on=merge_cols, how='left', suffixes=('', '_df2'))\n",
    "\n",
    "print(f\"\\nMerged: {len(merged)} rows\")\n",
    "\n",
    "# Better way to check unmatched rows - look for nulls in df2 columns only\n",
    "df2_cols = [col for col in merged.columns if col.endswith('_df2') or col in df2.columns]\n",
    "unmatched = merged[df2_cols].isnull().all(axis=1).sum()\n",
    "print(f\"Unmatched rows: {unmatched}\")\n",
    "\n",
    "# Save the merged DataFrame\n",
    "merged.to_csv('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/pairing_result_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols_merged_complete.csv', index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "816efcc7",
   "metadata": {},
   "source": [
    "def simplify_gene_name(gene_name):\n",
    "    \"\"\"Remove allele designation (part after *) from gene name\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    return str(gene_name).split('*')[0]\n",
    "\n",
    "def extract_gene_family(gene_name):\n",
    "    \"\"\"Extract gene family (e.g., IGHV3 from IGHV3-23*01)\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    simplified = str(gene_name).split('*')[0]\n",
    "    # Extract family part (everything before the dash)\n",
    "    if '-' in simplified:\n",
    "        return simplified.split('-')[0]\n",
    "    return simplified\n",
    "\n",
    "def analyze_vgene_by_pairing_score(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze V gene distributions grouped by pairing scores (<0.5 vs ≥0.5)\n",
    "    and compare generated vs true light chain V genes.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['pairing_scores', 'true_light_gene_name', 'gen_light_1_first_hit_gene']\n",
    "    \n",
    "    # Check for heavy chain V gene column\n",
    "    heavy_gene_col = None\n",
    "    possible_heavy_cols = ['heavy_gene_name', 'true_v_gene_simple', 'heavy_v_gene', 'true_heavy_gene']\n",
    "    \n",
    "    for col in possible_heavy_cols:\n",
    "        if col in df.columns:\n",
    "            heavy_gene_col = col\n",
    "            break\n",
    "    \n",
    "    if heavy_gene_col:\n",
    "        required_cols.append(heavy_gene_col)\n",
    "        print(f\"✅ Using heavy chain V gene column: {heavy_gene_col}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No heavy chain V gene column found. Searched for: {possible_heavy_cols}\")\n",
    "        print(f\"Available columns: {df.columns.tolist()}\")\n",
    "        print(f\"Will skip heavy-light V gene pairing analysis and focus on light chain only.\")\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"❌ Missing required columns: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Required columns found\")\n",
    "    \n",
    "    # ============================\n",
    "    # DATA PREPARATION\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"DATA PREPARATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Remove rows with missing pairing scores\n",
    "    df_clean = df.dropna(subset=['pairing_scores']).copy()\n",
    "    print(f\"Rows with pairing scores: {len(df_clean)}/{len(df)} ({len(df_clean)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Group by pairing score threshold\n",
    "    df_low = df_clean[df_clean['pairing_scores'] < 0.5].copy()\n",
    "    df_high = df_clean[df_clean['pairing_scores'] >= 0.5].copy()\n",
    "    \n",
    "    print(f\"Low pairing scores (<0.5): {len(df_low)} rows ({len(df_low)/len(df_clean)*100:.1f}%)\")\n",
    "    print(f\"High pairing scores (≥0.5): {len(df_high)} rows ({len(df_high)/len(df_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Pairing score statistics\n",
    "    print(f\"\\nPairing Score Statistics:\")\n",
    "    print(f\"Overall - Mean: {df_clean['pairing_scores'].mean():.3f}, Median: {df_clean['pairing_scores'].median():.3f}\")\n",
    "    if len(df_low) > 0:\n",
    "        print(f\"Low group - Mean: {df_low['pairing_scores'].mean():.3f}, Range: {df_low['pairing_scores'].min():.3f}-{df_low['pairing_scores'].max():.3f}\")\n",
    "    if len(df_high) > 0:\n",
    "        print(f\"High group - Mean: {df_high['pairing_scores'].mean():.3f}, Range: {df_high['pairing_scores'].min():.3f}-{df_high['pairing_scores'].max():.3f}\")\n",
    "    \n",
    "    def analyze_group(df_group, group_name):\n",
    "        \"\"\"Analyze V gene distributions for a specific pairing score group\"\"\"\n",
    "        \n",
    "        if len(df_group) == 0:\n",
    "            print(f\"\\n⚠️ No data for {group_name} group\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{group_name.upper()} PAIRING SCORE GROUP ANALYSIS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # ============================\n",
    "        # GENERATED V GENE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nGENERATED LIGHT CHAIN V GENE ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Collect generated light chain V genes\n",
    "        gen_light_genes = []\n",
    "        for idx, row in df_group.iterrows():\n",
    "            gen_light_gene = row['gen_light_1_first_hit_gene']\n",
    "            if not pd.isna(gen_light_gene):\n",
    "                gen_light_genes.append(gen_light_gene)\n",
    "        \n",
    "        print(f\"Generated light V genes: {len(gen_light_genes)}\")\n",
    "        \n",
    "        # Create simplified and family versions for generated\n",
    "        gen_light_simple = [simplify_gene_name(gene) for gene in gen_light_genes if not pd.isna(gene)]\n",
    "        gen_light_family = [extract_gene_family(gene) for gene in gen_light_genes if not pd.isna(gene)]\n",
    "        \n",
    "        # Count frequencies for generated\n",
    "        gen_light_counts_full = Counter(gen_light_genes)\n",
    "        gen_light_counts_simple = Counter([gene for gene in gen_light_simple if not pd.isna(gene)])\n",
    "        gen_light_counts_family = Counter([gene for gene in gen_light_family if not pd.isna(gene)])\n",
    "        \n",
    "        print(f\"Generated - Full: {len(gen_light_counts_full)} unique genes\")\n",
    "        print(f\"Generated - Simple: {len(gen_light_counts_simple)} unique genes\")\n",
    "        print(f\"Generated - Family: {len(gen_light_counts_family)} unique families\")\n",
    "        \n",
    "        # ============================\n",
    "        # TRUE V GENE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nTRUE LIGHT CHAIN V GENE ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Collect true light chain V genes\n",
    "        true_light_genes = []\n",
    "        for idx, row in df_group.iterrows():\n",
    "            true_light_gene = row['true_light_gene_name']\n",
    "            if not pd.isna(true_light_gene):\n",
    "                true_light_genes.append(true_light_gene)\n",
    "        \n",
    "        print(f\"True light V genes: {len(true_light_genes)}\")\n",
    "        \n",
    "        # Create simplified and family versions for true\n",
    "        true_light_simple = [simplify_gene_name(gene) for gene in true_light_genes if not pd.isna(gene)]\n",
    "        true_light_family = [extract_gene_family(gene) for gene in true_light_genes if not pd.isna(gene)]\n",
    "        \n",
    "        # Count frequencies for true\n",
    "        true_light_counts_full = Counter(true_light_genes)\n",
    "        true_light_counts_simple = Counter([gene for gene in true_light_simple if not pd.isna(gene)])\n",
    "        true_light_counts_family = Counter([gene for gene in true_light_family if not pd.isna(gene)])\n",
    "        \n",
    "        print(f\"True - Full: {len(true_light_counts_full)} unique genes\")\n",
    "        print(f\"True - Simple: {len(true_light_counts_simple)} unique genes\") \n",
    "        print(f\"True - Family: {len(true_light_counts_family)} unique families\")\n",
    "        \n",
    "        # ============================\n",
    "        # HEAVY-LIGHT PAIRING ANALYSIS (if heavy chain data available)\n",
    "        # ============================\n",
    "        \n",
    "        if heavy_gene_col:\n",
    "            print(f\"\\nHEAVY-LIGHT V GENE PAIRING ANALYSIS - {group_name}\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Generated heavy-light pairs\n",
    "            gen_pairs_full = []\n",
    "            gen_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for idx, row in df_group.iterrows():\n",
    "                heavy_gene = row[heavy_gene_col]\n",
    "                gen_light_gene = row['gen_light_1_first_hit_gene']\n",
    "                \n",
    "                if pd.isna(heavy_gene) or pd.isna(gen_light_gene):\n",
    "                    continue\n",
    "                \n",
    "                gen_pairs_full.append((heavy_gene, gen_light_gene))\n",
    "                gen_vgene_dist_full[heavy_gene][gen_light_gene] += 1\n",
    "            \n",
    "            # True heavy-light pairs\n",
    "            true_pairs_full = []\n",
    "            true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for idx, row in df_group.iterrows():\n",
    "                heavy_gene = row[heavy_gene_col]\n",
    "                true_light_gene = row['true_light_gene_name']\n",
    "                \n",
    "                if pd.isna(heavy_gene) or pd.isna(true_light_gene):\n",
    "                    continue\n",
    "                \n",
    "                true_pairs_full.append((heavy_gene, true_light_gene))\n",
    "                true_vgene_dist_full[heavy_gene][true_light_gene] += 1\n",
    "            \n",
    "            print(f\"Generated heavy-light pairs: {len(gen_pairs_full)}\")\n",
    "            print(f\"True heavy-light pairs: {len(true_pairs_full)}\")\n",
    "            \n",
    "            # Create simplified and family versions for pairing\n",
    "            gen_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                               for pair in gen_pairs_full]\n",
    "            gen_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                               for pair in gen_pairs_full]\n",
    "            \n",
    "            true_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                                for pair in true_pairs_full]\n",
    "            true_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                                for pair in true_pairs_full]\n",
    "            \n",
    "            # Create distribution dictionaries\n",
    "            gen_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for heavy_gene, light_gene in gen_pairs_simple:\n",
    "                if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                    gen_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "            \n",
    "            for heavy_family, light_family in gen_pairs_family:\n",
    "                if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                    gen_vgene_dist_family[heavy_family][light_family] += 1\n",
    "            \n",
    "            for heavy_gene, light_gene in true_pairs_simple:\n",
    "                if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                    true_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "            \n",
    "            for heavy_family, light_family in true_pairs_family:\n",
    "                if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                    true_vgene_dist_family[heavy_family][light_family] += 1\n",
    "            \n",
    "            # Count heavy chain frequencies\n",
    "            gen_heavy_counts_full = Counter([pair[0] for pair in gen_pairs_full])\n",
    "            gen_heavy_counts_simple = Counter([pair[0] for pair in gen_pairs_simple if not pd.isna(pair[0])])\n",
    "            gen_heavy_counts_family = Counter([pair[0] for pair in gen_pairs_family if not pd.isna(pair[0])])\n",
    "            \n",
    "            true_heavy_counts_full = Counter([pair[0] for pair in true_pairs_full])\n",
    "            true_heavy_counts_simple = Counter([pair[0] for pair in true_pairs_simple if not pd.isna(pair[0])])\n",
    "            true_heavy_counts_family = Counter([pair[0] for pair in true_pairs_family if not pd.isna(pair[0])])\n",
    "            \n",
    "        else:\n",
    "            # No heavy chain data - create empty distributions\n",
    "            gen_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            gen_heavy_counts_full = Counter()\n",
    "            gen_heavy_counts_simple = Counter()\n",
    "            gen_heavy_counts_family = Counter()\n",
    "            true_heavy_counts_full = Counter()\n",
    "            true_heavy_counts_simple = Counter()\n",
    "            true_heavy_counts_family = Counter()\n",
    "        \n",
    "        # ============================\n",
    "        # LOCUS ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nLOCUS ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Analyze true vs generated loci\n",
    "        locus_pairs = []\n",
    "        locus_dist = defaultdict(lambda: defaultdict(int))\n",
    "        locus_accuracy = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "        \n",
    "        for idx, row in df_group.iterrows():\n",
    "            true_locus = row['true_light_light_locus']\n",
    "            gen_locus = row['gen_light_1_light_locus']\n",
    "            \n",
    "            if pd.isna(true_locus) or pd.isna(gen_locus):\n",
    "                continue\n",
    "            \n",
    "            locus_pairs.append((true_locus, gen_locus))\n",
    "            locus_dist[true_locus][gen_locus] += 1\n",
    "            locus_accuracy[true_locus]['total'] += 1\n",
    "            if gen_locus == true_locus:\n",
    "                locus_accuracy[true_locus]['correct'] += 1\n",
    "        \n",
    "        print(f\"True-generated locus pairs: {len(locus_pairs)}\")\n",
    "        \n",
    "        # Calculate overall locus accuracy\n",
    "        total_generated = sum([stats['total'] for stats in locus_accuracy.values()])\n",
    "        total_correct = sum([stats['correct'] for stats in locus_accuracy.values()])\n",
    "        overall_accuracy = (total_correct / total_generated * 100) if total_generated > 0 else 0\n",
    "        \n",
    "        print(f\"Locus accuracy: {overall_accuracy:.1f}% ({total_correct}/{total_generated})\")\n",
    "        \n",
    "        # ============================\n",
    "        # COVERAGE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        def analyze_coverage(heavy_counts, light_counts, vgene_dist, level_name):\n",
    "            total_heavy_genes = len(heavy_counts)\n",
    "            total_light_genes = len(light_counts)\n",
    "            \n",
    "            if total_heavy_genes == 0 or total_light_genes == 0:\n",
    "                return 0, 0, 0\n",
    "            \n",
    "            # Count total associations\n",
    "            total_associations = sum(sum(light_dist.values()) for light_dist in vgene_dist.values())\n",
    "            \n",
    "            # Get top 5 genes\n",
    "            top_5_heavy = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "            top_5_light = [gene for gene, _ in light_counts.most_common(5)]\n",
    "            \n",
    "            # Calculate coverage of top 5 associations\n",
    "            top_5_associations = 0\n",
    "            for heavy in top_5_heavy:\n",
    "                for light in top_5_light:\n",
    "                    top_5_associations += vgene_dist[heavy][light]\n",
    "            \n",
    "            coverage_pct = (top_5_associations / total_associations * 100) if total_associations > 0 else 0\n",
    "            \n",
    "            return total_heavy_genes, total_light_genes, coverage_pct\n",
    "        \n",
    "        print(f\"\\nCoverage Analysis - {group_name}:\")\n",
    "        gen_full_cov = analyze_coverage(gen_heavy_counts_full, gen_light_counts_full, gen_vgene_dist_full, \"Gen Full\")\n",
    "        gen_simple_cov = analyze_coverage(gen_heavy_counts_simple, gen_light_counts_simple, gen_vgene_dist_simple, \"Gen Simple\")\n",
    "        gen_family_cov = analyze_coverage(gen_heavy_counts_family, gen_light_counts_family, gen_vgene_dist_family, \"Gen Family\")\n",
    "        true_full_cov = analyze_coverage(true_heavy_counts_full, true_light_counts_full, true_vgene_dist_full, \"True Full\")\n",
    "        true_simple_cov = analyze_coverage(true_heavy_counts_simple, true_light_counts_simple, true_vgene_dist_simple, \"True Simple\")\n",
    "        true_family_cov = analyze_coverage(true_heavy_counts_family, true_light_counts_family, true_vgene_dist_family, \"True Family\")\n",
    "        \n",
    "        print(f\"Generated - Full: {gen_full_cov[0]}x{gen_light_counts_full if gen_light_counts_full else 0}, 5x5 covers {gen_full_cov[2]:.1f}%\")\n",
    "        print(f\"Generated - Simple: {gen_simple_cov[0]}x{len(gen_light_counts_simple)}, 5x5 covers {gen_simple_cov[2]:.1f}%\")\n",
    "        print(f\"Generated - Family: {gen_family_cov[0]}x{len(gen_light_counts_family)}, 5x5 covers {gen_family_cov[2]:.1f}%\")\n",
    "        print(f\"True - Full: {true_full_cov[0]}x{len(true_light_counts_full)}, 5x5 covers {true_full_cov[2]:.1f}%\")\n",
    "        print(f\"True - Simple: {true_simple_cov[0]}x{len(true_light_counts_simple)}, 5x5 covers {true_simple_cov[2]:.1f}%\")\n",
    "        print(f\"True - Family: {true_family_cov[0]}x{len(true_light_counts_family)}, 5x5 covers {true_family_cov[2]:.1f}%\")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'group_name': group_name,\n",
    "            'n_rows': len(df_group),\n",
    "            'heavy_gene_col': heavy_gene_col,\n",
    "            'gen_light_counts_full': gen_light_counts_full,\n",
    "            'gen_light_counts_simple': gen_light_counts_simple,\n",
    "            'gen_light_counts_family': gen_light_counts_family,\n",
    "            'true_light_counts_full': true_light_counts_full,\n",
    "            'true_light_counts_simple': true_light_counts_simple,\n",
    "            'true_light_counts_family': true_light_counts_family,\n",
    "            'gen_heavy_counts_full': gen_heavy_counts_full,\n",
    "            'gen_heavy_counts_simple': gen_heavy_counts_simple,\n",
    "            'gen_heavy_counts_family': gen_heavy_counts_family,\n",
    "            'true_heavy_counts_full': true_heavy_counts_full,\n",
    "            'true_heavy_counts_simple': true_heavy_counts_simple,\n",
    "            'true_heavy_counts_family': true_heavy_counts_family,\n",
    "            'gen_vgene_dist_full': dict(gen_vgene_dist_full),\n",
    "            'gen_vgene_dist_simple': dict(gen_vgene_dist_simple),\n",
    "            'gen_vgene_dist_family': dict(gen_vgene_dist_family),\n",
    "            'true_vgene_dist_full': dict(true_vgene_dist_full),\n",
    "            'true_vgene_dist_simple': dict(true_vgene_dist_simple),\n",
    "            'true_vgene_dist_family': dict(true_vgene_dist_family),\n",
    "            'locus_dist': dict(locus_dist),\n",
    "            'locus_accuracy': dict(locus_accuracy),\n",
    "            'overall_locus_accuracy': overall_accuracy,\n",
    "            'coverage': {\n",
    "                'gen_full': gen_full_cov,\n",
    "                'gen_simple': gen_simple_cov,\n",
    "                'gen_family': gen_family_cov,\n",
    "                'true_full': true_full_cov,\n",
    "                'true_simple': true_simple_cov,\n",
    "                'true_family': true_family_cov\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Analyze both groups\n",
    "    low_results = analyze_group(df_low, \"Low Pairing Score (<0.5)\")\n",
    "    high_results = analyze_group(df_high, \"High Pairing Score (≥0.5)\")\n",
    "    \n",
    "    # Skip if either group has no data\n",
    "    if low_results is None or high_results is None:\n",
    "        print(\"\\n⚠️ One or both groups have no data. Skipping heatmap creation.\")\n",
    "        return {\n",
    "            'overall_stats': {\n",
    "                'total_rows': len(df),\n",
    "                'rows_with_scores': len(df_clean),\n",
    "                'low_score_rows': len(df_low),\n",
    "                'high_score_rows': len(df_high)\n",
    "            },\n",
    "            'low_score_group': low_results,\n",
    "            'high_score_group': high_results\n",
    "        }\n",
    "    \n",
    "    # ============================\n",
    "    # HEATMAPS\n",
    "    # ============================\n",
    "    \n",
    "    def create_complete_contingency(heavy_counts, light_counts, vgene_dist):\n",
    "        all_heavy = list(heavy_counts.keys())\n",
    "        all_light = list(light_counts.keys())\n",
    "        \n",
    "        if len(all_heavy) == 0 or len(all_light) == 0:\n",
    "            return None, [], []\n",
    "        \n",
    "        contingency = np.zeros((len(all_heavy), len(all_light)))\n",
    "        \n",
    "        for i, heavy_gene in enumerate(all_heavy):\n",
    "            for j, light_gene in enumerate(all_light):\n",
    "                contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        return contingency, all_heavy, all_light\n",
    "    \n",
    "    def create_heatmap(heavy_counts, light_counts, vgene_dist, title, cmap='YlOrRd', complete=False):\n",
    "        if len(heavy_counts) == 0 or len(light_counts) == 0:\n",
    "            print(f\"No data for {title}\")\n",
    "            return None\n",
    "        \n",
    "        if complete:\n",
    "            result = create_complete_contingency(heavy_counts, light_counts, vgene_dist)\n",
    "            if result[0] is None:\n",
    "                print(f\"No data for {title}\")\n",
    "                return None\n",
    "            contingency, heavy_genes, light_genes = result\n",
    "        else:\n",
    "            heavy_genes = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "            light_genes = [gene for gene, _ in light_counts.most_common(5)]\n",
    "            \n",
    "            if len(heavy_genes) < 2 or len(light_genes) < 2:\n",
    "                print(f\"Insufficient data for {title}\")\n",
    "                return None\n",
    "            \n",
    "            contingency = np.zeros((len(heavy_genes), len(light_genes)))\n",
    "            for i, heavy_gene in enumerate(heavy_genes):\n",
    "                for j, light_gene in enumerate(light_genes):\n",
    "                    contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        # Dynamic figure sizing\n",
    "        fig_width = max(8, len(light_genes) * 0.6)\n",
    "        fig_height = max(6, len(heavy_genes) * 0.5)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(fig_width, fig_height))\n",
    "        \n",
    "        im = ax.imshow(contingency, cmap=cmap, aspect='auto')\n",
    "        ax.set_xticks(range(len(light_genes)))\n",
    "        ax.set_yticks(range(len(heavy_genes)))\n",
    "        ax.set_xticklabels(light_genes, rotation=45, ha='right', fontsize=16)\n",
    "        ax.set_yticklabels(heavy_genes, fontsize=16)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Light V Genes')\n",
    "        ax.set_ylabel('Heavy V Genes')\n",
    "        \n",
    "        # Add annotations for smaller heatmaps\n",
    "        if len(heavy_genes) <= 15 and len(light_genes) <= 15:\n",
    "            for i in range(len(heavy_genes)):\n",
    "                for j in range(len(light_genes)):\n",
    "                    text_color = 'white' if contingency[i, j] > np.max(contingency) * 0.5 else 'black'\n",
    "                    ax.text(j, i, int(contingency[i, j]), ha='center', va='center', \n",
    "                           fontsize=28, color=text_color)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return contingency\n",
    "    \n",
    "    def create_heatmaps_for_group(results, data_type=\"Generated\"):\n",
    "        \"\"\"Create heatmaps for a specific group and data type\"\"\"\n",
    "        \n",
    "        group_name = results['group_name']\n",
    "        prefix = 'gen_' if data_type == \"Generated\" else 'true_'\n",
    "        cmap = 'YlOrRd' if data_type == \"Generated\" else 'Reds'\n",
    "        \n",
    "        print(f\"\\n--- {data_type.upper()} V GENE HEATMAPS - {group_name.upper()} ---\")\n",
    "        \n",
    "        # Get data\n",
    "        heavy_counts_full = results[f'{prefix}heavy_counts_full']\n",
    "        light_counts_full = results[f'{prefix}light_counts_full']\n",
    "        heavy_counts_simple = results[f'{prefix}heavy_counts_simple']\n",
    "        light_counts_simple = results[f'{prefix}light_counts_simple']\n",
    "        heavy_counts_family = results[f'{prefix}heavy_counts_family']\n",
    "        light_counts_family = results[f'{prefix}light_counts_family']\n",
    "        \n",
    "        vgene_dist_full = results[f'{prefix}vgene_dist_full']\n",
    "        vgene_dist_simple = results[f'{prefix}vgene_dist_simple']\n",
    "        vgene_dist_family = results[f'{prefix}vgene_dist_family']\n",
    "        \n",
    "        coverage = results['coverage']\n",
    "        \n",
    "        # Only create heavy-light heatmaps if we have heavy chain data\n",
    "        if heavy_gene_col and len(heavy_counts_full) > 0:\n",
    "            # 5x5 heatmaps\n",
    "            create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Full Names, Top 5x5)\", cmap)\n",
    "            \n",
    "            create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Simplified, Top 5x5)\", cmap)\n",
    "            \n",
    "            create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Families, Top 5x5)\", cmap)\n",
    "            \n",
    "            # Complete heatmaps when feasible\n",
    "            coverage_key = f'{prefix[:-1]}_family'\n",
    "            if coverage[coverage_key][0] <= 15 and coverage[coverage_key][1] <= 15:\n",
    "                create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                              f\"Complete {data_type} Family Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "            \n",
    "            coverage_key = f'{prefix[:-1]}_simple'\n",
    "            if coverage[coverage_key][0] <= 20 and coverage[coverage_key][1] <= 20:\n",
    "                create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                              f\"Complete {data_type} Simplified Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "            \n",
    "            coverage_key = f'{prefix[:-1]}_full'\n",
    "            if coverage[coverage_key][0] <= 25 and coverage[coverage_key][1] <= 25:\n",
    "                create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                              f\"Complete {data_type} Full Name Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "        else:\n",
    "            print(f\"Skipping heavy-light heatmaps for {data_type} - {group_name} (no heavy chain data)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"CREATING HEATMAPS...\")\n",
    "    \n",
    "    # Create heatmaps for both groups\n",
    "    for results in [low_results, high_results]:\n",
    "        create_heatmaps_for_group(results, \"Generated\")\n",
    "        create_heatmaps_for_group(results, \"True\")\n",
    "    \n",
    "    # Create locus heatmaps for both groups\n",
    "    print(\"\\n--- LOCUS ASSOCIATION HEATMAPS ---\")\n",
    "    \n",
    "    for results in [low_results, high_results]:\n",
    "        group_name = results['group_name']\n",
    "        locus_dist = results['locus_dist']\n",
    "        \n",
    "        if len(locus_dist) == 0:\n",
    "            print(f\"No locus data for {group_name}\")\n",
    "            continue\n",
    "        \n",
    "        true_loci = list(locus_dist.keys())\n",
    "        gen_loci = list(set([gen for true_dist in locus_dist.values() for gen in true_dist.keys()]))\n",
    "        \n",
    "        if len(true_loci) >= 2 and len(gen_loci) >= 2:\n",
    "            locus_contingency = np.zeros((len(true_loci), len(gen_loci)))\n",
    "            \n",
    "            for i, true_locus in enumerate(true_loci):\n",
    "                for j, gen_locus in enumerate(gen_loci):\n",
    "                    locus_contingency[i, j] = locus_dist[true_locus][gen_locus]\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "            im = ax.imshow(locus_contingency, cmap='Blues', aspect='auto')\n",
    "            ax.set_xticks(range(len(gen_loci)))\n",
    "            ax.set_yticks(range(len(true_loci)))\n",
    "            ax.set_xticklabels(gen_loci, rotation=45, ha='right')\n",
    "            ax.set_yticklabels(true_loci)\n",
    "            ax.set_title(f'Locus Associations - {group_name}')\n",
    "            ax.set_xlabel('Generated Light Chain Loci')\n",
    "            ax.set_ylabel('True Light Chain Loci')\n",
    "            \n",
    "            # Add annotations\n",
    "            for i in range(len(true_loci)):\n",
    "                for j in range(len(gen_loci)):\n",
    "                    text_color = 'white' if locus_contingency[i, j] > np.max(locus_contingency) * 0.5 else 'black'\n",
    "                    ax.text(j, i, int(locus_contingency[i, j]), ha='center', va='center', color=text_color)\n",
    "            \n",
    "            plt.colorbar(im, ax=ax)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Insufficient locus data for {group_name}\")\n",
    "    \n",
    "    # ============================\n",
    "    # COMPARISON ANALYSIS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"COMPARISON ANALYSIS BETWEEN GROUPS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nLocus Accuracy Comparison:\")\n",
    "    print(f\"Low pairing scores: {low_results['overall_locus_accuracy']:.1f}%\")\n",
    "    print(f\"High pairing scores: {high_results['overall_locus_accuracy']:.1f}%\")\n",
    "    print(f\"Difference: {high_results['overall_locus_accuracy'] - low_results['overall_locus_accuracy']:.1f} percentage points\")\n",
    "    \n",
    "    print(f\"\\nV Gene Diversity Comparison:\")\n",
    "    for level in ['full', 'simple', 'family']:\n",
    "        low_gen = len(low_results[f'gen_light_counts_{level}'])\n",
    "        high_gen = len(high_results[f'gen_light_counts_{level}'])\n",
    "        low_true = len(low_results[f'true_light_counts_{level}'])\n",
    "        high_true = len(high_results[f'true_light_counts_{level}'])\n",
    "        \n",
    "        print(f\"{level.capitalize()} - Generated light genes: Low={low_gen}, High={high_gen}\")\n",
    "        print(f\"{level.capitalize()} - True light genes: Low={low_true}, High={high_true}\")\n",
    "    \n",
    "    # Top genes comparison\n",
    "    print(f\"\\nTop 5 Generated Light V Genes Comparison:\")\n",
    "    print(f\"{'Low Score Group':<30} {'High Score Group':<30}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    low_top5_gen = low_results['gen_light_counts_full'].most_common(5)\n",
    "    high_top5_gen = high_results['gen_light_counts_full'].most_common(5)\n",
    "    \n",
    "    max_rows = max(len(low_top5_gen), len(high_top5_gen))\n",
    "    for i in range(max_rows):\n",
    "        low_entry = f\"{low_top5_gen[i][0]} ({low_top5_gen[i][1]})\" if i < len(low_top5_gen) else \"\"\n",
    "        high_entry = f\"{high_top5_gen[i][0]} ({high_top5_gen[i][1]})\" if i < len(high_top5_gen) else \"\"\n",
    "        print(f\"{low_entry:<30} {high_entry:<30}\")\n",
    "    \n",
    "    print(f\"\\nTop 5 True Light V Genes Comparison:\")\n",
    "    print(f\"{'Low Score Group':<30} {'High Score Group':<30}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    low_top5_true = low_results['true_light_counts_full'].most_common(5)\n",
    "    high_top5_true = high_results['true_light_counts_full'].most_common(5)\n",
    "    \n",
    "    max_rows = max(len(low_top5_true), len(high_top5_true))\n",
    "    for i in range(max_rows):\n",
    "        low_entry = f\"{low_top5_true[i][0]} ({low_top5_true[i][1]})\" if i < len(low_top5_true) else \"\"\n",
    "        high_entry = f\"{high_top5_true[i][0]} ({high_top5_true[i][1]})\" if i < len(high_top5_true) else \"\"\n",
    "        print(f\"{low_entry:<30} {high_entry:<30}\")\n",
    "    \n",
    "    # ============================\n",
    "    # RETURN RESULTS\n",
    "    # ============================\n",
    "    \n",
    "    return {\n",
    "        'overall_stats': {\n",
    "            'total_rows': len(df),\n",
    "            'rows_with_scores': len(df_clean),\n",
    "            'low_score_rows': len(df_low),\n",
    "            'high_score_rows': len(df_high),\n",
    "            'score_stats': {\n",
    "                'overall_mean': df_clean['pairing_scores'].mean(),\n",
    "                'overall_median': df_clean['pairing_scores'].median(),\n",
    "                'low_mean': df_low['pairing_scores'].mean() if len(df_low) > 0 else None,\n",
    "                'high_mean': df_high['pairing_scores'].mean() if len(df_high) > 0 else None\n",
    "            }\n",
    "        },\n",
    "        'low_score_group': low_results,\n",
    "        'high_score_group': high_results,\n",
    "        'heavy_gene_col': heavy_gene_col\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22e906fc",
   "metadata": {},
   "source": [
    "\n",
    "csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/pairing_result_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols_merged_complete.csv'\n",
    "    \n",
    "try:\n",
    "    results = analyze_vgene_by_pairing_score(csv_file)\n",
    "    if results:\n",
    "        print(\"\\nAnalysis completed successfully!\")\n",
    "        print(\"Results contain separate analyses for low (<0.5) and high (≥0.5) pairing score groups.\")\n",
    "        print(\"Generated vs True light chain V gene associations are compared for each group.\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the file '{csv_file}'\")\n",
    "    print(\"Please make sure the file path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1261bc5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "def simplify_gene_name(gene_name):\n",
    "    \"\"\"Remove allele designation (part after *) from gene name\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    return str(gene_name).split('*')[0]\n",
    "\n",
    "def extract_gene_family(gene_name):\n",
    "    \"\"\"Extract gene family (e.g., IGHV3 from IGHV3-23*01)\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    simplified = str(gene_name).split('*')[0]\n",
    "    # Extract family part (everything before the dash)\n",
    "    if '-' in simplified:\n",
    "        return simplified.split('-')[0]\n",
    "    return simplified\n",
    "\n",
    "def analyze_vgene_by_pairing_score(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze V gene distributions grouped by pairing scores (<0.5 vs ≥0.5)\n",
    "    and compare generated vs true light chain V genes.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['pairing_scores', 'true_light_gene_name', 'gen_light_1_first_hit_gene']\n",
    "    \n",
    "    # Check for heavy chain V gene column\n",
    "    heavy_gene_col = None\n",
    "    possible_heavy_cols = ['heavy_gene_name', 'true_v_gene_simple', 'heavy_v_gene', 'true_heavy_gene']\n",
    "    \n",
    "    for col in possible_heavy_cols:\n",
    "        if col in df.columns:\n",
    "            heavy_gene_col = col\n",
    "            break\n",
    "    \n",
    "    if heavy_gene_col:\n",
    "        required_cols.append(heavy_gene_col)\n",
    "        print(f\"✅ Using heavy chain V gene column: {heavy_gene_col}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No heavy chain V gene column found. Searched for: {possible_heavy_cols}\")\n",
    "        print(f\"Available columns: {df.columns.tolist()}\")\n",
    "        print(f\"Will skip heavy-light V gene pairing analysis and focus on light chain only.\")\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"❌ Missing required columns: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Required columns found\")\n",
    "    \n",
    "    # ============================\n",
    "    # DATA PREPARATION\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"DATA PREPARATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Remove rows with missing pairing scores\n",
    "    df_clean = df.dropna(subset=['pairing_scores']).copy()\n",
    "    print(f\"Rows with pairing scores: {len(df_clean)}/{len(df)} ({len(df_clean)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Group by pairing score threshold\n",
    "    df_low = df_clean[df_clean['pairing_scores'] < 0.5].copy()\n",
    "    df_high = df_clean[df_clean['pairing_scores'] >= 0.5].copy()\n",
    "    \n",
    "    print(f\"Low pairing scores (<0.5): {len(df_low)} rows ({len(df_low)/len(df_clean)*100:.1f}%)\")\n",
    "    print(f\"High pairing scores (≥0.5): {len(df_high)} rows ({len(df_high)/len(df_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Pairing score statistics\n",
    "    print(f\"\\nPairing Score Statistics:\")\n",
    "    print(f\"Overall - Mean: {df_clean['pairing_scores'].mean():.3f}, Median: {df_clean['pairing_scores'].median():.3f}\")\n",
    "    if len(df_low) > 0:\n",
    "        print(f\"Low group - Mean: {df_low['pairing_scores'].mean():.3f}, Range: {df_low['pairing_scores'].min():.3f}-{df_low['pairing_scores'].max():.3f}\")\n",
    "    if len(df_high) > 0:\n",
    "        print(f\"High group - Mean: {df_high['pairing_scores'].mean():.3f}, Range: {df_high['pairing_scores'].min():.3f}-{df_high['pairing_scores'].max():.3f}\")\n",
    "    \n",
    "    def analyze_group(df_group, group_name):\n",
    "        \"\"\"Analyze V gene distributions for a specific pairing score group\"\"\"\n",
    "        \n",
    "        if len(df_group) == 0:\n",
    "            print(f\"\\n⚠️ No data for {group_name} group\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{group_name.upper()} PAIRING SCORE GROUP ANALYSIS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # ============================\n",
    "        # GENERATED V GENE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nGENERATED LIGHT CHAIN V GENE ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Collect generated light chain V genes\n",
    "        gen_light_genes = []\n",
    "        for idx, row in df_group.iterrows():\n",
    "            gen_light_gene = row['gen_light_1_first_hit_gene']\n",
    "            if not pd.isna(gen_light_gene):\n",
    "                gen_light_genes.append(gen_light_gene)\n",
    "        \n",
    "        print(f\"Generated light V genes: {len(gen_light_genes)}\")\n",
    "        \n",
    "        # Create simplified and family versions for generated\n",
    "        gen_light_simple = [simplify_gene_name(gene) for gene in gen_light_genes if not pd.isna(gene)]\n",
    "        gen_light_family = [extract_gene_family(gene) for gene in gen_light_genes if not pd.isna(gene)]\n",
    "        \n",
    "        # Count frequencies for generated\n",
    "        gen_light_counts_full = Counter(gen_light_genes)\n",
    "        gen_light_counts_simple = Counter([gene for gene in gen_light_simple if not pd.isna(gene)])\n",
    "        gen_light_counts_family = Counter([gene for gene in gen_light_family if not pd.isna(gene)])\n",
    "        \n",
    "        print(f\"Generated - Full: {len(gen_light_counts_full)} unique genes\")\n",
    "        print(f\"Generated - Simple: {len(gen_light_counts_simple)} unique genes\")\n",
    "        print(f\"Generated - Family: {len(gen_light_counts_family)} unique families\")\n",
    "        \n",
    "        # ============================\n",
    "        # TRUE V GENE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nTRUE LIGHT CHAIN V GENE ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Collect true light chain V genes\n",
    "        true_light_genes = []\n",
    "        for idx, row in df_group.iterrows():\n",
    "            true_light_gene = row['true_light_gene_name']\n",
    "            if not pd.isna(true_light_gene):\n",
    "                true_light_genes.append(true_light_gene)\n",
    "        \n",
    "        print(f\"True light V genes: {len(true_light_genes)}\")\n",
    "        \n",
    "        # Create simplified and family versions for true\n",
    "        true_light_simple = [simplify_gene_name(gene) for gene in true_light_genes if not pd.isna(gene)]\n",
    "        true_light_family = [extract_gene_family(gene) for gene in true_light_genes if not pd.isna(gene)]\n",
    "        \n",
    "        # Count frequencies for true\n",
    "        true_light_counts_full = Counter(true_light_genes)\n",
    "        true_light_counts_simple = Counter([gene for gene in true_light_simple if not pd.isna(gene)])\n",
    "        true_light_counts_family = Counter([gene for gene in true_light_family if not pd.isna(gene)])\n",
    "        \n",
    "        print(f\"True - Full: {len(true_light_counts_full)} unique genes\")\n",
    "        print(f\"True - Simple: {len(true_light_counts_simple)} unique genes\") \n",
    "        print(f\"True - Family: {len(true_light_counts_family)} unique families\")\n",
    "        \n",
    "        # ============================\n",
    "        # HEAVY-LIGHT PAIRING ANALYSIS (if heavy chain data available)\n",
    "        # ============================\n",
    "        \n",
    "        if heavy_gene_col:\n",
    "            print(f\"\\nHEAVY-LIGHT V GENE PAIRING ANALYSIS - {group_name}\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Generated heavy-light pairs\n",
    "            gen_pairs_full = []\n",
    "            gen_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for idx, row in df_group.iterrows():\n",
    "                heavy_gene = row[heavy_gene_col]\n",
    "                gen_light_gene = row['gen_light_1_first_hit_gene']\n",
    "                \n",
    "                if pd.isna(heavy_gene) or pd.isna(gen_light_gene):\n",
    "                    continue\n",
    "                \n",
    "                gen_pairs_full.append((heavy_gene, gen_light_gene))\n",
    "                gen_vgene_dist_full[heavy_gene][gen_light_gene] += 1\n",
    "            \n",
    "            # True heavy-light pairs\n",
    "            true_pairs_full = []\n",
    "            true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for idx, row in df_group.iterrows():\n",
    "                heavy_gene = row[heavy_gene_col]\n",
    "                true_light_gene = row['true_light_gene_name']\n",
    "                \n",
    "                if pd.isna(heavy_gene) or pd.isna(true_light_gene):\n",
    "                    continue\n",
    "                \n",
    "                true_pairs_full.append((heavy_gene, true_light_gene))\n",
    "                true_vgene_dist_full[heavy_gene][true_light_gene] += 1\n",
    "            \n",
    "            print(f\"Generated heavy-light pairs: {len(gen_pairs_full)}\")\n",
    "            print(f\"True heavy-light pairs: {len(true_pairs_full)}\")\n",
    "            \n",
    "            # Create simplified and family versions for pairing\n",
    "            gen_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                               for pair in gen_pairs_full]\n",
    "            gen_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                               for pair in gen_pairs_full]\n",
    "            \n",
    "            true_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                                for pair in true_pairs_full]\n",
    "            true_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                                for pair in true_pairs_full]\n",
    "            \n",
    "            # Create distribution dictionaries\n",
    "            gen_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            for heavy_gene, light_gene in gen_pairs_simple:\n",
    "                if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                    gen_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "            \n",
    "            for heavy_family, light_family in gen_pairs_family:\n",
    "                if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                    gen_vgene_dist_family[heavy_family][light_family] += 1\n",
    "            \n",
    "            for heavy_gene, light_gene in true_pairs_simple:\n",
    "                if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                    true_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "            \n",
    "            for heavy_family, light_family in true_pairs_family:\n",
    "                if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                    true_vgene_dist_family[heavy_family][light_family] += 1\n",
    "            \n",
    "            # Count heavy chain frequencies\n",
    "            gen_heavy_counts_full = Counter([pair[0] for pair in gen_pairs_full])\n",
    "            gen_heavy_counts_simple = Counter([pair[0] for pair in gen_pairs_simple if not pd.isna(pair[0])])\n",
    "            gen_heavy_counts_family = Counter([pair[0] for pair in gen_pairs_family if not pd.isna(pair[0])])\n",
    "            \n",
    "            true_heavy_counts_full = Counter([pair[0] for pair in true_pairs_full])\n",
    "            true_heavy_counts_simple = Counter([pair[0] for pair in true_pairs_simple if not pd.isna(pair[0])])\n",
    "            true_heavy_counts_family = Counter([pair[0] for pair in true_pairs_family if not pd.isna(pair[0])])\n",
    "            \n",
    "        else:\n",
    "            # No heavy chain data - create empty distributions\n",
    "            gen_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            gen_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "            true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "            \n",
    "            gen_heavy_counts_full = Counter()\n",
    "            gen_heavy_counts_simple = Counter()\n",
    "            gen_heavy_counts_family = Counter()\n",
    "            true_heavy_counts_full = Counter()\n",
    "            true_heavy_counts_simple = Counter()\n",
    "            true_heavy_counts_family = Counter()\n",
    "        \n",
    "        # ============================\n",
    "        # LOCUS ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        print(f\"\\nLOCUS ANALYSIS - {group_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Analyze true vs generated loci\n",
    "        locus_pairs = []\n",
    "        locus_dist = defaultdict(lambda: defaultdict(int))\n",
    "        locus_accuracy = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "        \n",
    "        for idx, row in df_group.iterrows():\n",
    "            true_locus = row['true_light_light_locus']\n",
    "            gen_locus = row['gen_light_1_light_locus']\n",
    "            \n",
    "            if pd.isna(true_locus) or pd.isna(gen_locus):\n",
    "                continue\n",
    "            \n",
    "            locus_pairs.append((true_locus, gen_locus))\n",
    "            locus_dist[true_locus][gen_locus] += 1\n",
    "            locus_accuracy[true_locus]['total'] += 1\n",
    "            if gen_locus == true_locus:\n",
    "                locus_accuracy[true_locus]['correct'] += 1\n",
    "        \n",
    "        print(f\"True-generated locus pairs: {len(locus_pairs)}\")\n",
    "        \n",
    "        # Calculate overall locus accuracy\n",
    "        total_generated = sum([stats['total'] for stats in locus_accuracy.values()])\n",
    "        total_correct = sum([stats['correct'] for stats in locus_accuracy.values()])\n",
    "        overall_accuracy = (total_correct / total_generated * 100) if total_generated > 0 else 0\n",
    "        \n",
    "        print(f\"Locus accuracy: {overall_accuracy:.1f}% ({total_correct}/{total_generated})\")\n",
    "        \n",
    "        # ============================\n",
    "        # COVERAGE ANALYSIS\n",
    "        # ============================\n",
    "        \n",
    "        def analyze_coverage(heavy_counts, light_counts, vgene_dist, level_name):\n",
    "            total_heavy_genes = len(heavy_counts)\n",
    "            total_light_genes = len(light_counts)\n",
    "            \n",
    "            if total_heavy_genes == 0 or total_light_genes == 0:\n",
    "                return 0, 0, 0\n",
    "            \n",
    "            # Count total associations\n",
    "            total_associations = sum(sum(light_dist.values()) for light_dist in vgene_dist.values())\n",
    "            \n",
    "            # Get top 5 genes\n",
    "            top_5_heavy = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "            top_5_light = [gene for gene, _ in light_counts.most_common(5)]\n",
    "            \n",
    "            # Calculate coverage of top 5 associations\n",
    "            top_5_associations = 0\n",
    "            for heavy in top_5_heavy:\n",
    "                for light in top_5_light:\n",
    "                    top_5_associations += vgene_dist[heavy][light]\n",
    "            \n",
    "            coverage_pct = (top_5_associations / total_associations * 100) if total_associations > 0 else 0\n",
    "            \n",
    "            return total_heavy_genes, total_light_genes, coverage_pct\n",
    "        \n",
    "        print(f\"\\nCoverage Analysis - {group_name}:\")\n",
    "        gen_full_cov = analyze_coverage(gen_heavy_counts_full, gen_light_counts_full, gen_vgene_dist_full, \"Gen Full\")\n",
    "        gen_simple_cov = analyze_coverage(gen_heavy_counts_simple, gen_light_counts_simple, gen_vgene_dist_simple, \"Gen Simple\")\n",
    "        gen_family_cov = analyze_coverage(gen_heavy_counts_family, gen_light_counts_family, gen_vgene_dist_family, \"Gen Family\")\n",
    "        true_full_cov = analyze_coverage(true_heavy_counts_full, true_light_counts_full, true_vgene_dist_full, \"True Full\")\n",
    "        true_simple_cov = analyze_coverage(true_heavy_counts_simple, true_light_counts_simple, true_vgene_dist_simple, \"True Simple\")\n",
    "        true_family_cov = analyze_coverage(true_heavy_counts_family, true_light_counts_family, true_vgene_dist_family, \"True Family\")\n",
    "        \n",
    "        print(f\"Generated - Full: {gen_full_cov[0]}x{gen_light_counts_full if gen_light_counts_full else 0}, 5x5 covers {gen_full_cov[2]:.1f}%\")\n",
    "        print(f\"Generated - Simple: {gen_simple_cov[0]}x{len(gen_light_counts_simple)}, 5x5 covers {gen_simple_cov[2]:.1f}%\")\n",
    "        print(f\"Generated - Family: {gen_family_cov[0]}x{len(gen_light_counts_family)}, 5x5 covers {gen_family_cov[2]:.1f}%\")\n",
    "        print(f\"True - Full: {true_full_cov[0]}x{len(true_light_counts_full)}, 5x5 covers {true_full_cov[2]:.1f}%\")\n",
    "        print(f\"True - Simple: {true_simple_cov[0]}x{len(true_light_counts_simple)}, 5x5 covers {true_simple_cov[2]:.1f}%\")\n",
    "        print(f\"True - Family: {true_family_cov[0]}x{len(true_light_counts_family)}, 5x5 covers {true_family_cov[2]:.1f}%\")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'group_name': group_name,\n",
    "            'n_rows': len(df_group),\n",
    "            'heavy_gene_col': heavy_gene_col,\n",
    "            'gen_light_counts_full': gen_light_counts_full,\n",
    "            'gen_light_counts_simple': gen_light_counts_simple,\n",
    "            'gen_light_counts_family': gen_light_counts_family,\n",
    "            'true_light_counts_full': true_light_counts_full,\n",
    "            'true_light_counts_simple': true_light_counts_simple,\n",
    "            'true_light_counts_family': true_light_counts_family,\n",
    "            'gen_heavy_counts_full': gen_heavy_counts_full,\n",
    "            'gen_heavy_counts_simple': gen_heavy_counts_simple,\n",
    "            'gen_heavy_counts_family': gen_heavy_counts_family,\n",
    "            'true_heavy_counts_full': true_heavy_counts_full,\n",
    "            'true_heavy_counts_simple': true_heavy_counts_simple,\n",
    "            'true_heavy_counts_family': true_heavy_counts_family,\n",
    "            'gen_vgene_dist_full': dict(gen_vgene_dist_full),\n",
    "            'gen_vgene_dist_simple': dict(gen_vgene_dist_simple),\n",
    "            'gen_vgene_dist_family': dict(gen_vgene_dist_family),\n",
    "            'true_vgene_dist_full': dict(true_vgene_dist_full),\n",
    "            'true_vgene_dist_simple': dict(true_vgene_dist_simple),\n",
    "            'true_vgene_dist_family': dict(true_vgene_dist_family),\n",
    "            'locus_dist': dict(locus_dist),\n",
    "            'locus_accuracy': dict(locus_accuracy),\n",
    "            'overall_locus_accuracy': overall_accuracy,\n",
    "            'coverage': {\n",
    "                'gen_full': gen_full_cov,\n",
    "                'gen_simple': gen_simple_cov,\n",
    "                'gen_family': gen_family_cov,\n",
    "                'true_full': true_full_cov,\n",
    "                'true_simple': true_simple_cov,\n",
    "                'true_family': true_family_cov\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Analyze both groups\n",
    "    low_results = analyze_group(df_low, \"Low Pairing Score (<0.5)\")\n",
    "    high_results = analyze_group(df_high, \"High Pairing Score (≥0.5)\")\n",
    "    \n",
    "    # Skip if either group has no data\n",
    "    if low_results is None or high_results is None:\n",
    "        print(\"\\n⚠️ One or both groups have no data. Skipping heatmap creation.\")\n",
    "        return {\n",
    "            'overall_stats': {\n",
    "                'total_rows': len(df),\n",
    "                'rows_with_scores': len(df_clean),\n",
    "                'low_score_rows': len(df_low),\n",
    "                'high_score_rows': len(df_high)\n",
    "            },\n",
    "            'low_score_group': low_results,\n",
    "            'high_score_group': high_results\n",
    "        }\n",
    "    \n",
    "    # ============================\n",
    "    # HEATMAPS\n",
    "    # ============================\n",
    "    \n",
    "    def create_complete_contingency(heavy_counts, light_counts, vgene_dist):\n",
    "        all_heavy = list(heavy_counts.keys())\n",
    "        all_light = list(light_counts.keys())\n",
    "        \n",
    "        if len(all_heavy) == 0 or len(all_light) == 0:\n",
    "            return None, [], []\n",
    "        \n",
    "        contingency = np.zeros((len(all_heavy), len(all_light)))\n",
    "        \n",
    "        for i, heavy_gene in enumerate(all_heavy):\n",
    "            for j, light_gene in enumerate(all_light):\n",
    "                contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        return contingency, all_heavy, all_light\n",
    "    \n",
    "    def create_heatmap(heavy_counts, light_counts, vgene_dist, title, cmap='YlOrRd', complete=False):\n",
    "        if len(heavy_counts) == 0 or len(light_counts) == 0:\n",
    "            print(f\"No data for {title}\")\n",
    "            return None\n",
    "        \n",
    "        if complete:\n",
    "            result = create_complete_contingency(heavy_counts, light_counts, vgene_dist)\n",
    "            if result[0] is None:\n",
    "                print(f\"No data for {title}\")\n",
    "                return None\n",
    "            contingency, heavy_genes, light_genes = result\n",
    "        else:\n",
    "            heavy_genes = [gene for gene, _ in heavy_counts.most_common(5)]\n",
    "            light_genes = [gene for gene, _ in light_counts.most_common(5)]\n",
    "            \n",
    "            if len(heavy_genes) < 2 or len(light_genes) < 2:\n",
    "                print(f\"Insufficient data for {title}\")\n",
    "                return None\n",
    "            \n",
    "            contingency = np.zeros((len(heavy_genes), len(light_genes)))\n",
    "            for i, heavy_gene in enumerate(heavy_genes):\n",
    "                for j, light_gene in enumerate(light_genes):\n",
    "                    contingency[i, j] = vgene_dist[heavy_gene][light_gene]\n",
    "        \n",
    "        # Dynamic figure sizing\n",
    "        fig_width = max(8, len(light_genes) * 0.6)\n",
    "        fig_height = max(6, len(heavy_genes) * 0.5)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(fig_width, fig_height))\n",
    "        \n",
    "        im = ax.imshow(contingency, cmap=cmap, aspect='auto')\n",
    "        ax.set_xticks(range(len(light_genes)))\n",
    "        ax.set_yticks(range(len(heavy_genes)))\n",
    "        ax.set_xticklabels(light_genes, rotation=45, ha='right', fontsize=16)\n",
    "        ax.set_yticklabels(heavy_genes, fontsize=16)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Light V Genes')\n",
    "        ax.set_ylabel('Heavy V Genes')\n",
    "        \n",
    "        # Add annotations for smaller heatmaps\n",
    "        if len(heavy_genes) <= 15 and len(light_genes) <= 15:\n",
    "            for i in range(len(heavy_genes)):\n",
    "                for j in range(len(light_genes)):\n",
    "                    text_color = 'white' if contingency[i, j] > np.max(contingency) * 0.5 else 'black'\n",
    "                    ax.text(j, i, int(contingency[i, j]), ha='center', va='center', \n",
    "                           fontsize=14, color=text_color)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return contingency\n",
    "    \n",
    "    def create_heatmaps_for_group(results, data_type=\"Generated\"):\n",
    "        \"\"\"Create heatmaps for a specific group and data type\"\"\"\n",
    "        \n",
    "        group_name = results['group_name']\n",
    "        prefix = 'gen_' if data_type == \"Generated\" else 'true_'\n",
    "        cmap = 'YlOrRd' if data_type == \"Generated\" else 'Reds'\n",
    "        \n",
    "        print(f\"\\n--- {data_type.upper()} V GENE HEATMAPS - {group_name.upper()} ---\")\n",
    "        \n",
    "        # Get data\n",
    "        heavy_counts_full = results[f'{prefix}heavy_counts_full']\n",
    "        light_counts_full = results[f'{prefix}light_counts_full']\n",
    "        heavy_counts_simple = results[f'{prefix}heavy_counts_simple']\n",
    "        light_counts_simple = results[f'{prefix}light_counts_simple']\n",
    "        heavy_counts_family = results[f'{prefix}heavy_counts_family']\n",
    "        light_counts_family = results[f'{prefix}light_counts_family']\n",
    "        \n",
    "        vgene_dist_full = results[f'{prefix}vgene_dist_full']\n",
    "        vgene_dist_simple = results[f'{prefix}vgene_dist_simple']\n",
    "        vgene_dist_family = results[f'{prefix}vgene_dist_family']\n",
    "        \n",
    "        coverage = results['coverage']\n",
    "        \n",
    "        # Only create heavy-light heatmaps if we have heavy chain data\n",
    "        if heavy_gene_col and len(heavy_counts_full) > 0:\n",
    "            # 5x5 heatmaps\n",
    "            create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Full Names, Top 5x5)\", cmap)\n",
    "            \n",
    "            create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Simplified, Top 5x5)\", cmap)\n",
    "            \n",
    "            create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                          f\"{data_type} V Gene Associations - {group_name} (Families, Top 5x5)\", cmap)\n",
    "            \n",
    "            # Complete heatmaps when feasible\n",
    "            coverage_key = f'{prefix[:-1]}_family'\n",
    "            if coverage[coverage_key][0] <= 15 and coverage[coverage_key][1] <= 15:\n",
    "                create_heatmap(heavy_counts_family, light_counts_family, vgene_dist_family, \n",
    "                              f\"Complete {data_type} Family Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "            \n",
    "            coverage_key = f'{prefix[:-1]}_simple'\n",
    "            if coverage[coverage_key][0] <= 20 and coverage[coverage_key][1] <= 20:\n",
    "                create_heatmap(heavy_counts_simple, light_counts_simple, vgene_dist_simple, \n",
    "                              f\"Complete {data_type} Simplified Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "            \n",
    "            coverage_key = f'{prefix[:-1]}_full'\n",
    "            if coverage[coverage_key][0] <= 25 and coverage[coverage_key][1] <= 25:\n",
    "                create_heatmap(heavy_counts_full, light_counts_full, vgene_dist_full, \n",
    "                              f\"Complete {data_type} Full Name Associations - {group_name} ({coverage[coverage_key][0]}x{coverage[coverage_key][1]})\", \n",
    "                              cmap, complete=True)\n",
    "        else:\n",
    "            print(f\"Skipping heavy-light heatmaps for {data_type} - {group_name} (no heavy chain data)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"CREATING HEATMAPS...\")\n",
    "    \n",
    "    # Create heatmaps for both groups\n",
    "    for results in [low_results, high_results]:\n",
    "        create_heatmaps_for_group(results, \"Generated\")\n",
    "        create_heatmaps_for_group(results, \"True\")\n",
    "    \n",
    "    # Create locus heatmaps for both groups\n",
    "    print(\"\\n--- LOCUS ASSOCIATION HEATMAPS ---\")\n",
    "    \n",
    "    for results in [low_results, high_results]:\n",
    "        group_name = results['group_name']\n",
    "        locus_dist = results['locus_dist']\n",
    "        \n",
    "        if len(locus_dist) == 0:\n",
    "            print(f\"No locus data for {group_name}\")\n",
    "            continue\n",
    "        \n",
    "        true_loci = list(locus_dist.keys())\n",
    "        gen_loci = list(set([gen for true_dist in locus_dist.values() for gen in true_dist.keys()]))\n",
    "        \n",
    "        if len(true_loci) >= 2 and len(gen_loci) >= 2:\n",
    "            locus_contingency = np.zeros((len(true_loci), len(gen_loci)))\n",
    "            \n",
    "            for i, true_locus in enumerate(true_loci):\n",
    "                for j, gen_locus in enumerate(gen_loci):\n",
    "                    locus_contingency[i, j] = locus_dist[true_locus][gen_locus]\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "            im = ax.imshow(locus_contingency, cmap='Blues', aspect='auto')\n",
    "            ax.set_xticks(range(len(gen_loci)))\n",
    "            ax.set_yticks(range(len(true_loci)))\n",
    "            ax.set_xticklabels(gen_loci, rotation=45, ha='right')\n",
    "            ax.set_yticklabels(true_loci)\n",
    "            ax.set_title(f'Locus Associations - {group_name}')\n",
    "            ax.set_xlabel('Generated Light Chain Loci')\n",
    "            ax.set_ylabel('True Light Chain Loci')\n",
    "            \n",
    "            # Add annotations\n",
    "            for i in range(len(true_loci)):\n",
    "                for j in range(len(gen_loci)):\n",
    "                    text_color = 'white' if locus_contingency[i, j] > np.max(locus_contingency) * 0.5 else 'black'\n",
    "                    ax.text(j, i, int(locus_contingency[i, j]), ha='center', va='center', color=text_color)\n",
    "            \n",
    "            plt.colorbar(im, ax=ax)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Insufficient locus data for {group_name}\")\n",
    "    \n",
    "    # ============================\n",
    "    # V GENE CONSISTENCY ANALYSIS\n",
    "    # ============================\n",
    "    \n",
    "    def analyze_vgene_consistency(results_list, analysis_name):\n",
    "        \"\"\"Analyze if certain heavy V genes consistently generate the same light V genes\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"V GENE CONSISTENCY ANALYSIS - {analysis_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        all_consistency_results = {}\n",
    "        \n",
    "        for results in results_list:\n",
    "            if results is None:\n",
    "                continue\n",
    "                \n",
    "            group_name = results['group_name']\n",
    "            print(f\"\\n--- {group_name.upper()} ---\")\n",
    "            \n",
    "            # Only analyze if we have heavy chain data\n",
    "            if not heavy_gene_col or len(results['gen_heavy_counts_full']) == 0:\n",
    "                print(f\"No heavy-light pairing data for {group_name}\")\n",
    "                continue\n",
    "            \n",
    "            consistency_stats = {}\n",
    "            \n",
    "            # Analyze at different levels\n",
    "            for level in ['full', 'simple', 'family']:\n",
    "                print(f\"\\n{level.capitalize()} Level Analysis:\")\n",
    "                \n",
    "                gen_vgene_dist = results[f'gen_vgene_dist_{level}']\n",
    "                true_vgene_dist = results[f'true_vgene_dist_{level}']\n",
    "                \n",
    "                # Generated consistency analysis\n",
    "                gen_consistency = analyze_heavy_light_consistency(gen_vgene_dist, f\"Generated {level}\")\n",
    "                \n",
    "                # True consistency analysis  \n",
    "                true_consistency = analyze_heavy_light_consistency(true_vgene_dist, f\"True {level}\")\n",
    "                \n",
    "                consistency_stats[level] = {\n",
    "                    'generated': gen_consistency,\n",
    "                    'true': true_consistency\n",
    "                }\n",
    "            \n",
    "            all_consistency_results[group_name] = consistency_stats\n",
    "        \n",
    "        return all_consistency_results\n",
    "    \n",
    "    def analyze_heavy_light_consistency(vgene_dist, analysis_type):\n",
    "        \"\"\"Analyze consistency of heavy-light V gene associations\"\"\"\n",
    "        \n",
    "        consistency_results = []\n",
    "        \n",
    "        for heavy_gene, light_dist in vgene_dist.items():\n",
    "            if len(light_dist) == 0:\n",
    "                continue\n",
    "                \n",
    "            total_associations = sum(light_dist.values())\n",
    "            \n",
    "            # Calculate diversity metrics\n",
    "            most_common_light = max(light_dist.items(), key=lambda x: x[1])\n",
    "            most_common_count = most_common_light[1]\n",
    "            most_common_pct = (most_common_count / total_associations) * 100\n",
    "            \n",
    "            # Calculate entropy (lower = more consistent)\n",
    "            proportions = np.array(list(light_dist.values())) / total_associations\n",
    "            entropy = -np.sum(proportions * np.log2(proportions + 1e-10))\n",
    "            \n",
    "            # Calculate Gini coefficient (higher = more concentrated)\n",
    "            sorted_counts = sorted(light_dist.values(), reverse=True)\n",
    "            n = len(sorted_counts)\n",
    "            cumsum = np.cumsum(sorted_counts)\n",
    "            gini = (n + 1 - 2 * np.sum(cumsum) / cumsum[-1]) / n if cumsum[-1] > 0 else 0\n",
    "            \n",
    "            # Consistency classification\n",
    "            if most_common_pct >= 90:\n",
    "                consistency_level = \"Very High\"\n",
    "            elif most_common_pct >= 75:\n",
    "                consistency_level = \"High\"\n",
    "            elif most_common_pct >= 50:\n",
    "                consistency_level = \"Moderate\"\n",
    "            else:\n",
    "                consistency_level = \"Low\"\n",
    "            \n",
    "            consistency_results.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'total_associations': total_associations,\n",
    "                'unique_light_genes': len(light_dist),\n",
    "                'most_common_light': most_common_light[0],\n",
    "                'most_common_count': most_common_count,\n",
    "                'most_common_pct': most_common_pct,\n",
    "                'entropy': entropy,\n",
    "                'gini_coefficient': gini,\n",
    "                'consistency_level': consistency_level,\n",
    "                'light_distribution': dict(light_dist)\n",
    "            })\n",
    "        \n",
    "        # Sort by consistency (highest percentage first)\n",
    "        consistency_results.sort(key=lambda x: x['most_common_pct'], reverse=True)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{analysis_type} Consistency Results:\")\n",
    "        print(f\"{'Heavy V Gene':<25} {'Most Common Light':<25} {'Count':<8} {'%':<8} {'Unique':<8} {'Level':<12} {'Entropy':<8}\")\n",
    "        print(\"-\" * 110)\n",
    "        \n",
    "        for result in consistency_results[:20]:  # Show top 20\n",
    "            print(f\"{result['heavy_gene']:<25} {result['most_common_light']:<25} \"\n",
    "                  f\"{result['most_common_count']:<8} {result['most_common_pct']:<8.1f} \"\n",
    "                  f\"{result['unique_light_genes']:<8} {result['consistency_level']:<12} {result['entropy']:<8.2f}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        if consistency_results:\n",
    "            very_high = len([r for r in consistency_results if r['consistency_level'] == 'Very High'])\n",
    "            high = len([r for r in consistency_results if r['consistency_level'] == 'High'])\n",
    "            moderate = len([r for r in consistency_results if r['consistency_level'] == 'Moderate'])\n",
    "            low = len([r for r in consistency_results if r['consistency_level'] == 'Low'])\n",
    "            \n",
    "            print(f\"\\nConsistency Summary:\")\n",
    "            print(f\"  Very High (≥90%): {very_high} heavy V genes\")\n",
    "            print(f\"  High (75-89%): {high} heavy V genes\")\n",
    "            print(f\"  Moderate (50-74%): {moderate} heavy V genes\")  \n",
    "            print(f\"  Low (<50%): {low} heavy V genes\")\n",
    "            \n",
    "            # Find perfect matches (100% consistency)\n",
    "            perfect_matches = [r for r in consistency_results if r['most_common_pct'] == 100.0]\n",
    "            if perfect_matches:\n",
    "                print(f\"\\n🎯 PERFECT MATCHES (100% consistency):\")\n",
    "                for match in perfect_matches:\n",
    "                    print(f\"  {match['heavy_gene']} → {match['most_common_light']} \"\n",
    "                          f\"({match['total_associations']} associations)\")\n",
    "            \n",
    "            # Find highly consistent genes (≥90%)\n",
    "            highly_consistent = [r for r in consistency_results if r['most_common_pct'] >= 90 and r['most_common_pct'] < 100]\n",
    "            if highly_consistent:\n",
    "                print(f\"\\n⭐ HIGHLY CONSISTENT (≥90%):\")\n",
    "                for match in highly_consistent[:10]:  # Top 10\n",
    "                    print(f\"  {match['heavy_gene']} → {match['most_common_light']} \"\n",
    "                          f\"({match['most_common_pct']:.1f}%, {match['total_associations']} total)\")\n",
    "        \n",
    "        return consistency_results\n",
    "    \n",
    "    def create_consistency_heatmap(consistency_results, title, top_n=15):\n",
    "        \"\"\"Create a heatmap showing the most consistent heavy-light associations\"\"\"\n",
    "        \n",
    "        if not consistency_results:\n",
    "            print(f\"No data for {title}\")\n",
    "            return\n",
    "        \n",
    "        # Get top N most consistent heavy genes\n",
    "        top_results = consistency_results[:top_n]\n",
    "        \n",
    "        if len(top_results) < 2:\n",
    "            print(f\"Insufficient data for {title}\")\n",
    "            return\n",
    "        \n",
    "        # Create matrix for heatmap\n",
    "        heavy_genes = [r['heavy_gene'] for r in top_results]\n",
    "        all_light_genes = set()\n",
    "        for r in top_results:\n",
    "            all_light_genes.update(r['light_distribution'].keys())\n",
    "        all_light_genes = sorted(list(all_light_genes))\n",
    "        \n",
    "        # Create consistency matrix (percentages)\n",
    "        consistency_matrix = np.zeros((len(heavy_genes), len(all_light_genes)))\n",
    "        \n",
    "        for i, result in enumerate(top_results):\n",
    "            total = result['total_associations']\n",
    "            for j, light_gene in enumerate(all_light_genes):\n",
    "                count = result['light_distribution'].get(light_gene, 0)\n",
    "                consistency_matrix[i, j] = (count / total) * 100 if total > 0 else 0\n",
    "        \n",
    "        # Create heatmap\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(max(12, len(all_light_genes) * 0.8), max(8, len(heavy_genes) * 0.6)))\n",
    "        \n",
    "        im = ax.imshow(consistency_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=100)\n",
    "        ax.set_xticks(range(len(all_light_genes)))\n",
    "        ax.set_yticks(range(len(heavy_genes)))\n",
    "        ax.set_xticklabels(all_light_genes, rotation=45, ha='right', fontsize=16)\n",
    "        ax.set_yticklabels(heavy_genes, fontsize=16)\n",
    "        ax.set_title(f'{title}\\n(% of associations for each heavy V gene)')\n",
    "        ax.set_xlabel('Light V Genes')\n",
    "        ax.set_ylabel('Heavy V Genes (sorted by consistency)')\n",
    "        \n",
    "        # Add annotations for high percentages\n",
    "        for i in range(len(heavy_genes)):\n",
    "            for j in range(len(all_light_genes)):\n",
    "                value = consistency_matrix[i, j]\n",
    "                if value >= 25:  # Only annotate if ≥25%\n",
    "                    text_color = 'white' if value > 50 else 'black'\n",
    "                    ax.text(j, i, f'{value:.0f}%', ha='center', va='center', \n",
    "                           fontsize=7, color=text_color, weight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Percentage of Associations (%)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Run consistency analysis\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"ANALYZING V GENE CONSISTENCY...\")\n",
    "    \n",
    "    consistency_results = analyze_vgene_consistency([low_results, high_results], \"BY PAIRING SCORE GROUPS\")\n",
    "    \n",
    "    # Create consistency heatmaps\n",
    "    print(\"\\n--- CONSISTENCY HEATMAPS ---\")\n",
    "    \n",
    "    for group_results in [low_results, high_results]:\n",
    "        if group_results is None or not heavy_gene_col:\n",
    "            continue\n",
    "            \n",
    "        group_name = group_results['group_name']\n",
    "        \n",
    "        for level in ['full', 'simple', 'family']:\n",
    "            gen_vgene_dist = group_results[f'gen_vgene_dist_{level}']\n",
    "            true_vgene_dist = group_results[f'true_vgene_dist_{level}']\n",
    "            \n",
    "            if len(gen_vgene_dist) > 0:\n",
    "                gen_consistency = analyze_heavy_light_consistency(gen_vgene_dist, f\"Generated {level}\")\n",
    "                create_consistency_heatmap(gen_consistency, \n",
    "                                         f\"Generated V Gene Consistency - {group_name} ({level.capitalize()})\")\n",
    "            \n",
    "            if len(true_vgene_dist) > 0:\n",
    "                true_consistency = analyze_heavy_light_consistency(true_vgene_dist, f\"True {level}\")\n",
    "                create_consistency_heatmap(true_consistency, \n",
    "                                         f\"True V Gene Consistency - {group_name} ({level.capitalize()})\")\n",
    "    \n",
    "    # ============================\n",
    "    # COMPARISON ANALYSIS BETWEEN GROUPS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"COMPARISON ANALYSIS BETWEEN GROUPS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nLocus Accuracy Comparison:\")\n",
    "    print(f\"Low pairing scores: {low_results['overall_locus_accuracy']:.1f}%\")\n",
    "    print(f\"High pairing scores: {high_results['overall_locus_accuracy']:.1f}%\")\n",
    "    print(f\"Difference: {high_results['overall_locus_accuracy'] - low_results['overall_locus_accuracy']:.1f} percentage points\")\n",
    "    \n",
    "    print(f\"\\nV Gene Diversity Comparison:\")\n",
    "    for level in ['full', 'simple', 'family']:\n",
    "        low_gen = len(low_results[f'gen_light_counts_{level}'])\n",
    "        high_gen = len(high_results[f'gen_light_counts_{level}'])\n",
    "        low_true = len(low_results[f'true_light_counts_{level}'])\n",
    "        high_true = len(high_results[f'true_light_counts_{level}'])\n",
    "        \n",
    "        print(f\"{level.capitalize()} - Generated light genes: Low={low_gen}, High={high_gen}\")\n",
    "        print(f\"{level.capitalize()} - True light genes: Low={low_true}, High={high_true}\")\n",
    "    \n",
    "    # Top genes comparison\n",
    "    print(f\"\\nTop 5 Generated Light V Genes Comparison:\")\n",
    "    print(f\"{'Low Score Group':<30} {'High Score Group':<30}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    low_top5_gen = low_results['gen_light_counts_full'].most_common(5)\n",
    "    high_top5_gen = high_results['gen_light_counts_full'].most_common(5)\n",
    "    \n",
    "    max_rows = max(len(low_top5_gen), len(high_top5_gen))\n",
    "    for i in range(max_rows):\n",
    "        low_entry = f\"{low_top5_gen[i][0]} ({low_top5_gen[i][1]})\" if i < len(low_top5_gen) else \"\"\n",
    "        high_entry = f\"{high_top5_gen[i][0]} ({high_top5_gen[i][1]})\" if i < len(high_top5_gen) else \"\"\n",
    "        print(f\"{low_entry:<30} {high_entry:<30}\")\n",
    "    \n",
    "    print(f\"\\nTop 5 True Light V Genes Comparison:\")\n",
    "    print(f\"{'Low Score Group':<30} {'High Score Group':<30}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    low_top5_true = low_results['true_light_counts_full'].most_common(5)\n",
    "    high_top5_true = high_results['true_light_counts_full'].most_common(5)\n",
    "    \n",
    "    max_rows = max(len(low_top5_true), len(high_top5_true))\n",
    "    for i in range(max_rows):\n",
    "        low_entry = f\"{low_top5_true[i][0]} ({low_top5_true[i][1]})\" if i < len(low_top5_true) else \"\"\n",
    "        high_entry = f\"{high_top5_true[i][0]} ({high_top5_true[i][1]})\" if i < len(high_top5_true) else \"\"\n",
    "        print(f\"{low_entry:<30} {high_entry:<30}\")\n",
    "    \n",
    "    # ============================\n",
    "    # RETURN RESULTS\n",
    "    # ============================\n",
    "    \n",
    "    return {\n",
    "        'overall_stats': {\n",
    "            'total_rows': len(df),\n",
    "            'rows_with_scores': len(df_clean),\n",
    "            'low_score_rows': len(df_low),\n",
    "            'high_score_rows': len(df_high),\n",
    "            'score_stats': {\n",
    "                'overall_mean': df_clean['pairing_scores'].mean(),\n",
    "                'overall_median': df_clean['pairing_scores'].median(),\n",
    "                'low_mean': df_low['pairing_scores'].mean() if len(df_low) > 0 else None,\n",
    "                'high_mean': df_high['pairing_scores'].mean() if len(df_high) > 0 else None\n",
    "            }\n",
    "        },\n",
    "        'low_score_group': low_results,\n",
    "        'high_score_group': high_results,\n",
    "        'heavy_gene_col': heavy_gene_col,\n",
    "        'consistency_analysis': consistency_results\n",
    "    }\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ffde5cd",
   "metadata": {},
   "source": [
    "csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/pairing_result_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted_rel_cols_merged_complete.csv'\n",
    "\n",
    "results = analyze_vgene_by_pairing_score(csv_file)\n",
    "if results:\n",
    "    print(\"\\nAnalysis completed successfully!\")\n",
    "    print(\"Results contain separate analyses for low (<0.5) and high (≥0.5) pairing score groups.\")\n",
    "    print(\"Generated vs True light chain V gene associations are compared for each group.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4d25558",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "def simplify_gene_name(gene_name):\n",
    "    \"\"\"Remove allele designation (part after *) from gene name\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    return str(gene_name).split('*')[0]\n",
    "\n",
    "def extract_gene_family(gene_name):\n",
    "    \"\"\"Extract gene family (e.g., IGHV3 from IGHV3-23*01)\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    simplified = str(gene_name).split('*')[0]\n",
    "    # Extract family part (everything before the dash)\n",
    "    if '-' in simplified:\n",
    "        return simplified.split('-')[0]\n",
    "    return simplified\n",
    "\n",
    "def analyze_vgene_consistency(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze V gene consistency - whether certain heavy V genes always generate \n",
    "    the same light chain V genes, using all generated sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for true light V gene column\n",
    "    true_light_vgene_col = None\n",
    "    possible_true_light_cols = ['true_light_gene_name', 'true_light_v_gene', 'light_gene_name', 'true_light_v_gene_name']\n",
    "    \n",
    "    for col in possible_true_light_cols:\n",
    "        if col in df.columns:\n",
    "            true_light_vgene_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"True light V gene column: {true_light_vgene_col if true_light_vgene_col else 'NOT FOUND'}\")\n",
    "    \n",
    "    # Get heavy chain V gene column\n",
    "    heavy_gene_col = None\n",
    "    possible_heavy_cols = ['heavy_gene_name', 'true_v_gene_simple', 'heavy_v_gene', 'true_heavy_gene']\n",
    "    \n",
    "    for col in possible_heavy_cols:\n",
    "        if col in df.columns:\n",
    "            heavy_gene_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"Heavy chain V gene column: {heavy_gene_col if heavy_gene_col else 'NOT FOUND'}\")\n",
    "    \n",
    "    # Get generated light chain V gene columns\n",
    "    light_gene_cols = [col for col in df.columns if col.startswith('gen_light_') and col.endswith('_gene_name')]\n",
    "    light_locus_cols = [col for col in df.columns if col.startswith('gen_light_') and col.endswith('_light_locus')]\n",
    "    \n",
    "    print(f\"Generated light gene columns found: {len(light_gene_cols)}\")\n",
    "    print(f\"Generated light locus columns found: {len(light_locus_cols)}\")\n",
    "    \n",
    "    if not heavy_gene_col:\n",
    "        print(\"❌ No heavy chain V gene column found - cannot analyze heavy-light consistency\")\n",
    "        return None\n",
    "    \n",
    "    if len(light_gene_cols) == 0:\n",
    "        print(\"❌ No generated light chain V gene columns found\")\n",
    "        return None\n",
    "    \n",
    "    # ============================\n",
    "    # COLLECT V GENE PAIRS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"COLLECTING V GENE ASSOCIATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Generated heavy-light pairs\n",
    "    gen_pairs_full = []\n",
    "    gen_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        heavy_gene = row[heavy_gene_col]\n",
    "        if pd.isna(heavy_gene):\n",
    "            continue\n",
    "            \n",
    "        for col in light_gene_cols:\n",
    "            light_gene = row[col]\n",
    "            if not pd.isna(light_gene):\n",
    "                gen_pairs_full.append((heavy_gene, light_gene))\n",
    "                gen_vgene_dist_full[heavy_gene][light_gene] += 1\n",
    "    \n",
    "    print(f\"Generated heavy-light V gene pairs: {len(gen_pairs_full)}\")\n",
    "    \n",
    "    # Create simplified and family versions for generated\n",
    "    gen_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                       for pair in gen_pairs_full]\n",
    "    gen_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                       for pair in gen_pairs_full]\n",
    "    \n",
    "    gen_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "    gen_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for heavy_gene, light_gene in gen_pairs_simple:\n",
    "        if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "            gen_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "    \n",
    "    for heavy_family, light_family in gen_pairs_family:\n",
    "        if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "            gen_vgene_dist_family[heavy_family][light_family] += 1\n",
    "    \n",
    "    # True heavy-light pairs (if available)\n",
    "    true_vgene_dist_full = defaultdict(lambda: defaultdict(int))\n",
    "    true_vgene_dist_simple = defaultdict(lambda: defaultdict(int))\n",
    "    true_vgene_dist_family = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    if true_light_vgene_col:\n",
    "        true_pairs_full = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            heavy_gene = row[heavy_gene_col]\n",
    "            true_light_gene = row[true_light_vgene_col]\n",
    "            if pd.isna(heavy_gene) or pd.isna(true_light_gene):\n",
    "                continue\n",
    "            \n",
    "            true_pairs_full.append((heavy_gene, true_light_gene))\n",
    "            true_vgene_dist_full[heavy_gene][true_light_gene] += 1\n",
    "        \n",
    "        print(f\"True heavy-light V gene pairs: {len(true_pairs_full)}\")\n",
    "        \n",
    "        # Create simplified and family versions for true\n",
    "        true_pairs_simple = [(simplify_gene_name(pair[0]), simplify_gene_name(pair[1])) \n",
    "                            for pair in true_pairs_full]\n",
    "        true_pairs_family = [(extract_gene_family(pair[0]), extract_gene_family(pair[1])) \n",
    "                            for pair in true_pairs_full]\n",
    "        \n",
    "        for heavy_gene, light_gene in true_pairs_simple:\n",
    "            if not pd.isna(heavy_gene) and not pd.isna(light_gene):\n",
    "                true_vgene_dist_simple[heavy_gene][light_gene] += 1\n",
    "        \n",
    "        for heavy_family, light_family in true_pairs_family:\n",
    "            if not pd.isna(heavy_family) and not pd.isna(light_family):\n",
    "                true_vgene_dist_family[heavy_family][light_family] += 1\n",
    "    \n",
    "    # Count frequencies\n",
    "    gen_heavy_counts_full = Counter([pair[0] for pair in gen_pairs_full])\n",
    "    gen_light_counts_full = Counter([pair[1] for pair in gen_pairs_full])\n",
    "    gen_heavy_counts_simple = Counter([pair[0] for pair in gen_pairs_simple if not pd.isna(pair[0])])\n",
    "    gen_light_counts_simple = Counter([pair[1] for pair in gen_pairs_simple if not pd.isna(pair[1])])\n",
    "    gen_heavy_counts_family = Counter([pair[0] for pair in gen_pairs_family if not pd.isna(pair[0])])\n",
    "    gen_light_counts_family = Counter([pair[1] for pair in gen_pairs_family if not pd.isna(pair[1])])\n",
    "    \n",
    "    print(f\"Generated - Full Names: {len(gen_heavy_counts_full)} heavy, {len(gen_light_counts_full)} light\")\n",
    "    print(f\"Generated - Simplified: {len(gen_heavy_counts_simple)} heavy, {len(gen_light_counts_simple)} light\")\n",
    "    print(f\"Generated - Families: {len(gen_heavy_counts_family)} heavy, {len(gen_light_counts_family)} light\")\n",
    "    \n",
    "    if true_light_vgene_col:\n",
    "        true_heavy_counts_full = Counter([pair[0] for pair in true_pairs_full])\n",
    "        true_light_counts_full = Counter([pair[1] for pair in true_pairs_full])\n",
    "        true_heavy_counts_simple = Counter([pair[0] for pair in true_pairs_simple if not pd.isna(pair[0])])\n",
    "        true_light_counts_simple = Counter([pair[1] for pair in true_pairs_simple if not pd.isna(pair[1])])\n",
    "        true_heavy_counts_family = Counter([pair[0] for pair in true_pairs_family if not pd.isna(pair[0])])\n",
    "        true_light_counts_family = Counter([pair[1] for pair in true_pairs_family if not pd.isna(pair[1])])\n",
    "        \n",
    "        print(f\"True - Full Names: {len(true_heavy_counts_full)} heavy, {len(true_light_counts_full)} light\")\n",
    "        print(f\"True - Simplified: {len(true_heavy_counts_simple)} heavy, {len(true_light_counts_simple)} light\")\n",
    "        print(f\"True - Families: {len(true_heavy_counts_family)} heavy, {len(true_light_counts_family)} light\")\n",
    "    \n",
    "    # ============================\n",
    "    # CONSISTENCY ANALYSIS FUNCTIONS\n",
    "    # ============================\n",
    "    \n",
    "    def analyze_heavy_light_consistency(vgene_dist, analysis_type, min_associations=5):\n",
    "        \"\"\"Analyze consistency of heavy-light V gene associations\"\"\"\n",
    "        \n",
    "        consistency_results = []\n",
    "        \n",
    "        for heavy_gene, light_dist in vgene_dist.items():\n",
    "            if len(light_dist) == 0:\n",
    "                continue\n",
    "                \n",
    "            total_associations = sum(light_dist.values())\n",
    "            \n",
    "            # Skip genes with too few associations\n",
    "            if total_associations < min_associations:\n",
    "                continue\n",
    "            \n",
    "            # Calculate diversity metrics\n",
    "            most_common_light = max(light_dist.items(), key=lambda x: x[1])\n",
    "            most_common_count = most_common_light[1]\n",
    "            most_common_pct = (most_common_count / total_associations) * 100\n",
    "            \n",
    "            # Calculate entropy (lower = more consistent)\n",
    "            proportions = np.array(list(light_dist.values())) / total_associations\n",
    "            entropy = -np.sum(proportions * np.log2(proportions + 1e-10))\n",
    "            \n",
    "            # Calculate Gini coefficient (higher = more concentrated)\n",
    "            sorted_counts = sorted(light_dist.values(), reverse=True)\n",
    "            n = len(sorted_counts)\n",
    "            cumsum = np.cumsum(sorted_counts)\n",
    "            gini = (n + 1 - 2 * np.sum(cumsum) / cumsum[-1]) / n if cumsum[-1] > 0 else 0\n",
    "            \n",
    "            # Consistency classification\n",
    "            if most_common_pct >= 95:\n",
    "                consistency_level = \"Perfect\"\n",
    "            elif most_common_pct >= 90:\n",
    "                consistency_level = \"Very High\"\n",
    "            elif most_common_pct >= 75:\n",
    "                consistency_level = \"High\"\n",
    "            elif most_common_pct >= 50:\n",
    "                consistency_level = \"Moderate\"\n",
    "            else:\n",
    "                consistency_level = \"Low\"\n",
    "            \n",
    "            consistency_results.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'total_associations': total_associations,\n",
    "                'unique_light_genes': len(light_dist),\n",
    "                'most_common_light': most_common_light[0],\n",
    "                'most_common_count': most_common_count,\n",
    "                'most_common_pct': most_common_pct,\n",
    "                'entropy': entropy,\n",
    "                'gini_coefficient': gini,\n",
    "                'consistency_level': consistency_level,\n",
    "                'light_distribution': dict(light_dist)\n",
    "            })\n",
    "        \n",
    "        # Sort by consistency (highest percentage first)\n",
    "        consistency_results.sort(key=lambda x: x['most_common_pct'], reverse=True)\n",
    "        \n",
    "        return consistency_results\n",
    "    \n",
    "    def print_consistency_results(consistency_results, analysis_type):\n",
    "        \"\"\"Print formatted consistency results\"\"\"\n",
    "        \n",
    "        print(f\"\\n{analysis_type} Consistency Results:\")\n",
    "        print(f\"{'Heavy V Gene':<25} {'Most Common Light':<25} {'Count':<8} {'%':<8} {'Unique':<8} {'Level':<12} {'Entropy':<8}\")\n",
    "        print(\"-\" * 110)\n",
    "        \n",
    "        for result in consistency_results[:25]:  # Show top 25\n",
    "            print(f\"{result['heavy_gene']:<25} {result['most_common_light']:<25} \"\n",
    "                  f\"{result['most_common_count']:<8} {result['most_common_pct']:<8.1f} \"\n",
    "                  f\"{result['unique_light_genes']:<8} {result['consistency_level']:<12} {result['entropy']:<8.2f}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        if consistency_results:\n",
    "            perfect = len([r for r in consistency_results if r['consistency_level'] == 'Perfect'])\n",
    "            very_high = len([r for r in consistency_results if r['consistency_level'] == 'Very High'])\n",
    "            high = len([r for r in consistency_results if r['consistency_level'] == 'High'])\n",
    "            moderate = len([r for r in consistency_results if r['consistency_level'] == 'Moderate'])\n",
    "            low = len([r for r in consistency_results if r['consistency_level'] == 'Low'])\n",
    "            \n",
    "            total = len(consistency_results)\n",
    "            \n",
    "            print(f\"\\nConsistency Summary ({total} heavy V genes analyzed):\")\n",
    "            print(f\"  Perfect (≥95%): {perfect} genes ({perfect/total*100:.1f}%)\")\n",
    "            print(f\"  Very High (90-94%): {very_high} genes ({very_high/total*100:.1f}%)\")\n",
    "            print(f\"  High (75-89%): {high} genes ({high/total*100:.1f}%)\")\n",
    "            print(f\"  Moderate (50-74%): {moderate} genes ({moderate/total*100:.1f}%)\")\n",
    "            print(f\"  Low (<50%): {low} genes ({low/total*100:.1f}%)\")\n",
    "            \n",
    "            # Find perfect/near-perfect matches\n",
    "            perfect_matches = [r for r in consistency_results if r['most_common_pct'] >= 95]\n",
    "            if perfect_matches:\n",
    "                print(f\"\\n🎯 PERFECT/NEAR-PERFECT MATCHES (≥95% consistency):\")\n",
    "                for match in perfect_matches[:15]:  # Top 15\n",
    "                    print(f\"  {match['heavy_gene']} → {match['most_common_light']} \"\n",
    "                          f\"({match['most_common_pct']:.1f}%, {match['total_associations']} total)\")\n",
    "            \n",
    "            # Find highly consistent genes\n",
    "            highly_consistent = [r for r in consistency_results if 90 <= r['most_common_pct'] < 95]\n",
    "            if highly_consistent:\n",
    "                print(f\"\\n⭐ HIGHLY CONSISTENT (90-94%):\")\n",
    "                for match in highly_consistent[:10]:  # Top 10\n",
    "                    print(f\"  {match['heavy_gene']} → {match['most_common_light']} \"\n",
    "                          f\"({match['most_common_pct']:.1f}%, {match['total_associations']} total)\")\n",
    "    \n",
    "    def create_consistency_heatmap(consistency_results, title, top_n=20):\n",
    "        \"\"\"Create a heatmap showing the most consistent heavy-light associations\"\"\"\n",
    "        \n",
    "        if not consistency_results:\n",
    "            print(f\"No data for {title}\")\n",
    "            return\n",
    "        \n",
    "        # Get top N most consistent heavy genes\n",
    "        top_results = consistency_results[:top_n]\n",
    "        \n",
    "        if len(top_results) < 2:\n",
    "            print(f\"Insufficient data for {title}\")\n",
    "            return\n",
    "        \n",
    "        # Create matrix for heatmap\n",
    "        heavy_genes = [r['heavy_gene'] for r in top_results]\n",
    "        all_light_genes = set()\n",
    "        for r in top_results:\n",
    "            all_light_genes.update(r['light_distribution'].keys())\n",
    "        all_light_genes = sorted(list(all_light_genes))\n",
    "        \n",
    "        # Create consistency matrix (percentages)\n",
    "        consistency_matrix = np.zeros((len(heavy_genes), len(all_light_genes)))\n",
    "        \n",
    "        for i, result in enumerate(top_results):\n",
    "            total = result['total_associations']\n",
    "            for j, light_gene in enumerate(all_light_genes):\n",
    "                count = result['light_distribution'].get(light_gene, 0)\n",
    "                consistency_matrix[i, j] = (count / total) * 100 if total > 0 else 0\n",
    "        \n",
    "        # Create heatmap\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(max(14, len(all_light_genes) * 0.8), max(10, len(heavy_genes) * 0.6)))\n",
    "        \n",
    "        im = ax.imshow(consistency_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=100)\n",
    "        ax.set_xticks(range(len(all_light_genes)))\n",
    "        ax.set_yticks(range(len(heavy_genes)))\n",
    "        ax.set_xticklabels(all_light_genes, rotation=45, ha='right', fontsize=8)\n",
    "        ax.set_yticklabels(heavy_genes, fontsize=8)\n",
    "        ax.set_title(f'{title}\\n(% of associations for each heavy V gene)')\n",
    "        ax.set_xlabel('Light V Genes')\n",
    "        ax.set_ylabel('Heavy V Genes (sorted by consistency)')\n",
    "        \n",
    "        # Add annotations for high percentages\n",
    "        for i in range(len(heavy_genes)):\n",
    "            for j in range(len(all_light_genes)):\n",
    "                value = consistency_matrix[i, j]\n",
    "                if value >= 30:  # Only annotate if ≥30%\n",
    "                    text_color = 'white' if value > 50 else 'black'\n",
    "                    ax.text(j, i, f'{value:.0f}%', ha='center', va='center', \n",
    "                           fontsize=7, color=text_color, weight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Percentage of Associations (%)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # ============================\n",
    "    # RUN CONSISTENCY ANALYSIS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"V GENE CONSISTENCY ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Analyze generated V gene consistency at all levels\n",
    "    gen_consistency_full = analyze_heavy_light_consistency(gen_vgene_dist_full, \"Generated Full Names\")\n",
    "    gen_consistency_simple = analyze_heavy_light_consistency(gen_vgene_dist_simple, \"Generated Simplified\")\n",
    "    gen_consistency_family = analyze_heavy_light_consistency(gen_vgene_dist_family, \"Generated Families\")\n",
    "    \n",
    "    print_consistency_results(gen_consistency_full, \"GENERATED - FULL NAMES\")\n",
    "    print_consistency_results(gen_consistency_simple, \"GENERATED - SIMPLIFIED\")\n",
    "    print_consistency_results(gen_consistency_family, \"GENERATED - FAMILIES\")\n",
    "    \n",
    "    # Analyze true V gene consistency if available\n",
    "    if true_light_vgene_col:\n",
    "        true_consistency_full = analyze_heavy_light_consistency(true_vgene_dist_full, \"True Full Names\")\n",
    "        true_consistency_simple = analyze_heavy_light_consistency(true_vgene_dist_simple, \"True Simplified\")\n",
    "        true_consistency_family = analyze_heavy_light_consistency(true_vgene_dist_family, \"True Families\")\n",
    "        \n",
    "        print_consistency_results(true_consistency_full, \"TRUE - FULL NAMES\")\n",
    "        print_consistency_results(true_consistency_simple, \"TRUE - SIMPLIFIED\")\n",
    "        print_consistency_results(true_consistency_family, \"TRUE - FAMILIES\")\n",
    "    \n",
    "    # ============================\n",
    "    # CREATE CONSISTENCY HEATMAPS\n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    print(\"CREATING CONSISTENCY HEATMAPS...\")\n",
    "    \n",
    "    # Generated consistency heatmaps\n",
    "    create_consistency_heatmap(gen_consistency_full, \"Generated V Gene Consistency (Full Names)\")\n",
    "    create_consistency_heatmap(gen_consistency_simple, \"Generated V Gene Consistency (Simplified)\")\n",
    "    create_consistency_heatmap(gen_consistency_family, \"Generated V Gene Consistency (Families)\")\n",
    "    \n",
    "    # True consistency heatmaps (if available)\n",
    "    if true_light_vgene_col:\n",
    "        create_consistency_heatmap(true_consistency_full, \"True V Gene Consistency (Full Names)\")\n",
    "        create_consistency_heatmap(true_consistency_simple, \"True V Gene Consistency (Simplified)\")\n",
    "        create_consistency_heatmap(true_consistency_family, \"True V Gene Consistency (Families)\")\n",
    "    \n",
    "    # ============================\n",
    "    # COMPARE GENERATED VS TRUE CONSISTENCY\n",
    "    # ============================\n",
    "    \n",
    "    if true_light_vgene_col:\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        print(\"GENERATED vs TRUE CONSISTENCY COMPARISON\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        def compare_consistency(gen_results, true_results, level_name):\n",
    "            print(f\"\\n{level_name} Consistency Comparison:\")\n",
    "            \n",
    "            # Create dictionaries for easier lookup\n",
    "            gen_dict = {r['heavy_gene']: r for r in gen_results}\n",
    "            true_dict = {r['heavy_gene']: r for r in true_results}\n",
    "            \n",
    "            # Find common heavy genes\n",
    "            common_genes = set(gen_dict.keys()).intersection(set(true_dict.keys()))\n",
    "            \n",
    "            if len(common_genes) == 0:\n",
    "                print(\"  No common heavy genes found\")\n",
    "                return\n",
    "            \n",
    "            print(f\"  Common heavy genes: {len(common_genes)}\")\n",
    "            \n",
    "            # Compare consistency levels\n",
    "            gen_high_consistency = len([r for r in gen_results if r['most_common_pct'] >= 90])\n",
    "            true_high_consistency = len([r for r in true_results if r['most_common_pct'] >= 90])\n",
    "            \n",
    "            print(f\"  High consistency (≥90%): Generated={gen_high_consistency}, True={true_high_consistency}\")\n",
    "            \n",
    "            # Find genes with matching top light chains\n",
    "            matching_top_light = 0\n",
    "            for gene in common_genes:\n",
    "                if gen_dict[gene]['most_common_light'] == true_dict[gene]['most_common_light']:\n",
    "                    matching_top_light += 1\n",
    "            \n",
    "            print(f\"  Genes with matching top light chains: {matching_top_light}/{len(common_genes)} ({matching_top_light/len(common_genes)*100:.1f}%)\")\n",
    "            \n",
    "            # Show top mismatches\n",
    "            print(f\"\\n  Top mismatches (different preferred light chains):\")\n",
    "            mismatches = []\n",
    "            for gene in common_genes:\n",
    "                if gen_dict[gene]['most_common_light'] != true_dict[gene]['most_common_light']:\n",
    "                    mismatches.append({\n",
    "                        'heavy': gene,\n",
    "                        'gen_light': gen_dict[gene]['most_common_light'],\n",
    "                        'true_light': true_dict[gene]['most_common_light'],\n",
    "                        'gen_pct': gen_dict[gene]['most_common_pct'],\n",
    "                        'true_pct': true_dict[gene]['most_common_pct']\n",
    "                    })\n",
    "            \n",
    "            # Sort by generated consistency (most consistent first)\n",
    "            mismatches.sort(key=lambda x: x['gen_pct'], reverse=True)\n",
    "            \n",
    "            for mismatch in mismatches[:10]:  # Show top 10\n",
    "                print(f\"    {mismatch['heavy']}: Gen→{mismatch['gen_light']} ({mismatch['gen_pct']:.1f}%) vs True→{mismatch['true_light']} ({mismatch['true_pct']:.1f}%)\")\n",
    "        \n",
    "        # Compare at all levels\n",
    "        compare_consistency(gen_consistency_full, true_consistency_full, \"Full Names\")\n",
    "        compare_consistency(gen_consistency_simple, true_consistency_simple, \"Simplified\")\n",
    "        compare_consistency(gen_consistency_family, true_consistency_family, \"Families\")\n",
    "    \n",
    "    # ============================\n",
    "    # RETURN RESULTS\n",
    "    # ============================\n",
    "    \n",
    "    return {\n",
    "        'dataset_info': {\n",
    "            'total_rows': len(df),\n",
    "            'heavy_gene_col': heavy_gene_col,\n",
    "            'true_light_vgene_col': true_light_vgene_col,\n",
    "            'gen_light_cols': light_gene_cols,\n",
    "            'gen_pairs_count': len(gen_pairs_full),\n",
    "            'true_pairs_count': len(true_pairs_full) if true_light_vgene_col else 0\n",
    "        },\n",
    "        'generated_consistency': {\n",
    "            'full': gen_consistency_full,\n",
    "            'simple': gen_consistency_simple,\n",
    "            'family': gen_consistency_family\n",
    "        },\n",
    "        'true_consistency': {\n",
    "            'full': true_consistency_full if true_light_vgene_col else None,\n",
    "            'simple': true_consistency_simple if true_light_vgene_col else None,\n",
    "            'family': true_consistency_family if true_light_vgene_col else None\n",
    "        } if true_light_vgene_col else None,\n",
    "        'vgene_distributions': {\n",
    "            'generated': {\n",
    "                'full': dict(gen_vgene_dist_full),\n",
    "                'simple': dict(gen_vgene_dist_simple),\n",
    "                'family': dict(gen_vgene_dist_family)\n",
    "            },\n",
    "            'true': {\n",
    "                'full': dict(true_vgene_dist_full),\n",
    "                'simple': dict(true_vgene_dist_simple),\n",
    "                'family': dict(true_vgene_dist_family)\n",
    "            } if true_light_vgene_col else None\n",
    "        }\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a7f32d9",
   "metadata": {},
   "source": [
    "\n",
    "# Example usage\n",
    "csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed_reformatted.csv'\n",
    "    \n",
    "try:\n",
    "    results = analyze_vgene_consistency(csv_file)\n",
    "    if results:\n",
    "        print(\"\\nV Gene Consistency Analysis completed successfully!\")\n",
    "        print(\"Results show which heavy V genes consistently generate the same light V genes.\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the file '{csv_file}'\")\n",
    "    print(\"Please make sure the file path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "952f458f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_gene_names_from_split_files(first_csv_path, matching_csv_path, non_matching_csv_path, output_path):\n",
    "    \"\"\"\n",
    "    Merge gene_name information from matching and non-matching CSV files to first CSV based on sequence_id patterns.\n",
    "    \n",
    "    Args:\n",
    "        first_csv_path (str): Path to the first CSV file with heavy/light chain data\n",
    "        matching_csv_path (str): Path to the matching sequences CSV file with gene_name information\n",
    "        non_matching_csv_path (str): Path to the non-matching sequences CSV file with gene_name information\n",
    "        output_path (str): Path for the output merged CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(first_csv_path)\n",
    "    df_matching = pd.read_csv(matching_csv_path)\n",
    "    df_non_matching = pd.read_csv(non_matching_csv_path)\n",
    "    \n",
    "    # Combine both matching and non-matching dataframes\n",
    "    df2_combined = pd.concat([df_matching, df_non_matching], ignore_index=True)\n",
    "    \n",
    "    # Create a mapping dictionary from sequence_id to gene_name\n",
    "    gene_name_mapping = dict(zip(df2_combined['sequence_id'], df2_combined['gene_name']))\n",
    "    \n",
    "    # Initialize new columns for gene names\n",
    "    df1['gen_light_gene_name'] = None\n",
    "    df1['true_light_gene_name'] = None\n",
    "    df1['heavy_chain_gene_name'] = None\n",
    "    \n",
    "    # Process each row in the first dataframe\n",
    "    for idx, row in df1.iterrows():\n",
    "        heavy_chain_num = row['heavy_chain_number']\n",
    "        gen_light_num = row['gen_light_chain_number']\n",
    "        \n",
    "        # Map generated light chain gene name\n",
    "        gen_light_id = f\"gen_light_{gen_light_num}_heavy_chain_{heavy_chain_num}\"\n",
    "        if gen_light_id in gene_name_mapping:\n",
    "            df1.at[idx, 'gen_light_gene_name'] = gene_name_mapping[gen_light_id]\n",
    "        \n",
    "        # Map true light chain gene name\n",
    "        true_light_id = f\"true_light_chain_heavy_chain_{heavy_chain_num}\"\n",
    "        if true_light_id in gene_name_mapping:\n",
    "            df1.at[idx, 'true_light_gene_name'] = gene_name_mapping[true_light_id]\n",
    "        \n",
    "        # Map heavy chain gene name\n",
    "        heavy_chain_id = f\"heavy_chain_{heavy_chain_num}\"\n",
    "        if heavy_chain_id in gene_name_mapping:\n",
    "            df1.at[idx, 'heavy_chain_gene_name'] = gene_name_mapping[heavy_chain_id]\n",
    "    \n",
    "    # Save the merged dataframe\n",
    "    df1.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"Total rows processed: {len(df1)}\")\n",
    "    print(f\"Generated light chain gene names found: {df1['gen_light_gene_name'].notna().sum()}\")\n",
    "    print(f\"True light chain gene names found: {df1['true_light_gene_name'].notna().sum()}\")\n",
    "    print(f\"Heavy chain gene names found: {df1['heavy_chain_gene_name'].notna().sum()}\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def merge_gene_names_single_column_from_split_files(first_csv_path, matching_csv_path, non_matching_csv_path, output_path):\n",
    "    \"\"\"\n",
    "    Merge gene_name information from matching and non-matching CSV files to first CSV, focusing on generated light chains.\n",
    "    \n",
    "    Args:\n",
    "        first_csv_path (str): Path to the first CSV file with heavy/light chain data\n",
    "        matching_csv_path (str): Path to the matching sequences CSV file with gene_name information\n",
    "        non_matching_csv_path (str): Path to the non-matching sequences CSV file with gene_name information\n",
    "        output_path (str): Path for the output merged CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(first_csv_path)\n",
    "    df_matching = pd.read_csv(matching_csv_path)\n",
    "    df_non_matching = pd.read_csv(non_matching_csv_path)\n",
    "    \n",
    "    # Combine both matching and non-matching dataframes\n",
    "    df2_combined = pd.concat([df_matching, df_non_matching], ignore_index=True)\n",
    "    \n",
    "    # Create a mapping dictionary from sequence_id to gene_name\n",
    "    gene_name_mapping = dict(zip(df2_combined['sequence_id'], df2_combined['gene_name']))\n",
    "    \n",
    "    # Initialize new column for gene names\n",
    "    df1['gene_name'] = None\n",
    "    \n",
    "    # Process each row in the first dataframe\n",
    "    for idx, row in df1.iterrows():\n",
    "        heavy_chain_num = row['heavy_chain_number']\n",
    "        gen_light_num = row['gen_light_chain_number']\n",
    "        \n",
    "        # Map generated light chain gene name\n",
    "        gen_light_id = f\"gen_light_{gen_light_num}_heavy_chain_{heavy_chain_num}\"\n",
    "        if gen_light_id in gene_name_mapping:\n",
    "            df1.at[idx, 'gene_name'] = gene_name_mapping[gen_light_id]\n",
    "    \n",
    "    # Save the merged dataframe\n",
    "    df1.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"Total rows processed: {len(df1)}\")\n",
    "    print(f\"Gene names found: {df1['gene_name'].notna().sum()}\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def analyze_sequence_coverage(first_csv_path, matching_csv_path, non_matching_csv_path):\n",
    "    \"\"\"\n",
    "    Analyze which sequences from the first CSV are covered in the matching/non-matching files.\n",
    "    Useful for debugging and understanding data coverage.\n",
    "    \n",
    "    Args:\n",
    "        first_csv_path (str): Path to the first CSV file with heavy/light chain data\n",
    "        matching_csv_path (str): Path to the matching sequences CSV file\n",
    "        non_matching_csv_path (str): Path to the non-matching sequences CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(first_csv_path)\n",
    "    df_matching = pd.read_csv(matching_csv_path)\n",
    "    df_non_matching = pd.read_csv(non_matching_csv_path)\n",
    "    \n",
    "    # Combine both matching and non-matching dataframes\n",
    "    df2_combined = pd.concat([df_matching, df_non_matching], ignore_index=True)\n",
    "    \n",
    "    # Get all sequence IDs from the combined data\n",
    "    available_sequence_ids = set(df2_combined['sequence_id'])\n",
    "    \n",
    "    # Create expected sequence IDs from the first CSV\n",
    "    expected_gen_light_ids = set()\n",
    "    expected_true_light_ids = set()\n",
    "    expected_heavy_ids = set()\n",
    "    \n",
    "    for _, row in df1.iterrows():\n",
    "        heavy_chain_num = row['heavy_chain_number']\n",
    "        gen_light_num = row['gen_light_chain_number']\n",
    "        \n",
    "        expected_gen_light_ids.add(f\"gen_light_{gen_light_num}_heavy_chain_{heavy_chain_num}\")\n",
    "        expected_true_light_ids.add(f\"true_light_chain_heavy_chain_{heavy_chain_num}\")\n",
    "        expected_heavy_ids.add(f\"heavy_chain_{heavy_chain_num}\")\n",
    "    \n",
    "    # Check coverage\n",
    "    print(\"=== SEQUENCE COVERAGE ANALYSIS ===\")\n",
    "    print(f\"Total rows in first CSV: {len(df1)}\")\n",
    "    print(f\"Total sequences in matching file: {len(df_matching)}\")\n",
    "    print(f\"Total sequences in non-matching file: {len(df_non_matching)}\")\n",
    "    print(f\"Total combined sequences: {len(df2_combined)}\")\n",
    "    \n",
    "    print(f\"\\nGenerated light chain coverage:\")\n",
    "    print(f\"  Expected: {len(expected_gen_light_ids)}\")\n",
    "    print(f\"  Found: {len(expected_gen_light_ids & available_sequence_ids)}\")\n",
    "    print(f\"  Missing: {len(expected_gen_light_ids - available_sequence_ids)}\")\n",
    "    \n",
    "    print(f\"\\nTrue light chain coverage:\")\n",
    "    print(f\"  Expected: {len(expected_true_light_ids)}\")\n",
    "    print(f\"  Found: {len(expected_true_light_ids & available_sequence_ids)}\")\n",
    "    print(f\"  Missing: {len(expected_true_light_ids - available_sequence_ids)}\")\n",
    "    \n",
    "    print(f\"\\nHeavy chain coverage:\")\n",
    "    print(f\"  Expected: {len(expected_heavy_ids)}\")\n",
    "    print(f\"  Found: {len(expected_heavy_ids & available_sequence_ids)}\")\n",
    "    print(f\"  Missing: {len(expected_heavy_ids - available_sequence_ids)}\")\n",
    "    \n",
    "    # Show some examples of missing sequences (if any)\n",
    "    missing_gen_light = expected_gen_light_ids - available_sequence_ids\n",
    "    if missing_gen_light:\n",
    "        print(f\"\\nExample missing generated light chains: {list(missing_gen_light)[:5]}\")\n",
    "    \n",
    "    missing_true_light = expected_true_light_ids - available_sequence_ids\n",
    "    if missing_true_light:\n",
    "        print(f\"Example missing true light chains: {list(missing_true_light)[:5]}\")\n",
    "    \n",
    "    missing_heavy = expected_heavy_ids - available_sequence_ids\n",
    "    if missing_heavy:\n",
    "        print(f\"Example missing heavy chains: {list(missing_heavy)[:5]}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "029be28f",
   "metadata": {},
   "source": [
    "\n",
    "first_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions.csv\"\n",
    "matching_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\"\n",
    "non_matching_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/non_matching_seqs_multiple_light_seqs_203276_cls_predictions_parsed.csv\"\n",
    "output_csv = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv\"\n",
    "\n",
    "# First, analyze coverage to understand your data\n",
    "analyze_sequence_coverage(first_csv, matching_csv, non_matching_csv)\n",
    "    \n",
    "# Option 1: Add separate gene name columns for each sequence type\n",
    "merged_df = merge_gene_names_from_split_files(first_csv, matching_csv, non_matching_csv, output_csv)\n",
    "    \n",
    "# Option 2: Add only generated light chain gene names\n",
    "# merged_df = merge_gene_names_single_column_from_split_files(first_csv, matching_csv, non_matching_csv, output_csv)\n",
    "    \n",
    "# Display first few rows to verify\n",
    "print(\"\\nFirst few rows of merged data:\")\n",
    "print(merged_df.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fea1ec0",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.stats import entropy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f591772",
   "metadata": {},
   "source": [
    "df = pd.read_csv('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv')\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Unique heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "print(f\"Generated light chains per heavy chain: {df['gen_light_chain_number'].max()}\")\n",
    "print(f\"Unique heavy V genes: {df['heavy_chain_gene_name'].nunique()}\")\n",
    "print(f\"Unique generated light V genes: {df['gen_light_gene_name'].nunique()}\")\n",
    "print(f\"Unique true light V genes: {df['true_light_gene_name'].nunique()}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf0e2093",
   "metadata": {},
   "source": [
    "# Function to simplify gene names (remove allele info)\n",
    "def simplify_gene_name(gene_name):\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    # Remove allele information (e.g., *01, *02)\n",
    "    return re.sub(r'\\*\\d+', '', str(gene_name))\n",
    "\n",
    "# Function to get gene family (e.g., IGHV3 from IGHV3-23)\n",
    "def get_gene_family(gene_name):\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    # Extract family (e.g., IGHV3 from IGHV3-23*01)\n",
    "    match = re.match(r'([A-Z]+\\d+)', str(gene_name))\n",
    "    return match.group(1) if match else str(gene_name)\n",
    "\n",
    "# Add simplified and family columns\n",
    "df['heavy_gene_simplified'] = df['heavy_chain_gene_name'].apply(simplify_gene_name)\n",
    "df['heavy_gene_family'] = df['heavy_chain_gene_name'].apply(get_gene_family)\n",
    "df['gen_light_gene_simplified'] = df['gen_light_gene_name'].apply(simplify_gene_name)\n",
    "df['gen_light_gene_family'] = df['gen_light_gene_name'].apply(get_gene_family)\n",
    "df['true_light_gene_simplified'] = df['true_light_gene_name'].apply(simplify_gene_name)\n",
    "df['true_light_gene_family'] = df['true_light_gene_name'].apply(get_gene_family)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46d76fb4",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"V GENE CONSISTENCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_consistency(heavy_col, light_col, analysis_name):\n",
    "    \"\"\"Analyze consistency between heavy and light V genes\"\"\"\n",
    "    print(f\"\\n{analysis_name}\")\n",
    "    print(\"-\" * len(analysis_name))\n",
    "    \n",
    "    # Calculate consistency for each heavy V gene\n",
    "    consistency_results = []\n",
    "    \n",
    "    for heavy_gene in df[heavy_col].dropna().unique():\n",
    "        heavy_data = df[df[heavy_col] == heavy_gene]\n",
    "        \n",
    "        # Count light gene associations\n",
    "        light_counts = heavy_data[light_col].value_counts()\n",
    "        \n",
    "        if len(light_counts) > 0:\n",
    "            total_associations = len(heavy_data)\n",
    "            most_common_light = light_counts.index[0]\n",
    "            most_common_count = light_counts.iloc[0]\n",
    "            consistency_pct = (most_common_count / total_associations) * 100\n",
    "            unique_light_genes = len(light_counts)\n",
    "            \n",
    "            # Calculate entropy (diversity measure)\n",
    "            probs = light_counts.values / total_associations\n",
    "            gene_entropy = entropy(probs)\n",
    "            \n",
    "            consistency_results.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'most_common_light': most_common_light,\n",
    "                'consistency_pct': consistency_pct,\n",
    "                'most_common_count': most_common_count,\n",
    "                'total_associations': total_associations,\n",
    "                'unique_light_genes': unique_light_genes,\n",
    "                'entropy': gene_entropy,\n",
    "                'light_distribution': dict(light_counts)\n",
    "            })\n",
    "    \n",
    "    consistency_df = pd.DataFrame(consistency_results)\n",
    "    consistency_df = consistency_df.sort_values('consistency_pct', ascending=False)\n",
    "    \n",
    "    # Categorize consistency levels\n",
    "    def categorize_consistency(pct):\n",
    "        if pct >= 95:\n",
    "            return 'Perfect (≥95%)'\n",
    "        elif pct >= 90:\n",
    "            return 'Very High (90-94%)'\n",
    "        elif pct >= 75:\n",
    "            return 'High (75-89%)'\n",
    "        elif pct >= 50:\n",
    "            return 'Moderate (50-74%)'\n",
    "        else:\n",
    "            return 'Low (<50%)'\n",
    "    \n",
    "    consistency_df['consistency_category'] = consistency_df['consistency_pct'].apply(categorize_consistency)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nConsistency Level Distribution:\")\n",
    "    category_counts = consistency_df['consistency_category'].value_counts()\n",
    "    for category in ['Perfect (≥95%)', 'Very High (90-94%)', 'High (75-89%)', 'Moderate (50-74%)', 'Low (<50%)']:\n",
    "        count = category_counts.get(category, 0)\n",
    "        pct = (count / len(consistency_df)) * 100 if len(consistency_df) > 0 else 0\n",
    "        print(f\"  {category}: {count} genes ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Average consistency: {consistency_df['consistency_pct'].mean():.1f}%\")\n",
    "    print(f\"  Median consistency: {consistency_df['consistency_pct'].median():.1f}%\")\n",
    "    print(f\"  Average unique light genes per heavy: {consistency_df['unique_light_genes'].mean():.1f}\")\n",
    "    print(f\"  Average entropy: {consistency_df['entropy'].mean():.3f}\")\n",
    "    \n",
    "    # Show top consistent genes\n",
    "    print(f\"\\nTop 10 Most Consistent Heavy V Genes:\")\n",
    "    top_consistent = consistency_df.head(10)\n",
    "    for _, row in top_consistent.iterrows():\n",
    "        print(f\"  {row['heavy_gene']}: {row['consistency_pct']:.1f}% → {row['most_common_light']} \"\n",
    "              f\"({row['most_common_count']}/{row['total_associations']})\")\n",
    "    \n",
    "    # Show most diverse genes\n",
    "    print(f\"\\nTop 10 Most Diverse Heavy V Genes:\")\n",
    "    most_diverse = consistency_df.nlargest(10, 'unique_light_genes')\n",
    "    for _, row in most_diverse.iterrows():\n",
    "        print(f\"  {row['heavy_gene']}: {row['unique_light_genes']} different light genes, \"\n",
    "              f\"{row['consistency_pct']:.1f}% consistency\")\n",
    "    \n",
    "    return consistency_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cadbf904",
   "metadata": {},
   "source": [
    "# Analyze at different levels\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"1. FULL NAME ANALYSIS (Allele-Specific)\")\n",
    "print(\"=\"*50)\n",
    "gen_full_consistency = analyze_consistency('heavy_chain_gene_name', 'gen_light_gene_name', \n",
    "                                          \"Generated Light Chains - Full Names\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. SIMPLIFIED ANALYSIS (Gene-Level)\")\n",
    "print(\"=\"*50)\n",
    "gen_simplified_consistency = analyze_consistency('heavy_gene_simplified', 'gen_light_gene_simplified', \n",
    "                                                \"Generated Light Chains - Simplified\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. FAMILY ANALYSIS (Family-Level)\")\n",
    "print(\"=\"*50)\n",
    "gen_family_consistency = analyze_consistency('heavy_gene_family', 'gen_light_gene_family', \n",
    "                                            \"Generated Light Chains - Family Level\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. TRUE LIGHT CHAIN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"4a. TRUE - FULL NAME ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "true_full_consistency = analyze_consistency('heavy_chain_gene_name', 'true_light_gene_name', \n",
    "                                           \"True Light Chains - Full Names\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"4b. TRUE - SIMPLIFIED ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "true_simplified_consistency = analyze_consistency('heavy_gene_simplified', 'true_light_gene_simplified', \n",
    "                                                 \"True Light Chains - Simplified\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"4c. TRUE - FAMILY ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "true_family_consistency = analyze_consistency('heavy_gene_family', 'true_light_gene_family', \n",
    "                                             \"True Light Chains - Family Level\")\n",
    "\n",
    "# Compare generated vs true preferences\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. GENERATED vs TRUE COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Merge generated and true consistency results\n",
    "comparison_df = pd.merge(\n",
    "    gen_full_consistency[['heavy_gene', 'most_common_light', 'consistency_pct']],\n",
    "    true_full_consistency[['heavy_gene', 'most_common_light', 'consistency_pct']],\n",
    "    on='heavy_gene', suffixes=('_gen', '_true'), how='outer'\n",
    ")\n",
    "\n",
    "# Find matching preferences\n",
    "comparison_df['preferences_match'] = comparison_df['most_common_light_gen'] == comparison_df['most_common_light_true']\n",
    "comparison_df['consistency_diff'] = comparison_df['consistency_pct_gen'] - comparison_df['consistency_pct_true']\n",
    "\n",
    "print(f\"\\nPreference Matching:\")\n",
    "matches = comparison_df['preferences_match'].sum()\n",
    "total = len(comparison_df)\n",
    "print(f\"  Heavy V genes with matching preferences: {matches}/{total} ({matches/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nConsistency Comparison:\")\n",
    "gen_avg = comparison_df['consistency_pct_gen'].mean()\n",
    "true_avg = comparison_df['consistency_pct_true'].mean()\n",
    "print(f\"  Generated average consistency: {gen_avg:.1f}%\")\n",
    "print(f\"  True average consistency: {true_avg:.1f}%\")\n",
    "print(f\"  Difference: {gen_avg - true_avg:.1f} percentage points\")\n",
    "\n",
    "print(f\"\\nTop Mismatches (Generated ≠ True Preferences):\")\n",
    "mismatches = comparison_df[~comparison_df['preferences_match']].head(10)\n",
    "for _, row in mismatches.iterrows():\n",
    "    print(f\"  {row['heavy_gene']}: Gen→{row['most_common_light_gen']} vs True→{row['most_common_light_true']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8b97906",
   "metadata": {},
   "source": [
    "# Create comparison visualization heatmaps\n",
    "def create_comparison_heatmap(comparison_df, metric='consistency_pct', top_n=20):\n",
    "    \"\"\"Create side-by-side heatmaps comparing generated vs true\"\"\"\n",
    "    \n",
    "    # Filter to top heavy genes by frequency and clean data\n",
    "    valid_comparison = comparison_df.dropna(subset=[f'{metric}_gen', f'{metric}_true'])\n",
    "    \n",
    "    # Calculate total occurrences for each heavy gene to rank by importance\n",
    "    heavy_gene_counts = pd.concat([\n",
    "        df.groupby('heavy_chain_gene_name').size(),\n",
    "    ]).sort_values(ascending=False)\n",
    "    \n",
    "    # Get top heavy genes that appear in comparison\n",
    "    top_heavy_genes = [gene for gene in heavy_gene_counts.index \n",
    "                      if gene in valid_comparison['heavy_gene'].values][:top_n]\n",
    "    \n",
    "    # Filter comparison data\n",
    "    plot_data = valid_comparison[valid_comparison['heavy_gene'].isin(top_heavy_genes)]\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    \n",
    "    # Prepare data for heatmaps\n",
    "    plot_data_sorted = plot_data.sort_values(f'{metric}_true', ascending=False)\n",
    "    \n",
    "    # Heatmap 1: Generated consistency\n",
    "    gen_data = plot_data_sorted.set_index('heavy_gene')[[f'{metric}_gen']]\n",
    "    sns.heatmap(gen_data, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Consistency (%)'}, ax=axes[0])\n",
    "    axes[0].set_title('Generated Light Chain\\nConsistency (%)')\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].set_ylabel('Heavy V Gene')\n",
    "    \n",
    "    # Heatmap 2: True consistency  \n",
    "    true_data = plot_data_sorted.set_index('heavy_gene')[[f'{metric}_true']]\n",
    "    sns.heatmap(true_data, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Consistency (%)'}, ax=axes[1])\n",
    "    axes[1].set_title('True Light Chain\\nConsistency (%)')\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    # Heatmap 3: Difference (Generated - True)\n",
    "    diff_data = plot_data_sorted.set_index('heavy_gene')[['consistency_diff']]\n",
    "    sns.heatmap(diff_data, annot=True, fmt='.1f', cmap='RdBu_r', center=0,\n",
    "                cbar_kws={'label': 'Difference (%)'}, ax=axes[2])\n",
    "    axes[2].set_title('Difference\\n(Generated - True)')\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[2].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return plot_data_sorted\n",
    "\n",
    "def create_preference_matching_heatmap(comparison_df, top_n=20):\n",
    "    \"\"\"Create heatmap showing preference matching patterns\"\"\"\n",
    "    \n",
    "    # Get top heavy genes by frequency\n",
    "    heavy_gene_counts = df.groupby('heavy_chain_gene_name').size().sort_values(ascending=False)\n",
    "    top_heavy_genes = [gene for gene in heavy_gene_counts.index \n",
    "                      if gene in comparison_df['heavy_gene'].values][:top_n]\n",
    "    \n",
    "    # Filter and prepare data\n",
    "    plot_data = comparison_df[comparison_df['heavy_gene'].isin(top_heavy_genes)].copy()\n",
    "    \n",
    "    # Create matching status and consistency level categories\n",
    "    plot_data['match_status'] = plot_data['preferences_match'].map({True: 'Match', False: 'Mismatch'})\n",
    "    \n",
    "    # Create performance categories\n",
    "    def performance_category(row):\n",
    "        if pd.isna(row['consistency_pct_gen']) or pd.isna(row['consistency_pct_true']):\n",
    "            return 'No Data'\n",
    "        \n",
    "        gen_pct = row['consistency_pct_gen']\n",
    "        true_pct = row['consistency_pct_true']\n",
    "        diff = abs(gen_pct - true_pct)\n",
    "        \n",
    "        if row['preferences_match']:\n",
    "            if diff <= 10:\n",
    "                return 'Excellent Match'\n",
    "            elif diff <= 20:\n",
    "                return 'Good Match'\n",
    "            else:\n",
    "                return 'Poor Match'\n",
    "        else:\n",
    "            return 'Wrong Preference'\n",
    "    \n",
    "    plot_data['performance'] = plot_data.apply(performance_category, axis=1)\n",
    "    \n",
    "    # Create summary matrix for heatmap\n",
    "    summary_data = []\n",
    "    for _, row in plot_data.iterrows():\n",
    "        summary_data.append({\n",
    "            'heavy_gene': row['heavy_gene'],\n",
    "            'generated_consistency': row['consistency_pct_gen'],\n",
    "            'true_consistency': row['consistency_pct_true'],\n",
    "            'performance': row['performance'],\n",
    "            'gen_light': row['most_common_light_gen'],\n",
    "            'true_light': row['most_common_light_true']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Sort by true consistency for better visualization\n",
    "    summary_df = summary_df.sort_values('true_consistency', ascending=False)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create performance score for color mapping\n",
    "    performance_scores = {\n",
    "        'Excellent Match': 4,\n",
    "        'Good Match': 3, \n",
    "        'Poor Match': 2,\n",
    "        'Wrong Preference': 1,\n",
    "        'No Data': 0\n",
    "    }\n",
    "    \n",
    "    summary_df['performance_score'] = summary_df['performance'].map(performance_scores)\n",
    "    \n",
    "    # Create heatmap data\n",
    "    heatmap_data = summary_df.set_index('heavy_gene')[['performance_score']]\n",
    "    \n",
    "    # Create custom colormap\n",
    "    colors = ['lightgray', 'red', 'orange', 'lightgreen', 'darkgreen']\n",
    "    cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "    \n",
    "    sns.heatmap(heatmap_data, annot=False, cmap=cmap, \n",
    "                cbar_kws={'label': 'Performance Level'}, ax=ax)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i, (_, row) in enumerate(summary_df.iterrows()):\n",
    "        gen_pct = row['generated_consistency']\n",
    "        true_pct = row['true_consistency']\n",
    "        if pd.notna(gen_pct) and pd.notna(true_pct):\n",
    "            ax.text(0.5, i + 0.5, f'{gen_pct:.1f}% vs {true_pct:.1f}%', \n",
    "                   ha='center', va='center', fontsize=8, weight='bold')\n",
    "    \n",
    "    ax.set_title('Model Performance: Generated vs True V Gene Pairing\\n' +\n",
    "                'Green=Excellent Match, Light Green=Good Match, Orange=Poor Match, Red=Wrong Preference')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Heavy V Gene (sorted by true consistency)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    perf_counts = summary_df['performance'].value_counts()\n",
    "    for perf, count in perf_counts.items():\n",
    "        pct = (count / len(summary_df)) * 100\n",
    "        print(f\"  {perf}: {count} genes ({pct:.1f}%)\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "def create_simple_consistency_comparison(gen_consistency_df, true_consistency_df, top_n=15):\n",
    "    \"\"\"Create a simple bar chart comparing generated vs true consistency percentages\"\"\"\n",
    "    \n",
    "    # Merge the data\n",
    "    comparison = pd.merge(\n",
    "        gen_consistency_df[['heavy_gene', 'consistency_pct', 'most_common_light']],\n",
    "        true_consistency_df[['heavy_gene', 'consistency_pct', 'most_common_light']],\n",
    "        on='heavy_gene', suffixes=('_gen', '_true'), how='outer'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values with 0 for missing data\n",
    "    comparison['consistency_pct_gen'] = comparison['consistency_pct_gen'].fillna(0)\n",
    "    comparison['consistency_pct_true'] = comparison['consistency_pct_true'].fillna(0)\n",
    "    \n",
    "    # Calculate which genes have matching preferences\n",
    "    comparison['preferences_match'] = comparison['most_common_light_gen'] == comparison['most_common_light_true']\n",
    "    \n",
    "    # Get top genes by either generated or true consistency\n",
    "    comparison['max_consistency'] = comparison[['consistency_pct_gen', 'consistency_pct_true']].max(axis=1)\n",
    "    top_genes = comparison.nlargest(top_n, 'max_consistency')\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Plot 1: Bar chart comparison\n",
    "    x = np.arange(len(top_genes))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, top_genes['consistency_pct_gen'], width, \n",
    "                    label='Generated', color='skyblue', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, top_genes['consistency_pct_true'], width, \n",
    "                    label='True', color='lightcoral', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Heavy V Gene')\n",
    "    ax1.set_ylabel('Consistency Percentage (%)')\n",
    "    ax1.set_title('Generated vs True Consistency Comparison')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(top_genes['heavy_gene'], rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "        height1 = bar1.get_height()\n",
    "        height2 = bar2.get_height()\n",
    "        if height1 > 0:\n",
    "            ax1.text(bar1.get_x() + bar1.get_width()/2., height1 + 1,\n",
    "                    f'{height1:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "        if height2 > 0:\n",
    "            ax1.text(bar2.get_x() + bar2.get_width()/2., height2 + 1,\n",
    "                    f'{height2:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Plot 2: Scatter plot with preference matching\n",
    "    matching_genes = top_genes[top_genes['preferences_match']]\n",
    "    mismatched_genes = top_genes[~top_genes['preferences_match']]\n",
    "    \n",
    "    ax2.scatter(matching_genes['consistency_pct_true'], matching_genes['consistency_pct_gen'], \n",
    "               color='green', s=100, alpha=0.7, label='Same Light Chain Preference')\n",
    "    ax2.scatter(mismatched_genes['consistency_pct_true'], mismatched_genes['consistency_pct_gen'], \n",
    "               color='red', s=100, alpha=0.7, label='Different Light Chain Preference')\n",
    "    \n",
    "    # Add diagonal line for perfect match\n",
    "    max_val = max(top_genes['consistency_pct_gen'].max(), top_genes['consistency_pct_true'].max())\n",
    "    ax2.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='Perfect Match')\n",
    "    \n",
    "    ax2.set_xlabel('True Consistency (%)')\n",
    "    ax2.set_ylabel('Generated Consistency (%)')\n",
    "    ax2.set_title('Consistency Correlation with Preference Matching')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add labels for interesting points\n",
    "    for _, row in top_genes.iterrows():\n",
    "        if row['consistency_pct_gen'] > 30 or row['consistency_pct_true'] > 30:\n",
    "            ax2.annotate(row['heavy_gene'], \n",
    "                        (row['consistency_pct_true'], row['consistency_pct_gen']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed comparison\n",
    "    print(\"\\nDetailed Comparison (Top genes):\")\n",
    "    print(\"=\"*80)\n",
    "    for _, row in top_genes.iterrows():\n",
    "        gen_pct = row['consistency_pct_gen']\n",
    "        true_pct = row['consistency_pct_true']\n",
    "        gen_light = row['most_common_light_gen']\n",
    "        true_light = row['most_common_light_true']\n",
    "        match_status = \"✓\" if row['preferences_match'] else \"✗\"\n",
    "        \n",
    "        print(f\"{row['heavy_gene']:<15} | Gen: {gen_pct:5.1f}% → {gen_light:<15} | \"\n",
    "              f\"True: {true_pct:5.1f}% → {true_light:<15} | Match: {match_status}\")\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "def create_top_genes_heatmap(gen_consistency_df, true_consistency_df, top_n=15):\n",
    "    \"\"\"Create a heatmap showing top genes with their consistency percentages\"\"\"\n",
    "    \n",
    "    # Get top genes from both datasets\n",
    "    top_gen = gen_consistency_df.nlargest(top_n//2, 'consistency_pct')\n",
    "    top_true = true_consistency_df.nlargest(top_n//2, 'consistency_pct')\n",
    "    all_top_genes = pd.concat([top_gen['heavy_gene'], top_true['heavy_gene']]).unique()\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    heatmap_data = []\n",
    "    for gene in all_top_genes:\n",
    "        gen_row = gen_consistency_df[gen_consistency_df['heavy_gene'] == gene]\n",
    "        true_row = true_consistency_df[true_consistency_df['heavy_gene'] == gene]\n",
    "        \n",
    "        gen_pct = gen_row['consistency_pct'].iloc[0] if len(gen_row) > 0 else 0\n",
    "        true_pct = true_row['consistency_pct'].iloc[0] if len(true_row) > 0 else 0\n",
    "        \n",
    "        heatmap_data.append({\n",
    "            'Heavy_Gene': gene,\n",
    "            'Generated': gen_pct,\n",
    "            'True': true_pct\n",
    "        })\n",
    "    \n",
    "    heatmap_df = pd.DataFrame(heatmap_data)\n",
    "    heatmap_df = heatmap_df.set_index('Heavy_Gene')\n",
    "    \n",
    "    # Sort by maximum consistency\n",
    "    heatmap_df['max_consistency'] = heatmap_df.max(axis=1)\n",
    "    heatmap_df = heatmap_df.sort_values('max_consistency', ascending=False)\n",
    "    heatmap_df = heatmap_df.drop('max_consistency', axis=1)\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.heatmap(heatmap_df, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Consistency Percentage (%)'})\n",
    "    plt.title('Top Heavy V Genes: Generated vs True Consistency')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Heavy V Gene')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return heatmap_df\n",
    "\n",
    "# Create the visualizations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSISTENCY COMPARISON VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_data = create_simple_consistency_comparison(gen_full_consistency, true_full_consistency)\n",
    "heatmap_data = create_top_genes_heatmap(gen_full_consistency, true_full_consistency)\n",
    "\n",
    "# Create visualizations\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create consistency heatmaps\n",
    "def create_consistency_heatmap(heavy_col, light_col, title, max_genes=20):\n",
    "    \"\"\"Create a heatmap showing heavy→light gene associations\"\"\"\n",
    "    \n",
    "    # Get top heavy genes by frequency\n",
    "    top_heavy = df[heavy_col].value_counts().head(max_genes).index\n",
    "    \n",
    "    # Create crosstab\n",
    "    crosstab = pd.crosstab(df[heavy_col], df[light_col], normalize='index') * 100\n",
    "    crosstab = crosstab.loc[top_heavy]\n",
    "    \n",
    "    # Keep only columns with substantial associations (>10% for any heavy gene)\n",
    "    # This threshold was too restrictive before\n",
    "    col_mask = (crosstab > 10).any(axis=0)\n",
    "    crosstab_filtered = crosstab.loc[:, col_mask]\n",
    "    \n",
    "    # If no columns meet the threshold, keep top associations\n",
    "    if crosstab_filtered.empty or crosstab_filtered.shape[1] < 5:\n",
    "        # Keep columns that represent the top light chain for each heavy chain\n",
    "        top_light_per_heavy = crosstab.idxmax(axis=1)\n",
    "        important_light_genes = set(top_light_per_heavy.values)\n",
    "        \n",
    "        # Also keep any column with >5% association\n",
    "        col_mask_relaxed = (crosstab > 5).any(axis=0)\n",
    "        additional_light_genes = set(crosstab.columns[col_mask_relaxed])\n",
    "        \n",
    "        # Combine both sets\n",
    "        all_important_light = important_light_genes.union(additional_light_genes)\n",
    "        crosstab_filtered = crosstab[list(all_important_light)]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Only show annotations for values >= 30% to avoid cluttering\n",
    "    annot_mask = crosstab_filtered >= 30\n",
    "    \n",
    "    sns.heatmap(crosstab_filtered, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Percentage (%)'}, \n",
    "                annot_kws={'size': 8})\n",
    "    \n",
    "    plt.title(f'{title}\\nHeavy V Gene → Light V Gene Associations\\n(Values ≥30% are annotated)')\n",
    "    plt.xlabel('Light V Gene')\n",
    "    plt.ylabel('Heavy V Gene')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics about what's shown\n",
    "    print(f\"Heatmap for {title}:\")\n",
    "    print(f\"  Heavy genes shown: {len(crosstab_filtered)}\")\n",
    "    print(f\"  Light genes shown: {len(crosstab_filtered.columns)}\")\n",
    "    print(f\"  Maximum association: {crosstab_filtered.max().max():.1f}%\")\n",
    "    print(f\"  Associations ≥50%: {(crosstab_filtered >= 50).sum().sum()}\")\n",
    "    print(f\"  Associations ≥30%: {(crosstab_filtered >= 30).sum().sum()}\")\n",
    "    print()\n",
    "    \n",
    "    return crosstab_filtered\n",
    "\n",
    "# Create heatmaps for different analysis levels\n",
    "print(\"\\nCreating heatmaps...\")\n",
    "\n",
    "print(\"Generated Light Chain Heatmaps:\")\n",
    "# Generated - Full name heatmap\n",
    "gen_full_heatmap = create_consistency_heatmap('heavy_chain_gene_name', 'gen_light_gene_name', \n",
    "                                             'Generated Light Chains - Full Names')\n",
    "\n",
    "# Generated - Simplified heatmap  \n",
    "gen_simplified_heatmap = create_consistency_heatmap('heavy_gene_simplified', 'gen_light_gene_simplified', \n",
    "                                                   'Generated Light Chains - Simplified')\n",
    "\n",
    "# Generated - Family heatmap\n",
    "gen_family_heatmap = create_consistency_heatmap('heavy_gene_family', 'gen_light_gene_family', \n",
    "                                               'Generated Light Chains - Family Level')\n",
    "\n",
    "print(\"\\nTrue Light Chain Heatmaps:\")\n",
    "# True - Full name heatmap\n",
    "true_full_heatmap = create_consistency_heatmap('heavy_chain_gene_name', 'true_light_gene_name', \n",
    "                                              'True Light Chains - Full Names')\n",
    "\n",
    "# True - Simplified heatmap  \n",
    "true_simplified_heatmap = create_consistency_heatmap('heavy_gene_simplified', 'true_light_gene_simplified', \n",
    "                                                    'True Light Chains - Simplified')\n",
    "\n",
    "# True - Family heatmap\n",
    "true_family_heatmap = create_consistency_heatmap('heavy_gene_family', 'true_light_gene_family', \n",
    "                                                'True Light Chains - Family Level')\n",
    "\n",
    "# Consistency distribution plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "# Plot 1: Generated consistency percentage distribution\n",
    "axes[0, 0].hist(gen_full_consistency['consistency_pct'], bins=20, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0, 0].set_title('Generated: Consistency Percentages\\n(Full Names)')\n",
    "axes[0, 0].set_xlabel('Consistency Percentage')\n",
    "axes[0, 0].set_ylabel('Number of Heavy V Genes')\n",
    "axes[0, 0].axvline(gen_full_consistency['consistency_pct'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: True consistency percentage distribution\n",
    "axes[0, 1].hist(true_full_consistency['consistency_pct'], bins=20, alpha=0.7, edgecolor='black', color='lightcoral')\n",
    "axes[0, 1].set_title('True: Consistency Percentages\\n(Full Names)')\n",
    "axes[0, 1].set_xlabel('Consistency Percentage')\n",
    "axes[0, 1].set_ylabel('Number of Heavy V Genes')\n",
    "axes[0, 1].axvline(true_full_consistency['consistency_pct'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Generated unique light genes per heavy\n",
    "axes[1, 0].hist(gen_full_consistency['unique_light_genes'], bins=20, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[1, 0].set_title('Generated: Light Gene Diversity\\n(Full Names)')\n",
    "axes[1, 0].set_xlabel('Number of Unique Light Genes')\n",
    "axes[1, 0].set_ylabel('Number of Heavy V Genes')\n",
    "\n",
    "# Plot 4: True unique light genes per heavy\n",
    "axes[1, 1].hist(true_full_consistency['unique_light_genes'], bins=20, alpha=0.7, edgecolor='black', color='lightcoral')\n",
    "axes[1, 1].set_title('True: Light Gene Diversity\\n(Full Names)')\n",
    "axes[1, 1].set_xlabel('Number of Unique Light Genes')\n",
    "axes[1, 1].set_ylabel('Number of Heavy V Genes')\n",
    "\n",
    "# Plot 5: Generated vs True consistency comparison\n",
    "valid_comparison = comparison_df.dropna(subset=['consistency_pct_gen', 'consistency_pct_true'])\n",
    "axes[2, 0].scatter(valid_comparison['consistency_pct_true'], valid_comparison['consistency_pct_gen'], alpha=0.6)\n",
    "axes[2, 0].plot([0, 100], [0, 100], 'r--', label='Perfect Match')\n",
    "axes[2, 0].set_xlabel('True Consistency (%)')\n",
    "axes[2, 0].set_ylabel('Generated Consistency (%)')\n",
    "axes[2, 0].set_title('Generated vs True Consistency')\n",
    "axes[2, 0].legend()\n",
    "\n",
    "# Plot 6: Consistency categories comparison\n",
    "gen_category_counts = gen_full_consistency['consistency_category'].value_counts()\n",
    "true_category_counts = true_full_consistency['consistency_category'].value_counts()\n",
    "\n",
    "categories = ['Perfect (≥95%)', 'Very High (90-94%)', 'High (75-89%)', 'Moderate (50-74%)', 'Low (<50%)']\n",
    "gen_counts = [gen_category_counts.get(cat, 0) for cat in categories]\n",
    "true_counts = [true_category_counts.get(cat, 0) for cat in categories]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[2, 1].bar(x - width/2, gen_counts, width, label='Generated', color='skyblue')\n",
    "axes[2, 1].bar(x + width/2, true_counts, width, label='True', color='lightcoral')\n",
    "axes[2, 1].set_xticks(x)\n",
    "axes[2, 1].set_xticklabels(categories, rotation=45, ha='right')\n",
    "axes[2, 1].set_title('Consistency Categories Comparison\\n(Full Names)')\n",
    "axes[2, 1].set_ylabel('Number of Heavy V Genes')\n",
    "axes[2, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04ea739d",
   "metadata": {},
   "source": [
    "# Create visualizations\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create consistency heatmaps\n",
    "def create_consistency_heatmap(heavy_col, light_col, title, max_genes=20):\n",
    "    \"\"\"Create a heatmap showing heavy→light gene associations\"\"\"\n",
    "    \n",
    "    # Get top heavy genes by frequency\n",
    "    top_heavy = df[heavy_col].value_counts().head(max_genes).index\n",
    "    \n",
    "    # Create crosstab\n",
    "    crosstab = pd.crosstab(df[heavy_col], df[light_col], normalize='index') * 100\n",
    "    crosstab = crosstab.loc[top_heavy]\n",
    "    \n",
    "    # Keep only columns with substantial associations (>10% for any heavy gene)\n",
    "    # This threshold was too restrictive before\n",
    "    col_mask = (crosstab > 10).any(axis=0)\n",
    "    crosstab_filtered = crosstab.loc[:, col_mask]\n",
    "    \n",
    "    # If no columns meet the threshold, keep top associations\n",
    "    if crosstab_filtered.empty or crosstab_filtered.shape[1] < 5:\n",
    "        # Keep columns that represent the top light chain for each heavy chain\n",
    "        top_light_per_heavy = crosstab.idxmax(axis=1)\n",
    "        important_light_genes = set(top_light_per_heavy.values)\n",
    "        \n",
    "        # Also keep any column with >5% association\n",
    "        col_mask_relaxed = (crosstab > 5).any(axis=0)\n",
    "        additional_light_genes = set(crosstab.columns[col_mask_relaxed])\n",
    "        \n",
    "        # Combine both sets\n",
    "        all_important_light = important_light_genes.union(additional_light_genes)\n",
    "        crosstab_filtered = crosstab[list(all_important_light)]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Only show annotations for values >= 30% to avoid cluttering\n",
    "    annot_mask = crosstab_filtered >= 30\n",
    "    \n",
    "    sns.heatmap(crosstab_filtered, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Percentage (%)'}, \n",
    "                annot_kws={'size': 8})\n",
    "    \n",
    "    plt.title(f'{title}\\nHeavy V Gene → Light V Gene Associations\\n(Values ≥30% are annotated)')\n",
    "    plt.xlabel('Light V Gene')\n",
    "    plt.ylabel('Heavy V Gene')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics about what's shown\n",
    "    print(f\"Heatmap for {title}:\")\n",
    "    print(f\"  Heavy genes shown: {len(crosstab_filtered)}\")\n",
    "    print(f\"  Light genes shown: {len(crosstab_filtered.columns)}\")\n",
    "    print(f\"  Maximum association: {crosstab_filtered.max().max():.1f}%\")\n",
    "    print(f\"  Associations ≥50%: {(crosstab_filtered >= 50).sum().sum()}\")\n",
    "    print(f\"  Associations ≥30%: {(crosstab_filtered >= 30).sum().sum()}\")\n",
    "    print()\n",
    "    \n",
    "    return crosstab_filtered\n",
    "\n",
    "# Create heatmaps for different analysis levels\n",
    "print(\"\\nCreating heatmaps...\")\n",
    "\n",
    "print(\"Generated Light Chain Heatmaps:\")\n",
    "# Generated - Full name heatmap\n",
    "gen_full_heatmap = create_consistency_heatmap('heavy_chain_gene_name', 'gen_light_gene_name', \n",
    "                                             'Generated Light Chains - Full Names')\n",
    "\n",
    "# Generated - Simplified heatmap  \n",
    "gen_simplified_heatmap = create_consistency_heatmap('heavy_gene_simplified', 'gen_light_gene_simplified', \n",
    "                                                   'Generated Light Chains - Simplified')\n",
    "\n",
    "# Generated - Family heatmap\n",
    "gen_family_heatmap = create_consistency_heatmap('heavy_gene_family', 'gen_light_gene_family', \n",
    "                                               'Generated Light Chains - Family Level')\n",
    "\n",
    "print(\"\\nTrue Light Chain Heatmaps:\")\n",
    "# True - Full name heatmap\n",
    "true_full_heatmap = create_consistency_heatmap('heavy_chain_gene_name', 'true_light_gene_name', \n",
    "                                              'True Light Chains - Full Names')\n",
    "\n",
    "# True - Simplified heatmap  \n",
    "true_simplified_heatmap = create_consistency_heatmap('heavy_gene_simplified', 'true_light_gene_simplified', \n",
    "                                                    'True Light Chains - Simplified')\n",
    "\n",
    "# True - Family heatmap\n",
    "true_family_heatmap = create_consistency_heatmap('heavy_gene_family', 'true_light_gene_family', \n",
    "                                                'True Light Chains - Family Level')\n",
    "\n",
    "# Consistency distribution plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "# Plot 1: Generated consistency percentage distribution\n",
    "axes[0, 0].hist(gen_full_consistency['consistency_pct'], bins=20, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0, 0].set_title('Generated: Consistency Percentages\\n(Full Names)')\n",
    "axes[0, 0].set_xlabel('Consistency Percentage')\n",
    "axes[0, 0].set_ylabel('Number of Heavy V Genes')\n",
    "axes[0, 0].axvline(gen_full_consistency['consistency_pct'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: True consistency percentage distribution\n",
    "axes[0, 1].hist(true_full_consistency['consistency_pct'], bins=20, alpha=0.7, edgecolor='black', color='lightcoral')\n",
    "axes[0, 1].set_title('True: Consistency Percentages\\n(Full Names)')\n",
    "axes[0, 1].set_xlabel('Consistency Percentage')\n",
    "axes[0, 1].set_ylabel('Number of Heavy V Genes')\n",
    "axes[0, 1].axvline(true_full_consistency['consistency_pct'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Generated unique light genes per heavy\n",
    "axes[1, 0].hist(gen_full_consistency['unique_light_genes'], bins=20, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[1, 0].set_title('Generated: Light Gene Diversity\\n(Full Names)')\n",
    "axes[1, 0].set_xlabel('Number of Unique Light Genes')\n",
    "axes[1, 0].set_ylabel('Number of Heavy V Genes')\n",
    "\n",
    "# Plot 4: True unique light genes per heavy\n",
    "axes[1, 1].hist(true_full_consistency['unique_light_genes'], bins=20, alpha=0.7, edgecolor='black', color='lightcoral')\n",
    "axes[1, 1].set_title('True: Light Gene Diversity\\n(Full Names)')\n",
    "axes[1, 1].set_xlabel('Number of Unique Light Genes')\n",
    "axes[1, 1].set_ylabel('Number of Heavy V Genes')\n",
    "\n",
    "# Plot 5: Generated vs True consistency comparison\n",
    "valid_comparison = comparison_df.dropna(subset=['consistency_pct_gen', 'consistency_pct_true'])\n",
    "axes[2, 0].scatter(valid_comparison['consistency_pct_true'], valid_comparison['consistency_pct_gen'], alpha=0.6)\n",
    "axes[2, 0].plot([0, 100], [0, 100], 'r--', label='Perfect Match')\n",
    "axes[2, 0].set_xlabel('True Consistency (%)')\n",
    "axes[2, 0].set_ylabel('Generated Consistency (%)')\n",
    "axes[2, 0].set_title('Generated vs True Consistency')\n",
    "axes[2, 0].legend()\n",
    "\n",
    "# Plot 6: Consistency categories comparison\n",
    "gen_category_counts = gen_full_consistency['consistency_category'].value_counts()\n",
    "true_category_counts = true_full_consistency['consistency_category'].value_counts()\n",
    "\n",
    "categories = ['Perfect (≥95%)', 'Very High (90-94%)', 'High (75-89%)', 'Moderate (50-74%)', 'Low (<50%)']\n",
    "gen_counts = [gen_category_counts.get(cat, 0) for cat in categories]\n",
    "true_counts = [true_category_counts.get(cat, 0) for cat in categories]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[2, 1].bar(x - width/2, gen_counts, width, label='Generated', color='skyblue')\n",
    "axes[2, 1].bar(x + width/2, true_counts, width, label='True', color='lightcoral')\n",
    "axes[2, 1].set_xticks(x)\n",
    "axes[2, 1].set_xticklabels(categories, rotation=45, ha='right')\n",
    "axes[2, 1].set_title('Consistency Categories Comparison\\n(Full Names)')\n",
    "axes[2, 1].set_ylabel('Number of Heavy V Genes')\n",
    "axes[2, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f193db1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"1. V Gene Pairing Consistency:\")\n",
    "print(f\"   - Average consistency (full names): {gen_full_consistency['consistency_pct'].mean():.1f}%\")\n",
    "print(f\"   - Average consistency (simplified): {gen_simplified_consistency['consistency_pct'].mean():.1f}%\")\n",
    "print(f\"   - Average consistency (family): {gen_family_consistency['consistency_pct'].mean():.1f}%\")\n",
    "\n",
    "high_consistency = (gen_full_consistency['consistency_pct'] >= 75).sum()\n",
    "total_genes = len(gen_full_consistency)\n",
    "print(f\"2. High Consistency Genes: {high_consistency}/{total_genes} ({high_consistency/total_genes*100:.1f}%)\")\n",
    "\n",
    "print(f\"3. Generated vs True Comparison:\")\n",
    "print(f\"   - Matching preferences: {matches}/{total} ({matches/total*100:.1f}%)\")\n",
    "print(f\"   - Generated consistency: {gen_avg:.1f}%\")\n",
    "print(f\"   - True consistency: {true_avg:.1f}%\")\n",
    "\n",
    "print(f\"\\n4. Most Consistent Heavy V Genes (Generated):\")\n",
    "top_5 = gen_full_consistency.head(5)\n",
    "for _, row in top_5.iterrows():\n",
    "    print(f\"   {row['heavy_gene']}: {row['consistency_pct']:.1f}% → {row['most_common_light']}\")\n",
    "\n",
    "print(f\"\\n5. Most Diverse Heavy V Genes (Generated):\")\n",
    "diverse_5 = gen_full_consistency.nlargest(5, 'unique_light_genes')\n",
    "for _, row in diverse_5.iterrows():\n",
    "    print(f\"   {row['heavy_gene']}: {row['unique_light_genes']} different light genes\")\n",
    "\n",
    "print(f\"\\nAnalysis complete! The model shows {'high' if gen_avg >= 75 else 'moderate' if gen_avg >= 50 else 'low'} overall consistency in V gene pairing.\")\n",
    "print(f\"Generated sequences {'match' if matches/total > 0.5 else 'differ from'} true pairing preferences in most cases.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5df0e9cc",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def simplify_gene_name(gene_name):\n",
    "    \"\"\"Remove allele designation (part after *) from gene name\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    return str(gene_name).split('*')[0]\n",
    "\n",
    "def extract_gene_family(gene_name):\n",
    "    \"\"\"Extract gene family (e.g., IGHV3 from IGHV3-23*01)\"\"\"\n",
    "    if pd.isna(gene_name):\n",
    "        return gene_name\n",
    "    simplified = str(gene_name).split('*')[0]\n",
    "    # Extract family part (everything before the dash)\n",
    "    if '-' in simplified:\n",
    "        return simplified.split('-')[0]\n",
    "    return simplified\n",
    "\n",
    "def create_test_data():\n",
    "    \"\"\"Create test data to verify the analysis logic\"\"\"\n",
    "    \n",
    "    print(\"Creating test data...\")\n",
    "    \n",
    "    # Create test data with known patterns\n",
    "    test_data = []\n",
    "    \n",
    "    # Heavy chain 1: IGHV3-23*01 - should consistently generate IGKV1-39*01 (8/10 times)\n",
    "    # True light chain: IGKV1-5*03\n",
    "    heavy1_data = [\n",
    "        {\"heavy_chain_number\": 1, \"gen_light_chain_number\": i+1, \n",
    "         \"heavy_chain_gene_name\": \"IGHV3-23*01\", \"true_light_gene_name\": \"IGKV1-5*03\",\n",
    "         \"gen_light_gene_name\": \"IGKV1-39*01\" if i < 8 else \"IGKV2-28*01\"}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    \n",
    "    # Heavy chain 2: IGHV4-34*01 - should generate IGLV2-14*01 perfectly (10/10 times)\n",
    "    # True light chain: IGLV2-14*01 (perfect match)\n",
    "    heavy2_data = [\n",
    "        {\"heavy_chain_number\": 2, \"gen_light_chain_number\": i+1,\n",
    "         \"heavy_chain_gene_name\": \"IGHV4-34*01\", \"true_light_gene_name\": \"IGLV2-14*01\",\n",
    "         \"gen_light_gene_name\": \"IGLV2-14*01\"}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    \n",
    "    # Heavy chain 3: IGHV1-2*02 - should be diverse (no clear preference)\n",
    "    # True light chain: IGKV3-20*01\n",
    "    heavy3_genes = [\"IGKV1-39*01\", \"IGKV2-28*01\", \"IGLV1-44*01\", \"IGLV2-14*01\", \"IGKV3-11*01\"] * 2\n",
    "    heavy3_data = [\n",
    "        {\"heavy_chain_number\": 3, \"gen_light_chain_number\": i+1,\n",
    "         \"heavy_chain_gene_name\": \"IGHV1-2*02\", \"true_light_gene_name\": \"IGKV3-20*01\",\n",
    "         \"gen_light_gene_name\": heavy3_genes[i]}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    \n",
    "    # Heavy chain 4: IGHV3-23*02 (different allele) - should generate IGKV1-39*01 (7/10 times)\n",
    "    # True light chain: IGKV1-39*01 (matches most common generated)\n",
    "    heavy4_data = [\n",
    "        {\"heavy_chain_number\": 4, \"gen_light_chain_number\": i+1,\n",
    "         \"heavy_chain_gene_name\": \"IGHV3-23*02\", \"true_light_gene_name\": \"IGKV1-39*01\",\n",
    "         \"gen_light_gene_name\": \"IGKV1-39*01\" if i < 7 else (\"IGKV2-28*01\" if i < 9 else \"IGLV1-44*01\")}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    \n",
    "    # Heavy chain 5: IGHV5-51*01 - moderate consistency\n",
    "    # True light chain: IGLV3-19*01\n",
    "    heavy5_data = [\n",
    "        {\"heavy_chain_number\": 5, \"gen_light_chain_number\": i+1,\n",
    "         \"heavy_chain_gene_name\": \"IGHV5-51*01\", \"true_light_gene_name\": \"IGLV3-19*01\",\n",
    "         \"gen_light_gene_name\": \"IGLV3-19*01\" if i < 6 else \"IGKV2-28*01\"}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    \n",
    "    # Combine all test data\n",
    "    test_data = heavy1_data + heavy2_data + heavy3_data + heavy4_data + heavy5_data\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(test_data)\n",
    "    \n",
    "    print(\"Test data created:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "    print(f\"Expected patterns:\")\n",
    "    print(\"  Heavy 1 (IGHV3-23*01): 80% IGKV1-39*01, True: IGKV1-5*03\")\n",
    "    print(\"  Heavy 2 (IGHV4-34*01): 100% IGLV2-14*01, True: IGLV2-14*01 (perfect match)\")\n",
    "    print(\"  Heavy 3 (IGHV1-2*02): Diverse (20% each), True: IGKV3-20*01\")\n",
    "    print(\"  Heavy 4 (IGHV3-23*02): 70% IGKV1-39*01, True: IGKV1-39*01 (matches most common)\")\n",
    "    print(\"  Heavy 5 (IGHV5-51*01): 60% IGLV3-19*01, True: IGLV3-19*01 (matches most common)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_vgene_consistency_numbers_only(df):\n",
    "    \"\"\"\n",
    "    Analyze V gene consistency - numbers only, no plots\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"V GENE CONSISTENCY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ============================\n",
    "    # HANDLE DUPLICATES PROPERLY\n",
    "    # ============================\n",
    "    \n",
    "    # Group by heavy chain to get unique heavy chains and their true light chains\n",
    "    heavy_chains = df.groupby('heavy_chain_number').first()\n",
    "    \n",
    "    # Count unique heavy chains and total generated sequences\n",
    "    unique_heavy_chains = len(heavy_chains)\n",
    "    total_generated_sequences = len(df)\n",
    "    \n",
    "    # Get the true light chains (one per heavy chain)\n",
    "    true_light_chains = heavy_chains['true_light_gene_name'].dropna()\n",
    "    \n",
    "    print(f\"Total heavy chains: {unique_heavy_chains}\")\n",
    "    print(f\"Total generated sequences: {total_generated_sequences}\")\n",
    "    print(f\"Total true light chains: {len(true_light_chains)} (should equal heavy chains)\")\n",
    "    \n",
    "    if len(true_light_chains) != unique_heavy_chains:\n",
    "        print(\"⚠️  Warning: Number of true light chains doesn't match number of heavy chains\")\n",
    "        print(f\"   Expected: {unique_heavy_chains}, Got: {len(true_light_chains)}\")\n",
    "    else:\n",
    "        print(\"✅ Correct: One true light chain per heavy chain\")\n",
    "    \n",
    "    # ============================\n",
    "    # COLLECT V GENE ASSOCIATIONS\n",
    "    # ============================\n",
    "    \n",
    "    # For each heavy chain, collect all its generated light chains\n",
    "    heavy_gen_associations = defaultdict(list)\n",
    "    heavy_true_mapping = {}\n",
    "    \n",
    "    # Group by heavy chain number to handle each heavy chain separately\n",
    "    for heavy_num, group in df.groupby('heavy_chain_number'):\n",
    "        heavy_gene = group['heavy_chain_gene_name'].iloc[0]  # Same for all rows in group\n",
    "        true_light_gene = group['true_light_gene_name'].iloc[0]  # Same for all rows in group\n",
    "        \n",
    "        if pd.isna(heavy_gene) or pd.isna(true_light_gene):\n",
    "            continue\n",
    "            \n",
    "        # Collect all generated light genes for this heavy chain\n",
    "        gen_light_genes = group['gen_light_gene_name'].dropna().tolist()\n",
    "        \n",
    "        heavy_gen_associations[heavy_gene].extend(gen_light_genes)\n",
    "        heavy_true_mapping[heavy_gene] = true_light_gene\n",
    "    \n",
    "    print(f\"Unique heavy V genes: {len(heavy_gen_associations)}\")\n",
    "    \n",
    "    # Verify the data structure\n",
    "    total_gen_collected = sum(len(genes) for genes in heavy_gen_associations.values())\n",
    "    print(f\"Total generated sequences collected: {total_gen_collected}\")\n",
    "    \n",
    "    if total_gen_collected != total_generated_sequences:\n",
    "        print(f\"⚠️  Warning: Collected sequences ({total_gen_collected}) don't match total ({total_generated_sequences})\")\n",
    "    \n",
    "    # ============================\n",
    "    # ANALYZE CONSISTENCY AT DIFFERENT LEVELS\n",
    "    # ============================\n",
    "    \n",
    "    def analyze_level(associations, true_mapping, level_name, transform_func):\n",
    "        \"\"\"Analyze consistency at a specific level\"\"\"\n",
    "        \n",
    "        print(f\"\\n{level_name} LEVEL ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Transform gene names and group by transformed heavy gene\n",
    "        transformed_associations = defaultdict(list)\n",
    "        transformed_true_mapping = {}\n",
    "        \n",
    "        for heavy_gene, light_genes in associations.items():\n",
    "            transformed_heavy = transform_func(heavy_gene)\n",
    "            transformed_true = transform_func(true_mapping[heavy_gene])\n",
    "            \n",
    "            # If multiple original heavy genes map to the same transformed heavy gene,\n",
    "            # combine their generated light genes\n",
    "            transformed_associations[transformed_heavy].extend([transform_func(lg) for lg in light_genes])\n",
    "            \n",
    "            # For true mapping, if there's a conflict, keep the first one\n",
    "            # (in practice, this shouldn't happen much)\n",
    "            if transformed_heavy not in transformed_true_mapping:\n",
    "                transformed_true_mapping[transformed_heavy] = transformed_true\n",
    "        \n",
    "        # Calculate consistency for each heavy gene\n",
    "        consistency_results = []\n",
    "        \n",
    "        for heavy_gene, light_genes in transformed_associations.items():\n",
    "            if len(light_genes) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Count light gene frequencies\n",
    "            light_counts = Counter(light_genes)\n",
    "            total_generated = len(light_genes)\n",
    "            \n",
    "            # Most common generated light gene\n",
    "            most_common_light = light_counts.most_common(1)[0]\n",
    "            most_common_gene = most_common_light[0]\n",
    "            most_common_count = most_common_light[1]\n",
    "            most_common_pct = (most_common_count / total_generated) * 100\n",
    "            \n",
    "            # True light gene for this heavy gene\n",
    "            true_light_gene = transformed_true_mapping[heavy_gene]\n",
    "            \n",
    "            # Check if true matches most common generated\n",
    "            true_matches_most_common = (true_light_gene == most_common_gene)\n",
    "            \n",
    "            # Count how many times true light gene was generated\n",
    "            true_generated_count = light_counts.get(true_light_gene, 0)\n",
    "            true_generated_pct = (true_generated_count / total_generated) * 100\n",
    "            \n",
    "            # Consistency classification\n",
    "            if most_common_pct >= 95:\n",
    "                consistency_level = \"Perfect\"\n",
    "            elif most_common_pct >= 90:\n",
    "                consistency_level = \"Very High\"\n",
    "            elif most_common_pct >= 75:\n",
    "                consistency_level = \"High\"\n",
    "            elif most_common_pct >= 50:\n",
    "                consistency_level = \"Moderate\"\n",
    "            else:\n",
    "                consistency_level = \"Low\"\n",
    "            \n",
    "            consistency_results.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'total_generated': total_generated,\n",
    "                'unique_light_genes': len(light_counts),\n",
    "                'most_common_light': most_common_gene,\n",
    "                'most_common_count': most_common_count,\n",
    "                'most_common_pct': most_common_pct,\n",
    "                'true_light_gene': true_light_gene,\n",
    "                'true_generated_count': true_generated_count,\n",
    "                'true_generated_pct': true_generated_pct,\n",
    "                'true_matches_most_common': true_matches_most_common,\n",
    "                'consistency_level': consistency_level\n",
    "            })\n",
    "        \n",
    "        # Sort by consistency percentage\n",
    "        consistency_results.sort(key=lambda x: x['most_common_pct'], reverse=True)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"{'Heavy Gene':<20} {'N':<5} {'Most Common Generated':<25} {'%':<6} {'True Light':<25} {'True Gen %':<10} {'Match':<6} {'Level':<10}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for result in consistency_results:\n",
    "            match_symbol = \"✓\" if result['true_matches_most_common'] else \"✗\"\n",
    "            # Calculate number of heavy chains (sample size)\n",
    "            n_heavy_chains = result['total_generated'] // 10  # Each heavy chain contributes 10 sequences\n",
    "            print(f\"{result['heavy_gene']:<20} {n_heavy_chains:<5} {result['most_common_light']:<25} \"\n",
    "                  f\"{result['most_common_pct']:<6.1f} {result['true_light_gene']:<25} \"\n",
    "                  f\"{result['true_generated_pct']:<10.1f} {match_symbol:<6} {result['consistency_level']:<10}\")\n",
    "        \n",
    "        # Summary statistics with sample size info\n",
    "        if consistency_results:\n",
    "            total_heavy_genes = len(consistency_results)\n",
    "            perfect = len([r for r in consistency_results if r['consistency_level'] == 'Perfect'])\n",
    "            very_high = len([r for r in consistency_results if r['consistency_level'] == 'Very High'])\n",
    "            high = len([r for r in consistency_results if r['consistency_level'] == 'High'])\n",
    "            moderate = len([r for r in consistency_results if r['consistency_level'] == 'Moderate'])\n",
    "            low = len([r for r in consistency_results if r['consistency_level'] == 'Low'])\n",
    "            \n",
    "            true_matches = len([r for r in consistency_results if r['true_matches_most_common']])\n",
    "            \n",
    "            # Sample size statistics\n",
    "            sample_sizes = [r['total_generated'] // 10 for r in consistency_results]\n",
    "            min_sample = min(sample_sizes)\n",
    "            max_sample = max(sample_sizes)\n",
    "            avg_sample = sum(sample_sizes) / len(sample_sizes)\n",
    "            \n",
    "            print(f\"\\nSUMMARY ({total_heavy_genes} heavy V genes):\")\n",
    "            print(f\"  Sample sizes: Min={min_sample}, Max={max_sample}, Avg={avg_sample:.1f} heavy chains per gene\")\n",
    "            print(f\"  Perfect (≥95%): {perfect} ({perfect/total_heavy_genes*100:.1f}%)\")\n",
    "            print(f\"  Very High (90-94%): {very_high} ({very_high/total_heavy_genes*100:.1f}%)\")\n",
    "            print(f\"  High (75-89%): {high} ({high/total_heavy_genes*100:.1f}%)\")\n",
    "            print(f\"  Moderate (50-74%): {moderate} ({moderate/total_heavy_genes*100:.1f}%)\")\n",
    "            print(f\"  Low (<50%): {low} ({low/total_heavy_genes*100:.1f}%)\")\n",
    "            print(f\"  True matches most common: {true_matches}/{total_heavy_genes} ({true_matches/total_heavy_genes*100:.1f}%)\")\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = sum(r['most_common_pct'] for r in consistency_results) / len(consistency_results)\n",
    "            avg_true_generation = sum(r['true_generated_pct'] for r in consistency_results) / len(consistency_results)\n",
    "            \n",
    "            print(f\"  Average consistency: {avg_consistency:.1f}%\")\n",
    "            print(f\"  Average true light generation: {avg_true_generation:.1f}%\")\n",
    "            \n",
    "            # Show genes with largest sample sizes\n",
    "            top_samples = sorted(consistency_results, key=lambda x: x['total_generated'], reverse=True)[:10]\n",
    "            print(f\"\\nTop 10 genes by sample size:\")\n",
    "            for result in top_samples:\n",
    "                n_chains = result['total_generated'] // 10\n",
    "                print(f\"  {result['heavy_gene']:<20} {n_chains} heavy chains ({result['consistency_level']}, {result['most_common_pct']:.1f}%)\")\n",
    "        \n",
    "        return consistency_results\n",
    "    \n",
    "    # Analyze at all levels\n",
    "    full_results = analyze_level(heavy_gen_associations, heavy_true_mapping, \"FULL NAMES\", lambda x: x)\n",
    "    simple_results = analyze_level(heavy_gen_associations, heavy_true_mapping, \"SIMPLIFIED\", simplify_gene_name)\n",
    "    family_results = analyze_level(heavy_gen_associations, heavy_true_mapping, \"GENE FAMILIES\", extract_gene_family)\n",
    "    \n",
    "    return {\n",
    "        'full_results': full_results,\n",
    "        'simple_results': simple_results,\n",
    "        'family_results': family_results\n",
    "    }\n",
    "\n",
    "def analyze_csv_file(csv_file):\n",
    "    \"\"\"Analyze real CSV file\"\"\"\n",
    "    \n",
    "    print(\"Reading CSV file...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Dataset loaded:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = ['heavy_chain_number', 'heavy_chain_gene_name', 'gen_light_gene_name', 'true_light_gene_name']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"❌ Missing required columns: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"✅ All required columns found\")\n",
    "    \n",
    "    return analyze_vgene_consistency_numbers_only(df)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bc4576b",
   "metadata": {},
   "source": [
    "\n",
    "# print(\"TESTING WITH SAMPLE DATA\")\n",
    "# print(\"=\"*50)\n",
    "    \n",
    "# test_df = create_test_data()\n",
    "# test_results = analyze_vgene_consistency_numbers_only(test_df)\n",
    "    \n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"TEST COMPLETED - Check if results match expected patterns above\")\n",
    "# print(\"=\"*80)\n",
    "    \n",
    "    \n",
    "csv_file = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv'  \n",
    "    \n",
    "\n",
    "real_results = analyze_csv_file(csv_file)\n",
    "if real_results:\n",
    "    print(\"\\nReal data analysis completed successfully!\")\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a05f7b7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"Load CSV and prepare data for analysis\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Unique heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_groups(df):\n",
    "    \"\"\"Create the 4 groups based on predicted labels\"\"\"\n",
    "    \n",
    "    # Group 1: Both memory B cell origin (both labels = 1)\n",
    "    group1 = df[(df['predicted_gen_light_seq_label'] == 1) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 1)]\n",
    "    \n",
    "    # Group 2: Both naive B cell origin (both labels = 0)\n",
    "    group2 = df[(df['predicted_gen_light_seq_label'] == 0) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 3: Heavy memory, Generated light naive (heavy=1, gen_light=0)\n",
    "    group3 = df[(df['predicted_input_heavy_seq_label'] == 1) & \n",
    "                (df['predicted_gen_light_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 4: Heavy naive, Generated light memory (heavy=0, gen_light=1)\n",
    "    group4 = df[(df['predicted_input_heavy_seq_label'] == 0) & \n",
    "                (df['predicted_gen_light_seq_label'] == 1)]\n",
    "    \n",
    "    groups = {\n",
    "        'Group 1 (H:Memory, L:Memory)': group1,\n",
    "        'Group 2 (H:Naive, L:Naive)': group2,\n",
    "        'Group 3 (H:Memory, L:Naive)': group3,\n",
    "        'Group 4 (H:Naive, L:Memory)': group4\n",
    "    }\n",
    "    \n",
    "    print(\"\\nGroup sizes:\")\n",
    "    for name, group in groups.items():\n",
    "        print(f\"{name}: {len(group)} rows\")\n",
    "        if len(group) > 0:\n",
    "            print(f\"  Unique heavy chains: {group['heavy_chain_number'].nunique()}\")\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def extract_v_gene_info(gene_name):\n",
    "    \"\"\"Extract different levels of V gene information\"\"\"\n",
    "    if pd.isna(gene_name) or gene_name == '':\n",
    "        return {'full': 'Unknown', 'simplified': 'Unknown', 'family': 'Unknown'}\n",
    "    \n",
    "    # Full gene name\n",
    "    full = gene_name\n",
    "    \n",
    "    # Simplified (remove *XX part)\n",
    "    simplified = re.sub(r'\\*\\d+', '', gene_name)\n",
    "    \n",
    "    # Family (extract the main family part)\n",
    "    family_match = re.match(r'(IG[HKL]V\\d+)', gene_name)\n",
    "    family = family_match.group(1) if family_match else gene_name.split('-')[0]\n",
    "    \n",
    "    return {'full': full, 'simplified': simplified, 'family': family}\n",
    "\n",
    "def create_heavy_light_pairing_matrix(group_df, gene_level='full'):\n",
    "    \"\"\"Create heavy-light V gene pairing matrix\"\"\"\n",
    "    \n",
    "    if len(group_df) == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Extract V gene information for heavy and generated light chains\n",
    "    pairing_data = []\n",
    "    \n",
    "    for _, row in group_df.iterrows():\n",
    "        heavy_gene_info = extract_v_gene_info(row['heavy_chain_gene_name'])\n",
    "        gen_light_gene_info = extract_v_gene_info(row['gen_light_gene_name'])\n",
    "        \n",
    "        heavy_gene = heavy_gene_info[gene_level]\n",
    "        light_gene = gen_light_gene_info[gene_level]\n",
    "        \n",
    "        pairing_data.append({\n",
    "            'heavy_chain_number': row['heavy_chain_number'],\n",
    "            'heavy_gene': heavy_gene,\n",
    "            'light_gene': light_gene\n",
    "        })\n",
    "    \n",
    "    pairing_df = pd.DataFrame(pairing_data)\n",
    "    \n",
    "    # Create co-occurrence matrix (counts)\n",
    "    cooccurrence_matrix = pd.crosstab(\n",
    "        pairing_df['heavy_gene'], \n",
    "        pairing_df['light_gene'], \n",
    "        margins=False\n",
    "    )\n",
    "    \n",
    "    # Calculate percentages (what percentage of each heavy gene generates each light gene)\n",
    "    # This shows the preference of heavy genes for light genes\n",
    "    percentage_matrix = cooccurrence_matrix.div(cooccurrence_matrix.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    percentage_matrix = percentage_matrix.fillna(0)\n",
    "    \n",
    "    # Add sample sizes information\n",
    "    heavy_gene_counts = pairing_df['heavy_gene'].value_counts()\n",
    "    \n",
    "    print(f\"\\nSample sizes for each heavy gene (total generated sequences):\")\n",
    "    for gene, count in heavy_gene_counts.head(10).items():\n",
    "        unique_heavy_chains = pairing_df[pairing_df['heavy_gene'] == gene]['heavy_chain_number'].nunique()\n",
    "        print(f\"  {gene}: {count} total sequences from {unique_heavy_chains} heavy chains\")\n",
    "    \n",
    "    return cooccurrence_matrix, percentage_matrix\n",
    "\n",
    "def get_top_genes(matrix, top_n=15, axis='both'):\n",
    "    \"\"\"Get top N most frequent genes\"\"\"\n",
    "    if axis == 'both':\n",
    "        # Get top genes from both heavy and light\n",
    "        heavy_totals = matrix.sum(axis=1)\n",
    "        light_totals = matrix.sum(axis=0)\n",
    "        \n",
    "        top_heavy = heavy_totals.nlargest(top_n).index.tolist()\n",
    "        top_light = light_totals.nlargest(top_n).index.tolist()\n",
    "        \n",
    "        return top_heavy, top_light\n",
    "    elif axis == 'heavy':\n",
    "        heavy_totals = matrix.sum(axis=1)\n",
    "        return heavy_totals.nlargest(top_n).index.tolist()\n",
    "    elif axis == 'light':\n",
    "        light_totals = matrix.sum(axis=0)\n",
    "        return light_totals.nlargest(top_n).index.tolist()\n",
    "\n",
    "def create_pairing_heatmap(percentage_matrix, count_matrix, title, top_heavy=None, top_light=None, figsize=(14, 10)):\n",
    "    \"\"\"Create heatmap for heavy-light V gene pairing\"\"\"\n",
    "    \n",
    "    if percentage_matrix.empty:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.text(0.5, 0.5, 'No data available', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=16)\n",
    "        ax.set_title(title)\n",
    "        return fig\n",
    "    \n",
    "    # Filter to top genes if specified\n",
    "    plot_percentage = percentage_matrix.copy()\n",
    "    plot_count = count_matrix.copy()\n",
    "    \n",
    "    if top_heavy:\n",
    "        available_heavy = [gene for gene in top_heavy if gene in plot_percentage.index]\n",
    "        if available_heavy:\n",
    "            plot_percentage = plot_percentage.loc[available_heavy]\n",
    "            plot_count = plot_count.loc[available_heavy]\n",
    "    \n",
    "    if top_light:\n",
    "        available_light = [gene for gene in top_light if gene in plot_percentage.columns]\n",
    "        if available_light:\n",
    "            plot_percentage = plot_percentage[available_light]\n",
    "            plot_count = plot_count[available_light]\n",
    "    \n",
    "    # Create annotations combining percentage and count\n",
    "    annot_data = plot_percentage.round(1).astype(str) + '%\\n(' + plot_count.astype(str) + ')'\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(plot_percentage, \n",
    "                annot=annot_data, \n",
    "                cmap='YlOrRd', \n",
    "                fmt='', \n",
    "                ax=ax,\n",
    "                cbar_kws={'label': 'Percentage of Heavy Gene Usage'},\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Generated Light Chain V Gene', fontsize=12)\n",
    "    ax.set_ylabel('Heavy Chain V Gene', fontsize=12)\n",
    "    \n",
    "    # Rotate labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "    \n",
    "    # Add sample size information\n",
    "    total_sequences = plot_count.sum().sum()\n",
    "    unique_heavy_genes = len(plot_percentage.index)\n",
    "    unique_light_genes = len(plot_percentage.columns)\n",
    "    \n",
    "    sample_info = f\"Total sequences: {total_sequences}\\n\" \\\n",
    "                  f\"Heavy genes: {unique_heavy_genes}, Light genes: {unique_light_genes}\"\n",
    "    ax.text(0.02, 0.98, sample_info, transform=ax.transAxes, \n",
    "            verticalalignment='top', fontsize=10, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_pairing_preferences(percentage_matrix, count_matrix, gene_level):\n",
    "    \"\"\"Analyze and print pairing preferences\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Pairing Analysis for {gene_level} level ===\")\n",
    "    \n",
    "    # Find heavy genes with strong preferences (>50% for any light gene)\n",
    "    strong_preferences = []\n",
    "    for heavy_gene in percentage_matrix.index:\n",
    "        max_pct = percentage_matrix.loc[heavy_gene].max()\n",
    "        if max_pct > 50:\n",
    "            preferred_light = percentage_matrix.loc[heavy_gene].idxmax()\n",
    "            count = count_matrix.loc[heavy_gene, preferred_light]\n",
    "            total_count = count_matrix.loc[heavy_gene].sum()\n",
    "            strong_preferences.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'preferred_light': preferred_light,\n",
    "                'percentage': max_pct,\n",
    "                'count': count,\n",
    "                'total_sequences': total_count\n",
    "            })\n",
    "    \n",
    "    if strong_preferences:\n",
    "        print(\"Heavy genes with strong light gene preferences (>50%):\")\n",
    "        for pref in sorted(strong_preferences, key=lambda x: x['percentage'], reverse=True):\n",
    "            print(f\"  {pref['heavy_gene']} → {pref['preferred_light']}: \"\n",
    "                  f\"{pref['percentage']:.1f}% ({pref['count']}/{pref['total_sequences']} sequences)\")\n",
    "    else:\n",
    "        print(\"No heavy genes show strong preferences (>50%) for specific light genes\")\n",
    "    \n",
    "    # Find the most diverse heavy genes (spread across many light genes)\n",
    "    diversity_scores = []\n",
    "    for heavy_gene in percentage_matrix.index:\n",
    "        # Count how many light genes this heavy gene pairs with (>5% threshold)\n",
    "        num_partners = (percentage_matrix.loc[heavy_gene] > 5).sum()\n",
    "        total_sequences = count_matrix.loc[heavy_gene].sum()\n",
    "        diversity_scores.append({\n",
    "            'heavy_gene': heavy_gene,\n",
    "            'num_partners': num_partners,\n",
    "            'total_sequences': total_sequences\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nMost diverse heavy genes (pairing with multiple light genes >5%):\")\n",
    "    for div in sorted(diversity_scores, key=lambda x: x['num_partners'], reverse=True)[:5]:\n",
    "        print(f\"  {div['heavy_gene']}: pairs with {div['num_partners']} light genes \"\n",
    "              f\"({div['total_sequences']} total sequences)\")\n",
    "\n",
    "def create_all_pairing_heatmaps(groups):\n",
    "    \"\"\"Create all pairing heatmaps for all groups and gene levels\"\"\"\n",
    "    \n",
    "    gene_levels = ['full', 'simplified', 'family']\n",
    "    level_names = ['Full V Gene', 'Simplified V Gene', 'V Gene Family']\n",
    "    \n",
    "    all_figures = {}\n",
    "    \n",
    "    for group_name, group_df in groups.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {group_name}...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if len(group_df) == 0:\n",
    "            print(f\"No data for {group_name}\")\n",
    "            continue\n",
    "        \n",
    "        group_figures = {}\n",
    "        \n",
    "        for level, level_name in zip(gene_levels, level_names):\n",
    "            print(f\"\\n--- {level_name} ---\")\n",
    "            \n",
    "            # Create pairing matrices\n",
    "            count_matrix, percentage_matrix = create_heavy_light_pairing_matrix(group_df, level)\n",
    "            \n",
    "            if count_matrix.empty:\n",
    "                continue\n",
    "            \n",
    "            # Analyze pairing preferences\n",
    "            analyze_pairing_preferences(percentage_matrix, count_matrix, level_name)\n",
    "            \n",
    "            # Get top genes\n",
    "            top_heavy, top_light = get_top_genes(count_matrix, top_n=15)\n",
    "            \n",
    "            # Create heatmap with all genes\n",
    "            fig_all = create_pairing_heatmap(\n",
    "                percentage_matrix, count_matrix,\n",
    "                f\"{group_name} - {level_name}\\nHeavy-Light V Gene Pairing (All Genes)\",\n",
    "                figsize=(max(14, len(percentage_matrix.columns) * 0.8), \n",
    "                        max(10, len(percentage_matrix.index) * 0.5))\n",
    "            )\n",
    "            \n",
    "            # Create heatmap with top genes only\n",
    "            fig_top = create_pairing_heatmap(\n",
    "                percentage_matrix, count_matrix,\n",
    "                f\"{group_name} - {level_name}\\nHeavy-Light V Gene Pairing (Top 15 Genes)\",\n",
    "                top_heavy=top_heavy,\n",
    "                top_light=top_light,\n",
    "                figsize=(14, 10)\n",
    "            )\n",
    "            \n",
    "            group_figures[f\"{level}_all\"] = fig_all\n",
    "            group_figures[f\"{level}_top\"] = fig_top\n",
    "        \n",
    "        all_figures[group_name] = group_figures\n",
    "    \n",
    "    return all_figures\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6dcd10a3",
   "metadata": {},
   "source": [
    "\n",
    "def main(csv_file):\n",
    "    \"\"\"Main analysis function\"\"\"\n",
    "    \n",
    "    print(\"Heavy-Light V Gene Pairing Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load data\n",
    "    df = load_and_prepare_data(csv_file)\n",
    "    \n",
    "    # Create groups\n",
    "    groups = create_groups(df)\n",
    "    \n",
    "    # Create all heatmaps\n",
    "    all_figures = create_all_pairing_heatmaps(groups)\n",
    "    \n",
    "    # Display all figures\n",
    "    for group_name, group_figures in all_figures.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DISPLAYING HEATMAPS FOR {group_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for fig_name, fig in group_figures.items():\n",
    "            plt.figure(fig.number)\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(f\"Total heatmaps created: {sum(len(figs) for figs in all_figures.values())}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return all_figures\n",
    "\n",
    "\n",
    "figures = main('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2454e2a3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"Load CSV and prepare data for analysis\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Unique heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_groups(df):\n",
    "    \"\"\"Create the 4 groups based on predicted labels\"\"\"\n",
    "    \n",
    "    # Group 1: Both memory B cell origin (both labels = 1)\n",
    "    group1 = df[(df['predicted_gen_light_seq_label'] == 1) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 1)]\n",
    "    \n",
    "    # Group 2: Both naive B cell origin (both labels = 0)\n",
    "    group2 = df[(df['predicted_gen_light_seq_label'] == 0) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 3: Heavy memory, Generated light naive (heavy=1, gen_light=0)\n",
    "    group3 = df[(df['predicted_input_heavy_seq_label'] == 1) & \n",
    "                (df['predicted_gen_light_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 4: Heavy naive, Generated light memory (heavy=0, gen_light=1)\n",
    "    group4 = df[(df['predicted_input_heavy_seq_label'] == 0) & \n",
    "                (df['predicted_gen_light_seq_label'] == 1)]\n",
    "    \n",
    "    groups = {\n",
    "        'Group 1 (H:Memory, L:Memory)': group1,\n",
    "        'Group 2 (H:Naive, L:Naive)': group2,\n",
    "        'Group 3 (H:Memory, L:Naive)': group3,\n",
    "        'Group 4 (H:Naive, L:Memory)': group4\n",
    "    }\n",
    "    \n",
    "    print(\"\\nGroup sizes:\")\n",
    "    for name, group in groups.items():\n",
    "        print(f\"{name}: {len(group)} rows\")\n",
    "        if len(group) > 0:\n",
    "            print(f\"  Unique heavy chains: {group['heavy_chain_number'].nunique()}\")\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def extract_v_gene_info(gene_name):\n",
    "    \"\"\"Extract different levels of V gene information\"\"\"\n",
    "    if pd.isna(gene_name) or gene_name == '':\n",
    "        return {'full': 'Unknown', 'simplified': 'Unknown', 'family': 'Unknown'}\n",
    "    \n",
    "    # Full gene name\n",
    "    full = gene_name\n",
    "    \n",
    "    # Simplified (remove *XX part)\n",
    "    simplified = re.sub(r'\\*\\d+', '', gene_name)\n",
    "    \n",
    "    # Family (extract the main family part)\n",
    "    family_match = re.match(r'(IG[HKL]V\\d+)', gene_name)\n",
    "    family = family_match.group(1) if family_match else gene_name.split('-')[0]\n",
    "    \n",
    "    return {'full': full, 'simplified': simplified, 'family': family}\n",
    "\n",
    "def create_heavy_light_pairing_matrix(group_df, gene_level='full'):\n",
    "    \"\"\"Create heavy-light V gene pairing matrix\"\"\"\n",
    "    \n",
    "    if len(group_df) == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Extract V gene information for heavy and generated light chains\n",
    "    pairing_data = []\n",
    "    \n",
    "    for _, row in group_df.iterrows():\n",
    "        heavy_gene_info = extract_v_gene_info(row['heavy_chain_gene_name'])\n",
    "        gen_light_gene_info = extract_v_gene_info(row['gen_light_gene_name'])\n",
    "        \n",
    "        heavy_gene = heavy_gene_info[gene_level]\n",
    "        light_gene = gen_light_gene_info[gene_level]\n",
    "        \n",
    "        pairing_data.append({\n",
    "            'heavy_chain_number': row['heavy_chain_number'],\n",
    "            'heavy_gene': heavy_gene,\n",
    "            'light_gene': light_gene\n",
    "        })\n",
    "    \n",
    "    pairing_df = pd.DataFrame(pairing_data)\n",
    "    \n",
    "    # Create co-occurrence matrix (counts)\n",
    "    cooccurrence_matrix = pd.crosstab(\n",
    "        pairing_df['heavy_gene'], \n",
    "        pairing_df['light_gene'], \n",
    "        margins=False\n",
    "    )\n",
    "    \n",
    "    # Calculate percentages (what percentage of each heavy gene generates each light gene)\n",
    "    # This shows the preference of heavy genes for light genes\n",
    "    percentage_matrix = cooccurrence_matrix.div(cooccurrence_matrix.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    percentage_matrix = percentage_matrix.fillna(0)\n",
    "    \n",
    "    # Add sample sizes information\n",
    "    heavy_gene_counts = pairing_df['heavy_gene'].value_counts()\n",
    "    \n",
    "    print(f\"\\nSample sizes for each heavy gene (total generated sequences):\")\n",
    "    for gene, count in heavy_gene_counts.head(10).items():\n",
    "        unique_heavy_chains = pairing_df[pairing_df['heavy_gene'] == gene]['heavy_chain_number'].nunique()\n",
    "        print(f\"  {gene}: {count} total sequences from {unique_heavy_chains} heavy chains\")\n",
    "    \n",
    "    return cooccurrence_matrix, percentage_matrix\n",
    "\n",
    "def get_top_genes(matrix, top_n=15, axis='both'):\n",
    "    \"\"\"Get top N most frequent genes\"\"\"\n",
    "    if axis == 'both':\n",
    "        # Get top genes from both heavy and light\n",
    "        heavy_totals = matrix.sum(axis=1)\n",
    "        light_totals = matrix.sum(axis=0)\n",
    "        \n",
    "        top_heavy = heavy_totals.nlargest(top_n).index.tolist()\n",
    "        top_light = light_totals.nlargest(top_n).index.tolist()\n",
    "        \n",
    "        return top_heavy, top_light\n",
    "    elif axis == 'heavy':\n",
    "        heavy_totals = matrix.sum(axis=1)\n",
    "        return heavy_totals.nlargest(top_n).index.tolist()\n",
    "    elif axis == 'light':\n",
    "        light_totals = matrix.sum(axis=0)\n",
    "        return light_totals.nlargest(top_n).index.tolist()\n",
    "\n",
    "def create_pairing_heatmap(percentage_matrix, count_matrix, title, top_heavy=None, top_light=None, figsize=(14, 10)):\n",
    "    \"\"\"Create heatmap for heavy-light V gene pairing\"\"\"\n",
    "    \n",
    "    if percentage_matrix.empty:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.text(0.5, 0.5, 'No data available', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=16)\n",
    "        ax.set_title(title)\n",
    "        return fig\n",
    "    \n",
    "    # Filter to top genes if specified\n",
    "    plot_percentage = percentage_matrix.copy()\n",
    "    plot_count = count_matrix.copy()\n",
    "    \n",
    "    if top_heavy:\n",
    "        available_heavy = [gene for gene in top_heavy if gene in plot_percentage.index]\n",
    "        if available_heavy:\n",
    "            plot_percentage = plot_percentage.loc[available_heavy]\n",
    "            plot_count = plot_count.loc[available_heavy]\n",
    "    \n",
    "    if top_light:\n",
    "        available_light = [gene for gene in top_light if gene in plot_percentage.columns]\n",
    "        if available_light:\n",
    "            plot_percentage = plot_percentage[available_light]\n",
    "            plot_count = plot_count[available_light]\n",
    "    \n",
    "    # Create annotations combining percentage and count\n",
    "    annot_data = plot_percentage.round(1).astype(str) + '%\\n(' + plot_count.astype(str) + ')'\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(plot_percentage, \n",
    "                annot=annot_data, \n",
    "                cmap='YlOrRd', \n",
    "                fmt='', \n",
    "                ax=ax,\n",
    "                cbar_kws={'label': 'Percentage of Heavy Gene Usage'},\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Generated Light Chain V Gene', fontsize=12)\n",
    "    ax.set_ylabel('Heavy Chain V Gene', fontsize=12)\n",
    "    \n",
    "    # Rotate labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "    \n",
    "    # Add sample size information\n",
    "    total_sequences = plot_count.sum().sum()\n",
    "    unique_heavy_genes = len(plot_percentage.index)\n",
    "    unique_light_genes = len(plot_percentage.columns)\n",
    "    \n",
    "    sample_info = f\"Total sequences: {total_sequences}\\n\" \\\n",
    "                  f\"Heavy genes: {unique_heavy_genes}, Light genes: {unique_light_genes}\"\n",
    "    ax.text(0.02, 0.98, sample_info, transform=ax.transAxes, \n",
    "            verticalalignment='top', fontsize=10, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_pairing_preferences(percentage_matrix, count_matrix, gene_level):\n",
    "    \"\"\"Analyze and print pairing preferences\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Pairing Analysis for {gene_level} level ===\")\n",
    "    \n",
    "    # Find heavy genes with strong preferences (>50% for any light gene)\n",
    "    strong_preferences = []\n",
    "    for heavy_gene in percentage_matrix.index:\n",
    "        max_pct = percentage_matrix.loc[heavy_gene].max()\n",
    "        if max_pct > 50:\n",
    "            preferred_light = percentage_matrix.loc[heavy_gene].idxmax()\n",
    "            count = count_matrix.loc[heavy_gene, preferred_light]\n",
    "            total_count = count_matrix.loc[heavy_gene].sum()\n",
    "            strong_preferences.append({\n",
    "                'heavy_gene': heavy_gene,\n",
    "                'preferred_light': preferred_light,\n",
    "                'percentage': max_pct,\n",
    "                'count': count,\n",
    "                'total_sequences': total_count\n",
    "            })\n",
    "    \n",
    "    if strong_preferences:\n",
    "        print(\"Heavy genes with strong light gene preferences (>50%):\")\n",
    "        for pref in sorted(strong_preferences, key=lambda x: x['percentage'], reverse=True):\n",
    "            print(f\"  {pref['heavy_gene']} → {pref['preferred_light']}: \"\n",
    "                  f\"{pref['percentage']:.1f}% ({pref['count']}/{pref['total_sequences']} sequences)\")\n",
    "    else:\n",
    "        print(\"No heavy genes show strong preferences (>50%) for specific light genes\")\n",
    "    \n",
    "    # Find the most diverse heavy genes (spread across many light genes)\n",
    "    diversity_scores = []\n",
    "    for heavy_gene in percentage_matrix.index:\n",
    "        # Count how many light genes this heavy gene pairs with (>5% threshold)\n",
    "        num_partners = (percentage_matrix.loc[heavy_gene] > 5).sum()\n",
    "        total_sequences = count_matrix.loc[heavy_gene].sum()\n",
    "        diversity_scores.append({\n",
    "            'heavy_gene': heavy_gene,\n",
    "            'num_partners': num_partners,\n",
    "            'total_sequences': total_sequences\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nMost diverse heavy genes (pairing with multiple light genes >5%):\")\n",
    "    for div in sorted(diversity_scores, key=lambda x: x['num_partners'], reverse=True)[:5]:\n",
    "        print(f\"  {div['heavy_gene']}: pairs with {div['num_partners']} light genes \"\n",
    "              f\"({div['total_sequences']} total sequences)\")\n",
    "\n",
    "def create_all_pairing_heatmaps(groups, save_plots=True, dpi=500):\n",
    "    \"\"\"Create all pairing heatmaps for all groups and gene levels (only full heatmaps)\"\"\"\n",
    "    \n",
    "    gene_levels = ['full', 'simplified', 'family']\n",
    "    level_names = ['Full V Gene', 'Simplified V Gene', 'V Gene Family']\n",
    "    \n",
    "    all_figures = {}\n",
    "    \n",
    "    for group_name, group_df in groups.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {group_name}...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if len(group_df) == 0:\n",
    "            print(f\"No data for {group_name}\")\n",
    "            continue\n",
    "        \n",
    "        group_figures = {}\n",
    "        \n",
    "        for level, level_name in zip(gene_levels, level_names):\n",
    "            print(f\"\\n--- {level_name} ---\")\n",
    "            \n",
    "            # Create pairing matrices\n",
    "            count_matrix, percentage_matrix = create_heavy_light_pairing_matrix(group_df, level)\n",
    "            \n",
    "            if count_matrix.empty:\n",
    "                continue\n",
    "            \n",
    "            # Analyze pairing preferences\n",
    "            analyze_pairing_preferences(percentage_matrix, count_matrix, level_name)\n",
    "            \n",
    "            # Create heatmap with all genes only\n",
    "            fig_all = create_pairing_heatmap(\n",
    "                percentage_matrix, count_matrix,\n",
    "                f\"{group_name} - {level_name}\\nHeavy-Light V Gene Pairing (All Genes)\",\n",
    "                figsize=(max(14, len(percentage_matrix.columns) * 0.8), \n",
    "                        max(10, len(percentage_matrix.index) * 0.5))\n",
    "            )\n",
    "            \n",
    "            # Save the plot with high DPI\n",
    "            if save_plots:\n",
    "                # Create safe filename\n",
    "                safe_group_name = group_name.replace(':', '').replace('(', '').replace(')', '').replace(' ', '_')\n",
    "                filename = f\"{safe_group_name}_{level}_all_genes_heatmap.png\"\n",
    "                fig_all.savefig(filename, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "                print(f\"  Saved: {filename}\")\n",
    "            \n",
    "            group_figures[f\"{level}_all\"] = fig_all\n",
    "        \n",
    "        all_figures[group_name] = group_figures\n",
    "    \n",
    "    return all_figures\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7a683bd",
   "metadata": {},
   "source": [
    "def main(csv_file, save_plots=True, dpi=500):\n",
    "    \"\"\"Main analysis function\"\"\"\n",
    "    \n",
    "    print(\"Heavy-Light V Gene Pairing Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load data\n",
    "    df = load_and_prepare_data(csv_file)\n",
    "    \n",
    "    # Create groups\n",
    "    groups = create_groups(df)\n",
    "    \n",
    "    # Create all heatmaps (only full versions)\n",
    "    all_figures = create_all_pairing_heatmaps(groups, save_plots=save_plots, dpi=dpi)\n",
    "    \n",
    "    # Display all figures\n",
    "    for group_name, group_figures in all_figures.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DISPLAYING HEATMAPS FOR {group_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for fig_name, fig in group_figures.items():\n",
    "            plt.figure(fig.number)\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(f\"Total heatmaps created: {sum(len(figs) for figs in all_figures.values())}\")\n",
    "    if save_plots:\n",
    "        print(f\"All plots saved with DPI: {dpi}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return all_figures\n",
    "\n",
    "# Save plots with high DPI (500)\n",
    "figures = main('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv', save_plots=True, dpi=200)\n",
    "\n",
    "# Or run without saving plots\n",
    "# figures = main('your_file.csv', save_plots=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "698c7559",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"Load CSV and prepare data for analysis\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Unique heavy chains: {df['heavy_chain_number'].nunique()}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_groups(df):\n",
    "    \"\"\"Create the 4 groups based on predicted labels\"\"\"\n",
    "    \n",
    "    # Group 1: Both memory B cell origin (both labels = 1)\n",
    "    group1 = df[(df['predicted_gen_light_seq_label'] == 1) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 1)]\n",
    "    \n",
    "    # Group 2: Both naive B cell origin (both labels = 0)\n",
    "    group2 = df[(df['predicted_gen_light_seq_label'] == 0) & \n",
    "                (df['predicted_input_heavy_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 3: Heavy memory, Generated light naive (heavy=1, gen_light=0)\n",
    "    group3 = df[(df['predicted_input_heavy_seq_label'] == 1) & \n",
    "                (df['predicted_gen_light_seq_label'] == 0)]\n",
    "    \n",
    "    # Group 4: Heavy naive, Generated light memory (heavy=0, gen_light=1)\n",
    "    group4 = df[(df['predicted_input_heavy_seq_label'] == 0) & \n",
    "                (df['predicted_gen_light_seq_label'] == 1)]\n",
    "    \n",
    "    groups = {\n",
    "        'Group 1 (H:Memory, L:Memory)': group1,\n",
    "        'Group 2 (H:Naive, L:Naive)': group2,\n",
    "        'Group 3 (H:Memory, L:Naive)': group3,\n",
    "        'Group 4 (H:Naive, L:Memory)': group4\n",
    "    }\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def analyze_specific_switch(df, target_heavy='IGHV3-20*04', target_light='IGKV1-39*01'):\n",
    "    \"\"\"Analyze the specific switch from target heavy to target light gene\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANALYZING SWITCH: {target_heavy} → {target_light}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # First, let's see how many sequences we have with the target heavy gene\n",
    "    target_heavy_sequences = df[df['heavy_chain_gene_name'] == target_heavy]\n",
    "    \n",
    "    print(f\"\\nSequences with {target_heavy}:\")\n",
    "    print(f\"  Total sequences: {len(target_heavy_sequences)}\")\n",
    "    print(f\"  Unique heavy chains: {target_heavy_sequences['heavy_chain_number'].nunique()}\")\n",
    "    \n",
    "    if len(target_heavy_sequences) == 0:\n",
    "        print(f\"No sequences found with heavy gene {target_heavy}\")\n",
    "        return {}\n",
    "    \n",
    "    # Analyze for each group\n",
    "    groups = create_groups(df)\n",
    "    results = {}\n",
    "    \n",
    "    for group_name, group_df in groups.items():\n",
    "        print(f\"\\n--- {group_name} ---\")\n",
    "        \n",
    "        # Filter for target heavy gene in this group\n",
    "        group_target_heavy = group_df[group_df['heavy_chain_gene_name'] == target_heavy]\n",
    "        \n",
    "        if len(group_target_heavy) == 0:\n",
    "            print(f\"  No {target_heavy} sequences in this group\")\n",
    "            results[group_name] = {\n",
    "                'total_sequences': 0,\n",
    "                'unique_heavy_chains': 0,\n",
    "                'generated_switch_count': 0,\n",
    "                'generated_switch_percentage': 0,\n",
    "                'true_switch_count': 0,\n",
    "                'true_switch_percentage': 0,\n",
    "                'generated_switch_details': [],\n",
    "                'true_switch_details': []\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        total_sequences = len(group_target_heavy)\n",
    "        unique_heavy_chains = group_target_heavy['heavy_chain_number'].nunique()\n",
    "        \n",
    "        print(f\"  Total {target_heavy} sequences: {total_sequences}\")\n",
    "        print(f\"  Unique {target_heavy} heavy chains: {unique_heavy_chains}\")\n",
    "        \n",
    "        # Analyze generated light chain switches\n",
    "        generated_switches = group_target_heavy[\n",
    "            group_target_heavy['gen_light_gene_name'] == target_light\n",
    "        ]\n",
    "        generated_switch_count = len(generated_switches)\n",
    "        generated_switch_percentage = (generated_switch_count / total_sequences) * 100 if total_sequences > 0 else 0\n",
    "        \n",
    "        print(f\"  Generated light switches to {target_light}: {generated_switch_count}/{total_sequences} ({generated_switch_percentage:.1f}%)\")\n",
    "        \n",
    "        # Get details of generated switches\n",
    "        generated_switch_details = []\n",
    "        if generated_switch_count > 0:\n",
    "            for _, row in generated_switches.iterrows():\n",
    "                generated_switch_details.append({\n",
    "                    'heavy_chain_number': row['heavy_chain_number'],\n",
    "                    'gen_light_chain_number': row['gen_light_chain_number'],\n",
    "                    'true_light_gene': row['true_light_gene_name']\n",
    "                })\n",
    "        \n",
    "        # Analyze true light chain switches (only unique heavy chains)\n",
    "        unique_heavy_target = group_target_heavy.drop_duplicates(subset=['heavy_chain_number'])\n",
    "        true_switches = unique_heavy_target[\n",
    "            unique_heavy_target['true_light_gene_name'] == target_light\n",
    "        ]\n",
    "        true_switch_count = len(true_switches)\n",
    "        true_switch_percentage = (true_switch_count / unique_heavy_chains) * 100 if unique_heavy_chains > 0 else 0\n",
    "        \n",
    "        print(f\"  True light switches to {target_light}: {true_switch_count}/{unique_heavy_chains} ({true_switch_percentage:.1f}%)\")\n",
    "        \n",
    "        # Get details of true switches\n",
    "        true_switch_details = []\n",
    "        if true_switch_count > 0:\n",
    "            for _, row in true_switches.iterrows():\n",
    "                true_switch_details.append({\n",
    "                    'heavy_chain_number': row['heavy_chain_number'],\n",
    "                    'true_light_gene': row['true_light_gene_name']\n",
    "                })\n",
    "        \n",
    "        results[group_name] = {\n",
    "            'total_sequences': total_sequences,\n",
    "            'unique_heavy_chains': unique_heavy_chains,\n",
    "            'generated_switch_count': generated_switch_count,\n",
    "            'generated_switch_percentage': generated_switch_percentage,\n",
    "            'true_switch_count': true_switch_count,\n",
    "            'true_switch_percentage': true_switch_percentage,\n",
    "            'generated_switch_details': generated_switch_details,\n",
    "            'true_switch_details': true_switch_details\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_heavy_chain_specific_patterns(df, target_heavy='IGHV3-20*04'):\n",
    "    \"\"\"Analyze what light genes the target heavy gene typically pairs with\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LIGHT GENE PREFERENCES FOR {target_heavy}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    target_heavy_sequences = df[df['heavy_chain_gene_name'] == target_heavy]\n",
    "    \n",
    "    if len(target_heavy_sequences) == 0:\n",
    "        print(f\"No sequences found with heavy gene {target_heavy}\")\n",
    "        return\n",
    "    \n",
    "    groups = create_groups(df)\n",
    "    \n",
    "    for group_name, group_df in groups.items():\n",
    "        print(f\"\\n--- {group_name} ---\")\n",
    "        \n",
    "        group_target_heavy = group_df[group_df['heavy_chain_gene_name'] == target_heavy]\n",
    "        \n",
    "        if len(group_target_heavy) == 0:\n",
    "            print(f\"  No {target_heavy} sequences in this group\")\n",
    "            continue\n",
    "        \n",
    "        # Generated light gene distribution\n",
    "        gen_light_dist = group_target_heavy['gen_light_gene_name'].value_counts()\n",
    "        print(f\"  Generated light gene distribution (top 10):\")\n",
    "        for i, (gene, count) in enumerate(gen_light_dist.head(10).items()):\n",
    "            percentage = (count / len(group_target_heavy)) * 100\n",
    "            print(f\"    {i+1}. {gene}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # True light gene distribution (unique heavy chains only)\n",
    "        unique_heavy_target = group_target_heavy.drop_duplicates(subset=['heavy_chain_number'])\n",
    "        true_light_dist = unique_heavy_target['true_light_gene_name'].value_counts()\n",
    "        print(f\"  True light gene distribution:\")\n",
    "        for i, (gene, count) in enumerate(true_light_dist.items()):\n",
    "            percentage = (count / len(unique_heavy_target)) * 100\n",
    "            print(f\"    {i+1}. {gene}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "def create_switch_summary_table(results, target_heavy='IGHV3-20*04', target_light='IGKV1-39*01'):\n",
    "    \"\"\"Create a summary table of switch analysis results\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for group_name, result in results.items():\n",
    "        summary_data.append({\n",
    "            'Group': group_name,\n",
    "            'Total_Sequences': result['total_sequences'],\n",
    "            'Unique_Heavy_Chains': result['unique_heavy_chains'],\n",
    "            'Generated_Switches': result['generated_switch_count'],\n",
    "            'Generated_Switch_Pct': result['generated_switch_percentage'],\n",
    "            'True_Switches': result['true_switch_count'],\n",
    "            'True_Switch_Pct': result['true_switch_percentage']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SUMMARY TABLE: {target_heavy} → {target_light} SWITCHES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "def visualize_switch_analysis(results, target_heavy='IGHV3-20*04', target_light='IGKV1-39*01'):\n",
    "    \"\"\"Create visualizations of the switch analysis\"\"\"\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    groups = list(results.keys())\n",
    "    generated_percentages = [results[group]['generated_switch_percentage'] for group in groups]\n",
    "    true_percentages = [results[group]['true_switch_percentage'] for group in groups]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Generated light chain switches\n",
    "    bars1 = ax1.bar(range(len(groups)), generated_percentages, \n",
    "                    color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'], alpha=0.8)\n",
    "    ax1.set_xlabel('Groups')\n",
    "    ax1.set_ylabel('Switch Percentage (%)')\n",
    "    ax1.set_title(f'Generated Light Chain Switches\\n{target_heavy} → {target_light}')\n",
    "    ax1.set_xticks(range(len(groups)))\n",
    "    ax1.set_xticklabels([g.replace(' ', '\\n') for g in groups], fontsize=10)\n",
    "    ax1.set_ylim(0, max(generated_percentages + [1]) * 1.1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, pct) in enumerate(zip(bars1, generated_percentages)):\n",
    "        if pct > 0:\n",
    "            count = results[groups[i]]['generated_switch_count']\n",
    "            total = results[groups[i]]['total_sequences']\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{pct:.1f}%\\n({count}/{total})', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 2: True light chain switches\n",
    "    bars2 = ax2.bar(range(len(groups)), true_percentages, \n",
    "                    color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'], alpha=0.8)\n",
    "    ax2.set_xlabel('Groups')\n",
    "    ax2.set_ylabel('Switch Percentage (%)')\n",
    "    ax2.set_title(f'True Light Chain Switches\\n{target_heavy} → {target_light}')\n",
    "    ax2.set_xticks(range(len(groups)))\n",
    "    ax2.set_xticklabels([g.replace(' ', '\\n') for g in groups], fontsize=10)\n",
    "    ax2.set_ylim(0, max(true_percentages + [1]) * 1.1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, pct) in enumerate(zip(bars2, true_percentages)):\n",
    "        if pct > 0:\n",
    "            count = results[groups[i]]['true_switch_count']\n",
    "            total = results[groups[i]]['unique_heavy_chains']\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{pct:.1f}%\\n({count}/{total})', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f474792a",
   "metadata": {},
   "source": [
    "def main(csv_file, target_heavy='IGHV3-20*04', target_light='IGKV1-39*01'):\n",
    "    \"\"\"Main analysis function for specific switch analysis\"\"\"\n",
    "    \n",
    "    print(f\"SPECIFIC SWITCH ANALYSIS\")\n",
    "    print(f\"Target Switch: {target_heavy} → {target_light}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load data\n",
    "    df = load_and_prepare_data(csv_file)\n",
    "    \n",
    "    # Analyze the specific switch\n",
    "    results = analyze_specific_switch(df, target_heavy, target_light)\n",
    "    \n",
    "    # Analyze general patterns for the target heavy gene\n",
    "    analyze_heavy_chain_specific_patterns(df, target_heavy)\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_df = create_switch_summary_table(results, target_heavy, target_light)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = visualize_switch_analysis(results, target_heavy, target_light)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"DETAILED SWITCH ANALYSIS RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for group_name, result in results.items():\n",
    "        if result['total_sequences'] > 0:\n",
    "            print(f\"\\n{group_name}:\")\n",
    "            print(f\"  Sample size: {result['total_sequences']} sequences from {result['unique_heavy_chains']} unique heavy chains\")\n",
    "            print(f\"  Generated switches: {result['generated_switch_count']}/{result['total_sequences']} ({result['generated_switch_percentage']:.1f}%)\")\n",
    "            print(f\"  True switches: {result['true_switch_count']}/{result['unique_heavy_chains']} ({result['true_switch_percentage']:.1f}%)\")\n",
    "            \n",
    "            if result['generated_switch_count'] > 0:\n",
    "                print(f\"  Generated switch details:\")\n",
    "                for detail in result['generated_switch_details'][:5]:  # Show first 5\n",
    "                    print(f\"    Heavy chain {detail['heavy_chain_number']}, Gen light {detail['gen_light_chain_number']}, True light gene: {detail['true_light_gene']}\")\n",
    "                if len(result['generated_switch_details']) > 5:\n",
    "                    print(f\"    ... and {len(result['generated_switch_details']) - 5} more\")\n",
    "    \n",
    "    return results, summary_df, fig\n",
    "\n",
    "# Example usage:\n",
    "results, summary, fig = main('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv', 'IGHV3-20*04', 'IGKV1-39*01')\n",
    "\n",
    "# You can also analyze different switches:\n",
    "#results, summary, fig = main('/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2GPT/multiple_light_seqs_from_single_heavy/full_test_set_multiple_light_seqs/full_eval_generate_multiple_light_seqs_203276_cls_predictions_merged_genes.csv', 'IGHV1-69-2*01', 'IGKV6D-41*01')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbe523a0",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adap_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
