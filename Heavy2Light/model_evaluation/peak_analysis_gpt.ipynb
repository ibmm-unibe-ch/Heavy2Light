{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak analysis Bert2GPT\n",
    "run name: full_PLAbDab_healthy_human_nucleus_bert2gpt_nucleus_healthy_human_PLAbDab_max_new_tokens_115_num_epochs_50_bert_like_tokenizer_unpaired_epo_41-7  \n",
    "julia version: 1.10.2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Plots\")\n",
    "# Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"BioSequences\")\n",
    "Pkg.add(\"BioAlignments\")\n",
    "Pkg.add(\"PyCall\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using Statistics\n",
    "using BioSequences\n",
    "using BioAlignments"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "file_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2gpt/data/global_align.csv\"\n",
    "\n",
    "df = CSV.read(file_path, DataFrame);\n",
    "names(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# count unqiue values in the column generated_sequence_light\n",
    "unique_values = unique(df[!, :generated_sequence_light])\n",
    "length(unique_values)\n",
    "\n",
    "# group by the column generated_sequence_light\n",
    "grouped = groupby(df, :generated_sequence_light)\n",
    "grouped\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# count unqiue values in the column generated_sequence_light\n",
    "unique_values = unique(df[!, :sequence_alignment_aa_light])\n",
    "length(unique_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=false\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "using DataFrames, PyCall\n",
    "\n",
    "# Import Python modules\n",
    "sns = pyimport(\"seaborn\")\n",
    "plt = pyimport(\"matplotlib.pyplot\")\n",
    "pd = pyimport(\"pandas\")\n",
    "\n",
    "# Assume your Julia DataFrame is named `df`\n",
    "py_df = pd.DataFrame(Dict(col => df[!, col] for col in names(df)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Start with a fresh figure to avoid overlapping previous plots\n",
    "plt.figure()\n",
    "\n",
    "bins = 40\n",
    "sns.histplot(data=py_df, x=\"calculated_similarity\", bins=bins, kde=true, \n",
    "             color=\"lightskyblue\", edgecolor=\"white\", alpha=0.3)\n",
    "\n",
    "plt.xlabel(\"Similarity betw. generated and true light sequence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Save before showing the plot\n",
    "plt.savefig(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2gpt/plots/histplot_bins_40_poly_kde_lightskyblue.png\", dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df[!, :heavy_sep_light] = string.(df.input_heavy_sequence,\"[SEP]\", df.sequence_alignment_aa_light,)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "println(first(df, 10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "names(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 1: Count occurrences of each value in the column\n",
    "value_counts = combine(groupby(df, :heavy_sep_light), nrow => :count)\n",
    "\n",
    "# Step 2: Filter for values that appear more than once\n",
    "duplicates = filter(row -> row.count > 1, value_counts)\n",
    "\n",
    "# Display duplicate entries\n",
    "println(\"Duplicate entries in heavy_sep_light:\")\n",
    "println(duplicates)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Test DataFrame: df_main\n",
    "df_main = DataFrame(\n",
    "    sequence_alignment_heavy_sep_light = [\n",
    "        \"SEQ1 [SEP] LIGHT1\",\n",
    "        \"SEQ2 [SEP] LIGHT2\",\n",
    "        \"SEQ3 [SEP] LIGHT3\",\n",
    "        \"SEQ3 [SEP] LIGHT3\",\n",
    "        \"SEQ4 [SEP] LIGHT4\",\n",
    "        \"SEQ5 [SEP] LIGHT5\"\n",
    "    ],\n",
    "    BType = [\"Plasma\", \"Memory\", \"Naive\", \"Naive\", \"Memory\", \"Plasma\"],\n",
    "    Disease = [\"None\", \"Flu\", \"None\", \"None\", \"Covid\", \"None\"]\n",
    ")\n",
    "\n",
    "# Test DataFrame: df_other\n",
    "df_other = DataFrame(\n",
    "    heavy_sep_light = [\n",
    "        \"SEQ1 [SEP] LIGHT1\",\n",
    "        \"SEQ2 [SEP] LIGHT2\",\n",
    "        \"SEQ2 [SEP] LIGHT2\",  # Duplicate\n",
    "        \"SEQ4 [SEP] LIGHT4\",\n",
    "        \"SEQ6 [SEP] LIGHT6\"   # Not in df_main\n",
    "    ],\n",
    "    BLOSUM_score = [90, 85, 85, 88, 92],\n",
    "    similarity = [0.98, 0.95, 0.95, 0.89, 0.93]\n",
    ")\n",
    "\n",
    "println(\"df_main:\")\n",
    "println(df_main)\n",
    "println(\"df_other:\")\n",
    "println(df_other)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 1: Remove duplicates from the \"other\" DataFrame\n",
    "df_main_unique = unique(df_main, :sequence_alignment_heavy_sep_light)\n",
    "\n",
    "# Step 2: Merge the DataFrames using `on`\n",
    "df_merged = innerjoin(\n",
    "    df_main_unique, \n",
    "    df_other, \n",
    "    on=(:sequence_alignment_heavy_sep_light => :heavy_sep_light)\n",
    ")\n",
    "\n",
    "println(\"\\nMerged DataFrame:\")\n",
    "println(df_merged)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# /ibmm_data2/oas_database/paired_lea_tmp/paired_model/coherence_analysis_in_oas_db/data/full_extraction_for_coherence_paired_data_extra_cols_header.csv -> extracted paired data with B Types\n",
    "df_main_full = CSV.read(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/coherence_analysis_in_oas_db/data/full_extraction_for_coherence_paired_data_extra_cols_header.csv\", DataFrame);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 1: Remove duplicates from the \"other\" DataFrame\n",
    "df_main_full_unique = unique(df_main_full, :sequence_alignment_heavy_sep_light)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "names(df_main_full_unique)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Extract IDs from query file\n",
    "function get_ids(file)\n",
    "    ## Populate set with lines from the file\n",
    "    queries = Set(eachline(file))\n",
    "    return queries\n",
    "end\n",
    "\n",
    "# Modified compare_ids function to accept a file handle for output -> IDs here: heavy[SEP]light sequences!\n",
    "function compare_ids(queries, db, output_file)\n",
    "    # Loop through db_lines\n",
    "    for ln in eachline(db)\n",
    "        # Extract ID with regex\n",
    "        parts = split(ln, ',')  # Splitting based on comma\n",
    "        #ID = strip(parts[end])  # Assuming the ID is the last part after the comma!\n",
    "        ID = strip(parts[15])  # Extracting ID from the xth column!! -> always check the column number in your dataset!\n",
    "        # Search in queries\n",
    "        if ID in queries\n",
    "            println(output_file, ln)  # Writing to file instead of standard output\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Extract the heavy_sep_light column as a new DataFrame\n",
    "df_ids = select(df, :heavy_sep_light)\n",
    "\n",
    "# Save the extracted column to a CSV file\n",
    "output_file_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/heavy_sep_light_column_ids.csv\"\n",
    "CSV.write(output_file_path, df_ids)\n",
    "\n",
    "println(\"Column saved to $output_file_path\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Open output file for writing\n",
    "# open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/extracted_data_merged.csv\", \"w\") do output_file\n",
    "#     # Run the actual functions with output redirection\n",
    "#     open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/heavy_sep_light_column_ids.csv\") do query_file\n",
    "#         queries = get_ids(query_file)\n",
    "#         open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/coherence_analysis_in_oas_db/data/full_extraction_for_coherence_paired_data_extra_cols_header.csv\") do db_file\n",
    "#             compare_ids(queries, db_file, output_file)\n",
    "#         end\n",
    "#     end\n",
    "# end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to get the column names from a CSV file\n",
    "function get_column_names(file)\n",
    "    first_line = readline(file)  # Read the first line from the file\n",
    "    columns = split(first_line, \",\")  # Split by commas to get individual column names\n",
    "    return columns\n",
    "end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Open output file for writing\n",
    "open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/extracted_data_merged_header.csv\", \"w\") do output_file\n",
    "    # Open query file and extract queries\n",
    "    open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/heavy_sep_light_column_ids.csv\") do query_file\n",
    "        queries = get_ids(query_file)\n",
    "\n",
    "        # Open db_file and extract column names\n",
    "        open(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/coherence_analysis_in_oas_db/data/full_extraction_for_coherence_paired_data_extra_cols_header.csv\") do db_file\n",
    "            # Get column names from db_file\n",
    "            column_names = get_column_names(db_file)\n",
    "\n",
    "            # Write the column names to the output file\n",
    "            println(output_file, join(column_names, \",\"))  # Write header\n",
    "\n",
    "            # Now we can run the compare_ids function with output redirection\n",
    "            # Reopen the db_file as it is already consumed by get_column_names\n",
    "            seekstart(db_file)  # Go back to the beginning of the file\n",
    "            compare_ids(queries, db_file, output_file)\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "extracted_data_merged = CSV.read(\"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2bert/data/extracted_data_merged_header.csv\", DataFrame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_merged_final = innerjoin(extracted_data_merged, df, on=(:sequence_alignment_heavy_sep_light => :heavy_sep_light), makeunique=true)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=false\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:BType  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_filtered_mem_naive = filter(row -> row.BType in [\"Memory-B-Cells\", \"Naive-B-Cells\"], df_merged_final)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_filtered_mem_naive histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:BType  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:locus_light  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:Author  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:Subject  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract up to the first two segments (e.g., \"IGKV2-30\" from \"IGKV2-30*01\")\n",
    "df_merged_final[!, :general_v_gene_heavy] = replace.(df_merged_final.v_call_heavy, r\"(^[^*]+?)(?:\\*.*)?$\" => s\"\\1\"); # the regex removes any part of the string after (and including) the first *, keeping only the portion before it.\n",
    "df_merged_final[!, :general_v_gene_light] = replace.(df_merged_final.v_call_light, r\"(^[^*]+?)(?:\\*.*)?$\" => s\"\\1\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:general_v_gene_heavy  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:general_v_gene_light  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Extract up to the first two segments (e.g., \"IGKV2-30\" from \"IGKV2-30*01\")\n",
    "df_merged_final[!, :v_gene_heavy_family] = replace.(df_merged_final.v_call_heavy, r\"(^[^*]+?)(?:\\-.*)?$\" => s\"\\1\"); # the regex removes any part of the string after (and including) the first *, keeping only the portion before it.\n",
    "df_merged_final[!, :v_gene_light_family] = replace.(df_merged_final.v_call_light, r\"(^[^*]+?)(?:\\-.*)?$\" => s\"\\1\");\n",
    "\n",
    "df_merged_final;\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:v_gene_heavy_family  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:v_gene_light_family  # Group by the BType column to color the histogram bars\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group by the column v_gene_heavy_family\n",
    "grouped_df = groupby(df_merged_final, :v_gene_light_family)\n",
    "\n",
    "# Calculate the average and group size for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,  # Calculate average similarity\n",
    "    nrow => :group_size                                      # Calculate group size\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Group by the column v_gene_light_family\n",
    "grouped_df = groupby(df_merged_final, :v_gene_light_family)\n",
    "\n",
    "# Calculate the average, group size, and number of unique values in generated_light_seq for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,  # Calculate average similarity\n",
    "    nrow => :group_size,                                    # Calculate group size\n",
    "    :generated_sequence_light => x -> length(unique(x)) => :num_unique_generated_light_seq  # Count unique values\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# sort v_gene_light_family by its most common entry\n",
    "sorted_df = sort(result_df, :group_size, rev=true)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group by the column BType\n",
    "grouped_df = groupby(df_merged_final, :BType)\n",
    "\n",
    "# Calculate the average and group size for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,  # Calculate average similarity\n",
    "    nrow => :group_size                                      # Calculate group size\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group by the column BType\n",
    "grouped_df = groupby(df_merged_final, :v_gene_heavy_family)\n",
    "\n",
    "# Calculate the average similarity for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,\n",
    "    nrow => :group_size   # Calculate the average of calculated_similarity\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group by the column BType\n",
    "grouped_df = groupby(df_merged_final, :locus_light)\n",
    "\n",
    "# Calculate the average similarity for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,\n",
    "    nrow => :group_size   # Calculate the average of calculated_similarity\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_filtered_kappa_only = filter(row -> row.locus_light in [\"K\"], df_merged_final);\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_filtered_kappa_only histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:v_gene_light_family  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_filtered_kappa_only histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:v_gene_heavy_family  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "grouped_df = groupby(df_filtered_kappa_only, :v_gene_light_family)\n",
    "\n",
    "# Calculate the average similarity for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,\n",
    "    nrow => :group_size   # Calculate the average of calculated_similarity\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "grouped_df = groupby(df_merged_final, :general_v_gene_light)\n",
    "\n",
    "# Calculate the average similarity for each group\n",
    "result_df = combine(grouped_df, \n",
    "    :calculated_similarity => mean => :average_similarity,\n",
    "    nrow => :group_size   # Calculate the average of calculated_similarity\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "println(result_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# save df_merged_final to a CSV file\n",
    "output_file_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/coherence_analysis_in_oas_db/data/test_set/df_merged_final_test_set.csv\"\n",
    "CSV.write(output_file_path, df_merged_final)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Group by the column BType\n",
    "grouped_df = groupby(df_merged_final, :germline_alignment_aa_light)\n",
    "\n",
    "grouped_df_filt = filter(g -> nrow(g) > 10, grouped_df);\n",
    "\n",
    "# Calculate the average similarity for each group\n",
    "result_df = combine(grouped_df_filt, \n",
    "    :calculated_similarity => mean => :average_similarity,\n",
    "    nrow => :group_size\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by average_similarity in descending order\n",
    "sorted_result_df = sort(result_df, :average_similarity, rev=true)\n",
    "\n",
    "# Display the resulting sorted DataFrame\n",
    "sorted_result_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "function score_bio(S1, S2; matrix=BLOSUM62, gop=-10, gep=-4)\n",
    "\tscoremodel = AffineGapScoreModel(matrix, gap_open=gop, gap_extend=gep)\n",
    "\tres = pairalign(GlobalAlignment(), S1, S2, scoremodel)\n",
    "\tres\n",
    "end\n",
    "\n",
    "score_bio(\"DVVVTQSPLSLPVTLGQPASISCGSSESLLYSNGNTYLSWFQQRPGQSPRRLIYQVSNRDSGVPDRFSGSGSGTDFTLKISRVEVEDVGVYFCMQGTYLPITFGQGTRLEIK\", \"DVVMTQSPLSLPVTLGQPASISCRSSQSLVYSDGNTYLNWFQQRPGQSPRRLIYKVSNRDSGVPDRFSGSGSGTDFTLKISRVEAEDVGVYYCMQGTHWPITFGQGTRLEIK\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "function score_bio(S1, S2; matrix=BLOSUM62, gop=-10, gep=-4)\n",
    "    # Create the scoring model\n",
    "    scoremodel = AffineGapScoreModel(matrix, gap_open=gop, gap_extend=gep)\n",
    "    \n",
    "    # Perform the alignment\n",
    "    res = pairalign(GlobalAlignment(), S1, S2, scoremodel)\n",
    "\n",
    "    aln = alignment(res)\n",
    "    \n",
    "    matches = count_matches(aln)\n",
    "    \n",
    "    # Calculate the percentage similarity\n",
    "    alignment_length = length(S1)  # Includes gaps\n",
    "    similarity_percentage = (matches / alignment_length) * 100\n",
    "    \n",
    "    return similarity_percentage\n",
    "end\n",
    "\n",
    "# Example usage\n",
    "seq1 = aa\"DIQMTQSPSSLSASIGDRVTITCRASQDINNYLAWYQQKPGKVPKLLIYAASTLHSGVPSRFSGSGSGTDFSLTISSLQPDDIASYYCQKYNSAITFGQGTRLDIK\"\n",
    "seq2 = aa\"DIQMTQSPSSLSASVGDRVTITCRASQGISNYLAWYQQKPGKVPKLLIYAASTLQSGVPSRFSGSGSGTDFTLTISSLQPEDVATYYCQKYNSAITFGQGTRLEIK\"\n",
    "\n",
    "similarity = score_bio(seq1, seq2)\n",
    "\n",
    "println(\"Similarity Percentage: \", similarity, \"%\")\n",
    "similarity\n",
    "\n",
    "test = \"x\"\n",
    "print(\"$x\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the score_bio function\n",
    "function score_bio(S1, S2; matrix=BLOSUM62, gop=-10, gep=-4)\n",
    "    # Create the scoring model\n",
    "    scoremodel = AffineGapScoreModel(matrix, gap_open=gop, gap_extend=gep)\n",
    "    \n",
    "    # Perform the alignment\n",
    "    res = pairalign(GlobalAlignment(), S1, S2, scoremodel)\n",
    "\n",
    "    # Extract alignment and count matches\n",
    "    aln = alignment(res)\n",
    "    matches = count_matches(aln)\n",
    "    \n",
    "    # Calculate the percentage similarity\n",
    "    alignment_length = length(S1)  # Includes gaps\n",
    "    similarity_percentage = (matches / alignment_length) * 100\n",
    "    \n",
    "    return similarity_percentage\n",
    "end\n",
    "\n",
    "# Ensure the relevant columns are strings\n",
    "df_merged_final.sequence_alignment_aa_light = string.(df_merged_final.sequence_alignment_aa_light)\n",
    "df_merged_final.germline_alignment_aa_light = string.(df_merged_final.germline_alignment_aa_light)\n",
    "\n",
    "# Calculate alignment similarity for each row\n",
    "df_merged_final.alignment_germline = [\n",
    "    score_bio(row.sequence_alignment_aa_light, row.germline_alignment_aa_light)\n",
    "    for row in eachrow(df_merged_final)\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# using DataFrames\n",
    "\n",
    "# # Add a new column for the similarity group\n",
    "# df_merged_final.group = [\n",
    "#     if 0 ≤ val < 55\n",
    "#         \"0-55\"\n",
    "#     elseif 55 ≤ val < 75\n",
    "#         \"55-75\"\n",
    "#     elseif 75 ≤ val ≤ 100\n",
    "#         \"75-100\"\n",
    "#     else\n",
    "#         \"Out of range\"  # Optional, to catch invalid values\n",
    "#     end for val in df_merged_final.calculated_similarity\n",
    "# ]\n",
    "\n",
    "# # Group the DataFrame by the new column\n",
    "# grouped_df = groupby(df_merged_final, :group)\n",
    "\n",
    "# # Display grouped data\n",
    "# for g in grouped_df\n",
    "#     println(\"Group: \", g.group[1])\n",
    "#     println(g)\n",
    "# end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "using Pkg\n",
    "Pkg.add(\"CategoricalArrays\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "using DataFrames\n",
    "using CategoricalArrays\n",
    "\n",
    "# Define the similarity bins\n",
    "bins = [0, 55, 75, 110]\n",
    "\n",
    "# Create a new column by binning the calculated_similarity values\n",
    "df_merged_final.group = cut(df_merged_final.calculated_similarity, bins, labels=[\"0-55\", \"55-75\", \"75-100\"])\n",
    "\n",
    "# Group the DataFrame by the new column\n",
    "grouped_df = groupby(df_merged_final, :group)\n",
    "\n",
    "# Display grouped data\n",
    "for g in grouped_df\n",
    "    println(\"Group: \", g.group[1])\n",
    "    println(g)\n",
    "end"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group the DataFrame by the 'group' column and calculate the mean of 'calculated_similarity' for each group\n",
    "mean_df = combine(grouped_df, :alignment_germline => mean)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "mean_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@df df_merged_final histogram(\n",
    "    :calculated_similarity, \n",
    "    bins=150,  # Number of bins\n",
    "    xlabel=\"Calculated Similarity\", \n",
    "    ylabel=\"Frequency\", \n",
    "    title=\"Distribution of Calculated Similarity\", \n",
    "    legend=true,  # Show the legend\n",
    "    group=:Subject  # Group by the BType column to color the histogram bars\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# save df_merged_final to a CSV file\n",
    "output_file_path = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/peak_analysis/bert2gpt/data/bert2gpt_df_merged_final_test_set.csv\"\n",
    "CSV.write(output_file_path, df_merged_final)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
