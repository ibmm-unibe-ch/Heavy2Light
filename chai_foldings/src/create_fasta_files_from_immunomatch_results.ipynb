{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9299994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41479e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_fasta_files(csv_filename):\n",
    "    \"\"\"\n",
    "    Create two FASTA files from CSV based on pairing scores.\n",
    "    Removes duplicates based on NT_Trimmed column.\n",
    "    Each entry includes both light chain (NT_Trimmed) and heavy chain (input_heavy_sequence).\n",
    "    \n",
    "    Args:\n",
    "        csv_filename (str): Path to the input CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        print(f\"Reading CSV file: {csv_filename}\")\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        \n",
    "        print(f\"Initial number of rows: {len(df)}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_columns = ['fasta_id', 'NT_Trimmed', 'input_heavy_sequence', 'pairing_scores']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "            return\n",
    "        \n",
    "        # Remove rows with missing data in required columns\n",
    "        initial_count = len(df)\n",
    "        df = df.dropna(subset=required_columns)\n",
    "        print(f\"Rows after removing missing data: {len(df)} (removed {initial_count - len(df)})\")\n",
    "        \n",
    "        # Remove duplicates based on NT_Trimmed column\n",
    "        # Keep the first occurrence of each unique sequence\n",
    "        pre_dedup_count = len(df)\n",
    "        df = df.drop_duplicates(subset=['NT_Trimmed'], keep='first')\n",
    "        duplicates_removed = pre_dedup_count - len(df)\n",
    "        print(f\"Rows after removing duplicates: {len(df)} (removed {duplicates_removed} duplicates)\")\n",
    "        \n",
    "        # Convert pairing_scores to numeric, handle any conversion errors\n",
    "        df['pairing_scores'] = pd.to_numeric(df['pairing_scores'], errors='coerce')\n",
    "        \n",
    "        # Remove rows where pairing_scores couldn't be converted\n",
    "        df = df.dropna(subset=['pairing_scores'])\n",
    "        print(f\"Final rows for processing: {len(df)}\")\n",
    "        \n",
    "        # Split data based on pairing scores\n",
    "        high_scores = df[df['pairing_scores'] >= 0.5]\n",
    "        low_scores = df[df['pairing_scores'] < 0.5]\n",
    "        \n",
    "        print(f\"High pairing scores (>=0.5): {len(high_scores)} sequences\")\n",
    "        print(f\"Low pairing scores (<0.5): {len(low_scores)} sequences\")\n",
    "        \n",
    "        # Function to create FASTA content with both light and heavy chains\n",
    "        def create_fasta_content(dataframe):\n",
    "            fasta_entries = []\n",
    "            for _, row in dataframe.iterrows():\n",
    "                fasta_id = row['fasta_id']\n",
    "                light_sequence = row['NT_Trimmed']\n",
    "                heavy_sequence = row['input_heavy_sequence']\n",
    "                \n",
    "                # Add light chain entry\n",
    "                fasta_entries.append(f\">protein|{fasta_id}\")\n",
    "                fasta_entries.append(light_sequence)\n",
    "                \n",
    "                # Add heavy chain entry\n",
    "                fasta_entries.append(f\">protein|heavy_{fasta_id}\")\n",
    "                fasta_entries.append(heavy_sequence)\n",
    "                \n",
    "            return '\\n'.join(fasta_entries) + '\\n'\n",
    "        \n",
    "        # Create FASTA files\n",
    "        high_scores_fasta = create_fasta_content(high_scores)\n",
    "        low_scores_fasta = create_fasta_content(low_scores)\n",
    "        \n",
    "        # Write high pairing scores FASTA file\n",
    "        high_filename = 'high_pairing_scores_immunomatch_bert2gpt_trimmed.fasta'\n",
    "        with open(high_filename, 'w') as f:\n",
    "            f.write(high_scores_fasta)\n",
    "        print(f\"Created: {high_filename}\")\n",
    "        \n",
    "        # Write low pairing scores FASTA file\n",
    "        low_filename = 'low_pairing_scores_immunomatch_bert2gpt_trimmed.fasta'\n",
    "        with open(low_filename, 'w') as f:\n",
    "            f.write(low_scores_fasta)\n",
    "        print(f\"Created: {low_filename}\")\n",
    "        \n",
    "        # Display some statistics\n",
    "        print(\"\\n=== SUMMARY ===\")\n",
    "        print(f\"Total unique sequences processed: {len(df)}\")\n",
    "        print(f\"High pairing scores (>=0.5): {len(high_scores)} sequences ({len(high_scores) * 2} FASTA entries)\")\n",
    "        print(f\"Low pairing scores (<0.5): {len(low_scores)} sequences ({len(low_scores) * 2} FASTA entries)\")\n",
    "        print(f\"Duplicates removed: {duplicates_removed}\")\n",
    "        \n",
    "        # Show first few entries from each file as preview\n",
    "        print(f\"\\n=== PREVIEW OF {high_filename} ===\")\n",
    "        if len(high_scores) > 0:\n",
    "            preview_lines = high_scores_fasta.split('\\n')[:8]  # First 2 pairs (8 lines)\n",
    "            print('\\n'.join(preview_lines))\n",
    "            if len(high_scores) > 2:\n",
    "                print(\"...\")\n",
    "        else:\n",
    "            print(\"No sequences with high pairing scores.\")\n",
    "        \n",
    "        print(f\"\\n=== PREVIEW OF {low_filename} ===\")\n",
    "        if len(low_scores) > 0:\n",
    "            preview_lines = low_scores_fasta.split('\\n')[:8]  # First 2 pairs (8 lines)\n",
    "            print('\\n'.join(preview_lines))\n",
    "            if len(low_scores) > 2:\n",
    "                print(\"...\")\n",
    "        else:\n",
    "            print(\"No sequences with low pairing scores.\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{csv_filename}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0940b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/ibmm_data2/oas_database/paired_lea_tmp/paired_model/immuno_match/immunomatch_results/pairing_result_bert2gpt_full_complete_ids_mapping_unique_nt_trimmed_gene_hit_locus.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "402b90f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file: /ibmm_data2/oas_database/paired_lea_tmp/paired_model/immuno_match/immunomatch_results/pairing_result_bert2gpt_full_complete_ids_mapping_unique_nt_trimmed_gene_hit_locus.csv\n",
      "Initial number of rows: 8388\n",
      "Columns: ['Unnamed: 0', 'fasta_id', 'csv_row_index', 'csv_row_number', 'sequence_alignment_aa_light', 'generated_sequence_light', 'input_heavy_sequence', 'BLOSUM_score', 'similarity', 'perplexity', 'calculated_blosum', 'calculated_similarity', 'NT_Trimmed', 'Best_Gene', 'Best_Bit_Score', 'Best_E_Value', 'Locus', 'pairing_scores']\n",
      "Rows after removing missing data: 8388 (removed 0)\n",
      "Rows after removing duplicates: 8388 (removed 0 duplicates)\n",
      "Final rows for processing: 8388\n",
      "High pairing scores (>=0.5): 3712 sequences\n",
      "Low pairing scores (<0.5): 4676 sequences\n",
      "Created: high_pairing_scores_immunomatch_bert2gpt_trimmed.fasta\n",
      "Created: low_pairing_scores_immunomatch_bert2gpt_trimmed.fasta\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total unique sequences processed: 8388\n",
      "High pairing scores (>=0.5): 3712 sequences (7424 FASTA entries)\n",
      "Low pairing scores (<0.5): 4676 sequences (9352 FASTA entries)\n",
      "Duplicates removed: 0\n",
      "\n",
      "=== PREVIEW OF high_pairing_scores_immunomatch_bert2gpt_trimmed.fasta ===\n",
      ">protein|seq_5_63bc1d18_sim39.5_blosum152_perp2.4\n",
      "DIVMTQTPLSSPVTLGQPASISCRSSQSLVHSDGNTYLSWLQQRPGQPPRLLIYKIYNRFSGVPDRFSGSGAGTDFTLKISRVEAEDVGVYYCMQATQFP\n",
      ">protein|heavy_seq_5_63bc1d18_sim39.5_blosum152_perp2.4\n",
      "QVQLVESGGGVVQPGRSLRLSCAASGFTFSSHGLHWVRQAPGKGLEWVAVMSHEGNKKYHADSVKGRFTISRDNSKNTLYLEMNSLRAEDTAVYYCARGNRGTADYWGQGTLVTVSS\n",
      ">protein|seq_13_55679b8e_sim65.2_blosum339_perp2.6\n",
      "QSVLTQPPSVSGAPGQRVTISCTGSSSNIGAGYDVHWYQQLPGTAPKLLIYGNNNRPSGVPDRFSGSKSGTSASLAITGLQAEDEADYYCQSYDTSLSG\n",
      ">protein|heavy_seq_13_55679b8e_sim65.2_blosum339_perp2.6\n",
      "QVQLQESGPGQVKPSETLSLTCTVSGGSISTYYWTWTRQTPGKGLEWIGYIDNRGSTNYNPSLKSRVAISVDTSKNQFSLKLTSVTAADTAVYYCARSGGGYDRDGFYYSYFAMDVWGQGTTVTVSS\n",
      "...\n",
      "\n",
      "=== PREVIEW OF low_pairing_scores_immunomatch_bert2gpt_trimmed.fasta ===\n",
      ">protein|seq_0_0ccf5613_sim63.7_blosum345_perp2.4\n",
      "DIVMTQSPDSLAVSLGERATINCKSSQSVLYSSNNKNYLAWYQQKPGQPPKLLIYWASTRESGVPDRFSGSGSGTDFTLTISSLQAEDVAVYYCQQYYSSP\n",
      ">protein|heavy_seq_0_0ccf5613_sim63.7_blosum345_perp2.4\n",
      "QLQVQESGPGLVKPSETLSLTCTVSGASSSIKKYYWGWIRQSPGKGLEWIGSIYSSGSTQYNPALGSRVTLSVDTSQTQFSLRLTSVTAADTATYFCARQGADCTDGSCYLNDAFDVWGRGTVVTVSS\n",
      ">protein|seq_4_ceace03b_sim46.4_blosum246_perp2.3\n",
      "QSALTQPASVSGSPGQSITISCTGTSSDVGGYNYVSWYQQHPGKAPKLMIYDVSNRPSGVSNRFSGSKSGNTASLTISGLQAEDEADYYCSSYTSSST\n",
      ">protein|heavy_seq_4_ceace03b_sim46.4_blosum246_perp2.3\n",
      "QVQLQESGPGLVKPSGTLSLTCVVSGGSISTNNWWSWVRQPPGKGLEWIGEIYHSGFTNYNPSLRSRVSILADNSKNQFSLRLNSVTAADTAVYYCALYTSGWYALDHWGQGILVTVSS\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "create_fasta_files(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ddff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adap_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
